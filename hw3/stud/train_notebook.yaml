# data_args:
#   dataset_name: emotion
#   split_id: 01M
#   orthography: librispeech
#   speech_file_column: file
#   target_text_column: text

# model_args:
#   model_name_or_path: facebook/wav2vec2-base
#   cache_dir: cache
#   alpha: 0.1
#   tokenizer: facebook/wav2vec2-base

training_args:
  # output_dir: ../../model/checkpoints/
  # gradient_checkpointing: True
  # num_train_epochs: 6
  # do_train: True
  # do_eval: True
  # per_device_train_batch_size: 2
  # per_device_eval_batch_size: 2
  # evaluation_strategy: steps
  # save_total_limit: 1
  # save_steps: 500
  # eval_steps: 50
  # logging_steps: 250
  # logging_dir: log
  # learning_rate: 0.000005
  # gradient_accumulation_steps: 1 # batch size * acc = 8
  # fp16: True
  # seed: 10
  # dataloader_num_workers: 0

  output_dir: ../../model/checkpoints/
  save_model: False
  # resume_from_checkpoint: ../../model/checkpoints/850_6.pth
  num_train_epochs: 4
  logging_steps: 250
  # learning_rate: 0.000005
  learning_rate: 0.000005
  # grad_clipping: None
  early_stopping: True
  early_stopping_mode: max
  early_stopping_patience: 2
