{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0826276",
   "metadata": {},
   "source": [
    "This is the implementation of the model that follows the Mention Score approach to compute the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wIOz40JYJddq",
   "metadata": {
    "id": "wIOz40JYJddq"
   },
   "outputs": [],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3244dc15",
   "metadata": {
    "executionInfo": {
     "elapsed": 2834,
     "status": "ok",
     "timestamp": 1662929477437,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "3244dc15"
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    BertModel,\n",
    "    logging\n",
    ")\n",
    "import transformers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import yaml\n",
    "\n",
    "from typing import *\n",
    "from datetime import datetime\n",
    "from collections import namedtuple\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "SEED = 10\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Display the entire text\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58276aa2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1662929477438,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "58276aa2",
    "outputId": "eee38236-293b-4e07-a815-e6aa5d546200"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "kYGIp3MoJug2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1740,
     "status": "ok",
     "timestamp": 1662929479172,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "kYGIp3MoJug2",
    "outputId": "35c6caac-149a-47e4-83b0-ff16277def3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# For Colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "\n",
    "curr_location = \"/content/drive/MyDrive/Colab Notebooks/Deep Learning/NLP/nlp2022-hw3/hw3/stud/\"\n",
    "os.chdir(curr_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "QFqvmoaqhbyn",
   "metadata": {
    "id": "QFqvmoaqhbyn"
   },
   "outputs": [],
   "source": [
    "curr_location = \"H:/My Drive/Colab Notebooks/Deep Learning/NLP/nlp2022-hw3/hw3/stud\"\n",
    "os.chdir(curr_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fM1EDyRLifxE",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1662929479172,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "fM1EDyRLifxE"
   },
   "outputs": [],
   "source": [
    "from arguments import *\n",
    "from gap_dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "198e81e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1662929479173,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "198e81e5",
    "outputId": "f67b0dc8-4a84-454a-9802-78b3558430a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert-base-uncased'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yaml_file = \"./train_notebook2.yaml\"\n",
    "# Read configuration file with all the necessary parameters\n",
    "with open(yaml_file) as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    \n",
    "model_args = ModelArguments(**config['model_args'])\n",
    "model_name_or_path = model_args.model_name_or_path\n",
    "model_name_or_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3633ef51",
   "metadata": {
    "executionInfo": {
     "elapsed": 210,
     "status": "ok",
     "timestamp": 1662929481341,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "3633ef51"
   },
   "outputs": [],
   "source": [
    "train_clean_path = \"../../model/data/train_clean.tsv\"\n",
    "valid_clean_path = \"../../model/data/valid_clean.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "B1CvSmUrKc1y",
   "metadata": {
    "executionInfo": {
     "elapsed": 333,
     "status": "ok",
     "timestamp": 1662929482505,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "B1CvSmUrKc1y"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(filepath_or_buffer=train_clean_path, sep=\"\\t\")\n",
    "df_valid = pd.read_csv(filepath_or_buffer=valid_clean_path, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18fe9e9c",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1662929482506,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "18fe9e9c"
   },
   "outputs": [],
   "source": [
    "tag_labels = {\n",
    "    \"pronoun_tag\": \"<p>\",\n",
    "    \"start_A_tag\": \"<a>\",\n",
    "    \"end_A_tag\": \"</a>\",\n",
    "    \"start_B_tag\": \"<b>\",\n",
    "    \"end_B_tag\": \"</b>\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a86aae6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1662929483411,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "3a86aae6",
    "outputId": "8787188d-c4a8-4958-e670-a28aa5691b21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert-base-uncased'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_name_or_path = model_args.tokenizer\n",
    "if tokenizer_name_or_path is None:\n",
    "    tokenizer_name_or_path = model_name_or_path\n",
    "tokenizer_name_or_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6844631",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1763,
     "status": "ok",
     "timestamp": 1662929485921,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "e6844631",
    "outputId": "9d669385-829b-4fb9-c05f-84abb3032865"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name_or_path, never_split=list(tag_labels.values()))\n",
    "tokenizer.add_tokens(list(tag_labels.values()), special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7997cbe1",
   "metadata": {
    "executionInfo": {
     "elapsed": 4918,
     "status": "ok",
     "timestamp": 1662929490837,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "7997cbe1"
   },
   "outputs": [],
   "source": [
    "train_ds = GAP_Dataset(df_train, tokenizer, tag_labels, truncate_up_to_pron=False)\n",
    "valid_ds = GAP_Dataset(df_valid, tokenizer, tag_labels, truncate_up_to_pron=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8185e7a8",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1662929490837,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "8185e7a8"
   },
   "outputs": [],
   "source": [
    "class Entity_Resolution_Head(nn.Module):\n",
    "    def __init__(self, bert_hidden_size: int, args: ModelArguments):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.args = args\n",
    "        self.bert_hidden_size = bert_hidden_size\n",
    "\n",
    "        input_size_pronoun = bert_hidden_size\n",
    "        input_size_entities = bert_hidden_size * 6\n",
    "        if self.args.output_strategy == \"concat\":\n",
    "            input_size_pronoun *= 4\n",
    "            input_size_entities *= 4\n",
    "\n",
    "        self.ffnn_pronoun = nn.Sequential(\n",
    "            nn.Linear(input_size_pronoun, bert_hidden_size),\n",
    "            nn.LayerNorm(bert_hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(args.dropout),\n",
    "            nn.Linear(bert_hidden_size, args.head_hidden_size),\n",
    "        )\n",
    "        \n",
    "        self.ffnn_entities = nn.Sequential(\n",
    "            nn.Linear(input_size_entities, bert_hidden_size),\n",
    "            nn.LayerNorm(bert_hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(args.dropout),\n",
    "            nn.Linear(bert_hidden_size, args.head_hidden_size),\n",
    "        )\n",
    "\n",
    "        linear_hidden_size = args.linear_hidden_size\n",
    "\n",
    "        # self.bilinear = torch.nn.Bilinear(args.head_hidden_size, args.head_hidden_size, bilinear_hidden_size, bias=False)\n",
    "        self.linear = torch.nn.Linear(args.head_hidden_size * 2, linear_hidden_size)\n",
    "        self.activation = nn.GELU()\n",
    "        self.dropout = nn.Dropout(args.dropout)\n",
    "        \n",
    "        self.classifier = nn.Linear(linear_hidden_size, args.num_output)\n",
    "\n",
    "    def forward(self, bert_outputs, offsets):\n",
    "\n",
    "        pron_emb, ent_emb = self._retrieve_pron_and_ent_embeddings(bert_outputs, offsets)\n",
    "\n",
    "        x_pron = self.ffnn_pronoun(pron_emb)\n",
    "        x_ent = self.ffnn_entities(ent_emb)\n",
    "        \n",
    "        # x = self.bilinear(x_pron, x_ent)\n",
    "        x = self.linear(torch.cat([x_pron, x_ent], dim=-1))\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        output = self.classifier(x)\n",
    "        return output\n",
    "    \n",
    "    def _retrieve_pron_and_ent_embeddings(self, bert_embeddings: torch.Tensor, \n",
    "                                          offsets: torch.Tensor):\n",
    "        embeddings_A = []\n",
    "        embeddings_B = []\n",
    "        pronouns_embedding = []\n",
    "\n",
    "        # Consider embeddings and offsets in each batch separately\n",
    "        for embeddings, off in zip(bert_embeddings, offsets):\n",
    "            start_A = off[0] \n",
    "            end_A = off[1]\n",
    "            start_B = off[2]\n",
    "            end_B = off[3]\n",
    "            pron_off = off[-1]\n",
    "\n",
    "            emb_A = torch.cat([embeddings[start_A], embeddings[end_A-1], embeddings[start_A:end_A].mean(dim=0)], dim=-1)\n",
    "            embeddings_A.append(emb_A)\n",
    "\n",
    "            emb_B = torch.cat([embeddings[start_B], embeddings[end_B-1], embeddings[start_B:end_B].mean(dim=0)], dim=-1)\n",
    "            embeddings_B.append(emb_B)\n",
    "\n",
    "            pronouns_embedding.append(embeddings[pron_off])\n",
    "\n",
    "        # batch_size x (embedding_dim * 3 * 2)\n",
    "        merged_entities_embeddings = torch.cat([\n",
    "            torch.stack(embeddings_A, dim=0),\n",
    "            torch.stack(embeddings_B, dim=0),\n",
    "        ], dim=1)\n",
    "\n",
    "        # batch_size x embedding_dim \n",
    "        stacked_pronouns_embedding = torch.stack(pronouns_embedding, dim=0)\n",
    "        \n",
    "        return stacked_pronouns_embedding, merged_entities_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb7c679d",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1662929491618,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "eb7c679d"
   },
   "outputs": [],
   "source": [
    "class CR_Model(nn.Module):\n",
    "    \"\"\"The main model.\"\"\"\n",
    "\n",
    "    def __init__(self, bert_model: str, tokenizer, args: ModelArguments):\n",
    "        super().__init__()\n",
    "\n",
    "        self.args = args\n",
    "        \n",
    "        if bert_model in {\"bert-base-uncased\", \"bert-base-cased\"}:\n",
    "            self.bert_hidden_size = 768\n",
    "        elif bert_model in {\"bert-large-uncased\", \"bert-large-cased\"}:\n",
    "            self.bert_hidden_size = 1024\n",
    "        else:\n",
    "            self.bert_hidden_size = args.bert_hidden_size\n",
    "\n",
    "        self.bert = BertModel.from_pretrained(\n",
    "            bert_model).to(device, non_blocking=True)\n",
    "\n",
    "        # If the tag tokens (e.g., <p>, <a> etc.) are present in the features,\n",
    "        # the embedding dimension of the bert embeddings must be changed\n",
    "        # to be compliant with the new size of the tokenizer vocabulary. \n",
    "        if args.resize_embeddings:\n",
    "            self.bert.resize_token_embeddings(len(tokenizer.vocab))\n",
    "\n",
    "        self.head = Entity_Resolution_Head(self.bert_hidden_size, args).to(\n",
    "            device, non_blocking=True)\n",
    "\n",
    "    def forward(self, sample):\n",
    "        x = sample['features']\n",
    "        x_offsets = sample['offsets']\n",
    "\n",
    "        bert_outputs = self.bert(\n",
    "            x, attention_mask=(x > 0).long(),\n",
    "            token_type_ids=None, output_hidden_states=True)\n",
    "        \n",
    "        if self.args.output_strategy == \"last\":\n",
    "            out = bert_outputs.last_hidden_state\n",
    "\n",
    "        elif self.args.output_strategy == \"concat\":\n",
    "            out = torch.cat([bert_outputs.hidden_states[x] for x in [-1, -2, -3, -4]], dim=-1)\n",
    "\n",
    "        elif self.args.output_strategy == \"sum\":\n",
    "            layers_to_sum = torch.stack([bert_outputs.hidden_states[x] for x in [-1, -2, -3, -4]], dim=0)\n",
    "            out = torch.sum(layers_to_sum, dim=0)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported output strategy.\")\n",
    "            \n",
    "        head_outputs = self.head(out, x_offsets)\n",
    "        return head_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71b85264",
   "metadata": {
    "executionInfo": {
     "elapsed": 191,
     "status": "ok",
     "timestamp": 1662928146610,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "71b85264"
   },
   "outputs": [],
   "source": [
    "def freeze_weights(modules):\n",
    "    for module in modules:\n",
    "        for param in module.parameters():\n",
    "            if hasattr(param, 'requires_grad'):\n",
    "                param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31aa4455",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7655,
     "status": "ok",
     "timestamp": 1662928996712,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "31aa4455",
    "outputId": "d76606b7-770a-431f-d943-d8e9eb044c95",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomTrainingArguments(output_dir='../../model/checkpoints/', task_type=3, save_model=True, num_train_epochs=2, logging_steps=250, learning_rate=8e-06, grad_clipping=None, use_early_stopping=True, early_stopping_mode='max', early_stopping_patience=2, use_scaler=True)\n"
     ]
    }
   ],
   "source": [
    "model = CR_Model(model_name_or_path, tokenizer, model_args).to(device, non_blocking=True)\n",
    "\n",
    "last_frozen_layer = 12\n",
    "modules = [model.bert.embeddings, *model.bert.encoder.layer[:last_frozen_layer]]\n",
    "# modules = [*model.bert.encoder.layer[:last_frozen_layer]]\n",
    "freeze_weights(modules)\n",
    "\n",
    "yaml_file = \"./train_notebook2.yaml\"\n",
    "# Read configuration file with all the necessary parameters\n",
    "with open(yaml_file) as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    \n",
    "training_args = CustomTrainingArguments(**config['training_args'])\n",
    "\n",
    "# Make sure that the learning rate is read as a number and not as a string\n",
    "training_args.learning_rate = float(training_args.learning_rate)\n",
    "print(training_args)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device=device, non_blocking=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=training_args.learning_rate)\n",
    "# scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.8)\n",
    "# scheduler = None\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "collator = Collator(device)\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, \n",
    "                              collate_fn=collator, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_ds, batch_size=batch_size, \n",
    "                              collate_fn=collator, shuffle=False)\n",
    "\n",
    "from trainer import Trainer\n",
    "trainer = Trainer(str(device), model, training_args, \n",
    "                  train_dataloader, valid_dataloader, \n",
    "                  criterion, optimizer, scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7c8f03a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 355420,
     "status": "ok",
     "timestamp": 1662929362221,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "e7c8f03a",
    "outputId": "8e4b3054-ef2a-4528-b7a9-3be8bc7f9cdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training...\n",
      "\t| step  250/750 | train_loss: 0.842 | train_acc: 0.625 |\n",
      "\t| step  500/750 | train_loss: 0.660 | train_acc: 0.726 |\n",
      "\t| step  750/750 | train_loss: 0.575 | train_acc: 0.769 |\n",
      "-----------------\n",
      "| LR: 8.000e-06 |\n",
      "----------------------------------------------------------------------------\n",
      "| epoch   1/2   | train_loss: 0.575 | valid_loss: 0.396 | valid_acc: 0.866 |\n",
      "----------------------------------------------------------------------------\n",
      "\t| step  250/750 | train_loss: 0.252 | train_acc: 0.922 |\n",
      "\t| step  500/750 | train_loss: 0.258 | train_acc: 0.918 |\n",
      "\t| step  750/750 | train_loss: 0.254 | train_acc: 0.916 |\n",
      "-----------------\n",
      "| LR: 6.400e-06 |\n",
      "----------------------------------------------------------------------------\n",
      "| epoch   2/2   | train_loss: 0.254 | valid_loss: 0.407 | valid_acc: 0.872 |\n",
      "----------------------------------------------------------------------------\n",
      "Training time: 5m 44s\n",
      "{'train_losses': [0.5752722439219554, 0.2539264081319173], 'train_acc': [0.768922974324775, 0.9156385461820606], 'valid_losses': [0.39554286375641823, 0.4067128017266983], 'valid_acc': [0.8656387665198237, 0.8722466960352423]}\n",
      "Saving model...\n",
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "metrics_history = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3280693e",
   "metadata": {
    "id": "3280693e"
   },
   "outputs": [],
   "source": [
    "metrics_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfcc7055",
   "metadata": {
    "executionInfo": {
     "elapsed": 11758,
     "status": "ok",
     "timestamp": 1662929511659,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "bfcc7055",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = CR_Model(model_name_or_path, tokenizer, model_args).to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff48e517",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = \"../../model/checkpoints/MentionScore/base/base-mention_score_870.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce5edddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(model_save_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92449b7a",
   "metadata": {},
   "source": [
    "    torch.save(model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57b9ea3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_save_path, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb3812e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gap_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d02ca5d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 192,
     "status": "ok",
     "timestamp": 1662929551454,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "9d02ca5d",
    "outputId": "8b28bdc8-9f4f-4b15-f518-8cbaf209587a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'her': 402, 'she': 269, 'his': 181, 'he': 111, 'him': 37, 'hers': 1})\n"
     ]
    }
   ],
   "source": [
    "valid_path = \"../../model/data/dev.tsv\"\n",
    "valid_dataset, _ = read_dataset(valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54c46866",
   "metadata": {
    "executionInfo": {
     "elapsed": 201,
     "status": "ok",
     "timestamp": 1662929552539,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "54c46866"
   },
   "outputs": [],
   "source": [
    "def predict(model, sentences: List[Dict], tokenizer, tag_labels, device) -> List[Tuple[Tuple[str, int], Tuple[str, int]]]:\n",
    "    df = pd.DataFrame(sentences)\n",
    "\n",
    "    dataset = GAP_Dataset(df, tokenizer, tag_labels, truncate_up_to_pron=False, labeled=False, cleaned=False)\n",
    "    collator = Collator(device, labeled=False)\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        dataloader = DataLoader(dataset, batch_size=1, \n",
    "                                collate_fn=collator, shuffle=False)\n",
    "        \n",
    "        for sample, sentence in zip(dataloader, sentences):           \n",
    "            predicted_label_id = model(sample).argmax(1).item()\n",
    "            pred_entity, pred_entity_offset = get_entity_and_offset_from_id(predicted_label_id, sentence)\n",
    "            pron, pron_offset = sentence['pron'], sentence['p_offset']\n",
    "            predictions.append(((pron, pron_offset), (pred_entity, pred_entity_offset)))\n",
    "            \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "qHfx2UH4OSYM",
   "metadata": {
    "executionInfo": {
     "elapsed": 20876,
     "status": "ok",
     "timestamp": 1662929812030,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "qHfx2UH4OSYM"
   },
   "outputs": [],
   "source": [
    "pred = predict(model, valid_dataset, tokenizer, tag_labels, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3h08eqTOOVxM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1662929812031,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "3h08eqTOOVxM",
    "outputId": "5c6ac3cd-7bd0-4249-e512-890abf71bc5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# instances: 1001\n",
      "# accuracy: 0.8691\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(pred, valid_dataset)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.7 (DL)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
