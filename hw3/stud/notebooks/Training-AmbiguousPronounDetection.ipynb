{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa971fa8",
   "metadata": {},
   "source": [
    "This notebook implements the ambiguous pronoun detection. The model reaches pretty good performances: 91% accuracy.\n",
    "\n",
    "However, I did not delve into it too much, since I did not find a good model for entity identification and resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wIOz40JYJddq",
   "metadata": {
    "id": "wIOz40JYJddq"
   },
   "outputs": [],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3244dc15",
   "metadata": {
    "executionInfo": {
     "elapsed": 5489,
     "status": "ok",
     "timestamp": 1660751770217,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "3244dc15"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    BertModel,\n",
    "    logging\n",
    ")\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import yaml\n",
    "from typing import *\n",
    "from datetime import datetime\n",
    "from collections import namedtuple\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "SEED = 10\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Display the entire text\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58276aa2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 259,
     "status": "ok",
     "timestamp": 1660751781007,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "58276aa2",
    "outputId": "150bbcf1-dbcd-480d-9e85-82e77346e83f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "kYGIp3MoJug2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15143,
     "status": "ok",
     "timestamp": 1660751806072,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "kYGIp3MoJug2",
    "outputId": "aad7d923-b163-4609-93a9-a07790cbfba2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "# For Colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "\n",
    "curr_location = \"/content/drive/MyDrive/Colab Notebooks/Deep Learning/NLP/nlp2022-hw3/hw3/stud/\"\n",
    "os.chdir(curr_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3aac485",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_location = \"H:/My Drive/Colab Notebooks/Deep Learning/NLP/nlp2022-hw3/hw3/stud\"\n",
    "os.chdir(curr_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fM1EDyRLifxE",
   "metadata": {
    "executionInfo": {
     "elapsed": 1348,
     "status": "ok",
     "timestamp": 1660751818200,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "fM1EDyRLifxE"
   },
   "outputs": [],
   "source": [
    "from arguments import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39142d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert-base-uncased'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yaml_file = \"./train_notebook2.yaml\"\n",
    "# Read configuration file with all the necessary parameters\n",
    "with open(yaml_file) as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    \n",
    "model_args = ModelArguments(**config['model_args'])\n",
    "model_name_or_path = model_args.model_name_or_path\n",
    "model_name_or_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3633ef51",
   "metadata": {
    "executionInfo": {
     "elapsed": 279,
     "status": "ok",
     "timestamp": 1660751819788,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "3633ef51"
   },
   "outputs": [],
   "source": [
    "train_clean_path = \"../../model/data/train_clean.tsv\"\n",
    "valid_clean_path = \"../../model/data/valid_clean.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "B1CvSmUrKc1y",
   "metadata": {
    "executionInfo": {
     "elapsed": 1177,
     "status": "ok",
     "timestamp": 1660751822725,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "B1CvSmUrKc1y"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(filepath_or_buffer=train_clean_path, sep=\"\\t\")\n",
    "df_valid = pd.read_csv(filepath_or_buffer=valid_clean_path, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e80c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAP_Ambiguous_Detection_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom GAP dataset for ambiguous pronoun identification.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame\n",
    "        A dataframe from the GAP dataset.\n",
    "        \n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "        The tokenizer used to preprocess the data.\n",
    "        \n",
    "    pronouns_list: List[str]\n",
    "        A list containing the pronound that may apper\n",
    "        in the dataset.\n",
    "        \n",
    "    pronoun_tag: strdd\n",
    "        The pronoun tag that will be inserted to detect the ambiguous\n",
    "        pronoun, if labeled is True.\n",
    "          \n",
    "    keep_tags: bool\n",
    "        If true the tags added to text are kept even after\n",
    "        the tokenization process.\n",
    "  \n",
    "    labeled: bool\n",
    "        If the dataset also contains the labels.\n",
    "        \n",
    "    cleaned: bool\n",
    "        Whether the GAP dataframe is already cleaned or not.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        df: pd.DataFrame, \n",
    "        tokenizer: PreTrainedTokenizerBase, \n",
    "        pronouns_list: List[str],\n",
    "        pronoun_tag: str, \n",
    "        keep_tags: bool=False, \n",
    "        labeled: bool=True, \n",
    "        cleaned: bool=True\n",
    "    ):\n",
    "        \n",
    "        if not cleaned:\n",
    "             self.clean_dataframe(df)\n",
    "\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.pronouns_list = pronouns_list\n",
    "        self.pronoun_tag = pronoun_tag\n",
    "        self.keep_tags = keep_tags\n",
    "        self.labeled = labeled\n",
    "        \n",
    "        self.samples = []\n",
    "        self._convert_tokens_to_ids()\n",
    "        \n",
    "    @staticmethod\n",
    "    def clean_text(text: str):\n",
    "        text = text.translate(str.maketrans(\"`\", \"'\"))\n",
    "        return text\n",
    "\n",
    "    def clean_dataframe(self, df: pd.DataFrame):\n",
    "        df['text'] = df['text'].map(self.clean_text)\n",
    "        df['entity_A'] = df['entity_A'].map(self.clean_text) \n",
    "        df['entity_B'] = df['entity_B'].map(self.clean_text) \n",
    "\n",
    "    def _assign_class_to_pronouns(self, offsets: List[int],\n",
    "                                ambiguous_offset: int) -> List[int]:\n",
    "        \"\"\"\n",
    "        Returns\n",
    "        -------\n",
    "            A list of integers defining the pronoun class.\n",
    "            The class id is:\n",
    "            - 2 if the pronoun is the ambiguous one\n",
    "            - 1 for all the other pronouns\n",
    "            - (0 will be used for padding)\n",
    "        \"\"\"\n",
    "        labels = []\n",
    "        for off in offsets:\n",
    "            if off == ambiguous_offset:\n",
    "                labels.append(2)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "\n",
    "        return labels\n",
    "        \n",
    "    def _convert_tokens_to_ids(self):\n",
    "        CLS = [self.tokenizer.cls_token]\n",
    "        SEP = [self.tokenizer.sep_token]\n",
    "\n",
    "        Sample = namedtuple(\"Sample\", ['tokens', 'offsets'])\n",
    "        if self.labeled:\n",
    "            Sample = namedtuple(\"Sample\", Sample._fields + (\"labels\",))\n",
    "\n",
    "        for _, row in self.df.iterrows():\n",
    "            tokens, pronouns_offsets, ambiguous_offset = self._tokenize(row)\n",
    "\n",
    "            tokens_to_convert = CLS + tokens + SEP\n",
    "            final_tokens = self.tokenizer.convert_tokens_to_ids(tokens_to_convert)\n",
    "                \n",
    "            sample = {'tokens': final_tokens,\n",
    "                      'offsets': self._get_offsets_list(pronouns_offsets)}\n",
    "    \n",
    "            if self.labeled:\n",
    "                sample['labels'] = self._assign_class_to_pronouns(pronouns_offsets,\n",
    "                                                                  ambiguous_offset)\n",
    "\n",
    "            sample_namedtuple = Sample(**sample)\n",
    "            self.samples.append(sample_namedtuple)\n",
    "\n",
    "            \n",
    "    def _get_offsets_list(self, offsets: List[int]) -> List[int]:\n",
    "        # 1 is added for the introduction of the CLS token\n",
    "        return list(map(lambda off: off+1, offsets))\n",
    "\n",
    "        \n",
    "    def _insert_tag(self, text: str, offsets: Tuple[int, int], \n",
    "                    start_tag: str, end_tag: str = None) -> str:\n",
    "        start_off, end_off = offsets \n",
    "\n",
    "        # Starting tag only\n",
    "        if end_tag is None:\n",
    "            text = text[:start_off] + start_tag + text[start_off:]\n",
    "            return text\n",
    "\n",
    "        text = text[:start_off] + start_tag + text[start_off:end_off] + end_tag + text[end_off:]\n",
    "        return text\n",
    "\n",
    "    \n",
    "    def _tokenize(self, row: pd.Series) -> Tuple[List[int], List[int], int]: \n",
    "        \"\"\"\n",
    "        Tokenize the text.\n",
    "        If keep_tags is True, also the tags are tokenized.\n",
    "        \"\"\"        \n",
    "        tokens =[]\n",
    "        pronouns_offsets = []\n",
    "        ambiguous_offset = -1\n",
    "   \n",
    "        text = row['text']\n",
    "        \n",
    "        if self.labeled:\n",
    "            text = self._insert_tag(text, (row['p_offset'], None),\n",
    "                                    self.pronoun_tag)\n",
    "\n",
    "        # Also the tags are added to the tokens\n",
    "        if self.keep_tags:\n",
    "            for token in self.tokenizer.tokenize(text):\n",
    "                if token == self.pronoun_tag:\n",
    "                    ambiguous_offset = len(tokens) + 1\n",
    "                \n",
    "                if token.lower() in self.pronouns_list:\n",
    "                    pronouns_offsets.append(len(tokens)) \n",
    "                    \n",
    "                tokens.append(token)\n",
    "        \n",
    "        # The tags are skipped\n",
    "        else:\n",
    "            for token in self.tokenizer.tokenize(text):\n",
    "                \n",
    "                if token == self.pronoun_tag:\n",
    "                    ambiguous_offset = len(tokens)\n",
    "                    continue\n",
    "                \n",
    "                if token.lower() in self.pronouns_list:\n",
    "                    pronouns_offsets.append(len(tokens)) \n",
    "                    \n",
    "                tokens.append(token)\n",
    "        \n",
    "        return tokens, pronouns_offsets, ambiguous_offset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33a7d02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert-base-uncased'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_name_or_path = model_args.tokenizer\n",
    "if tokenizer_name_or_path is None:\n",
    "    tokenizer_name_or_path = model_name_or_path\n",
    "tokenizer_name_or_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6844631",
   "metadata": {
    "id": "e6844631"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronoun_tag = \"<p>\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name_or_path, never_split=[pronoun_tag])\n",
    "tokenizer.add_tokens([pronoun_tag], special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7599fc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pronouns_list = ['he','she','him','her','his','hers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7997cbe1",
   "metadata": {
    "executionInfo": {
     "elapsed": 5692,
     "status": "ok",
     "timestamp": 1660751846338,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "7997cbe1"
   },
   "outputs": [],
   "source": [
    "train_ds = GAP_Ambiguous_Detection_Dataset(df_train, tokenizer, pronouns_list, pronoun_tag)\n",
    "valid_ds = GAP_Ambiguous_Detection_Dataset(df_valid, tokenizer, pronouns_list, pronoun_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef4ed717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_max_len(sequences: Union[List[List[int]], Tuple[List[int]]], truncate_len: int) -> int:\n",
    "    \"\"\"\n",
    "    Computes the maximum length in the sequences.         \n",
    "    \"\"\"\n",
    "    max_len = min(\n",
    "        max((len(x) for x in sequences)),\n",
    "        truncate_len\n",
    "    )\n",
    "    return max_len\n",
    "    \n",
    "def pad_sequence(sequences: Union[List[List[int]], Tuple[List[int]]], max_len: int, pad: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    -------\n",
    "        A numpy array padded with the 'pad' value until \n",
    "        the 'max_len' length. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sequences: Union[List[List[int]], Tuple[List[int]]]\n",
    "        A list or tuple of lists. \n",
    "\n",
    "    max_len: int\n",
    "        The length to which the input is padded.\n",
    "\n",
    "    pad: int\n",
    "        The padding value.\n",
    "    \"\"\"\n",
    "    array_sequences = np.full((len(sequences), max_len), pad, dtype=np.int64)\n",
    "\n",
    "    # Padding\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        array_sequences[i, :len(sequence)] = sequence\n",
    "\n",
    "    return array_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a3c2791",
   "metadata": {
    "id": "9a3c2791"
   },
   "outputs": [],
   "source": [
    "class Collator_Token_Classification:\n",
    "    \"\"\"\n",
    "    Collator for Token Classification.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        A dictionary of tensors of the batch sequences in input.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    device: str\n",
    "        Where (CPU/GPU) to load the features.\n",
    "        \n",
    "    pad: int\n",
    "        The padding token.\n",
    "\n",
    "    truncate_len: int\n",
    "        Maximum length possible in the batch.\n",
    "\n",
    "    labeled: bool\n",
    "        If the batch also contains the labels.\n",
    "    \"\"\"\n",
    "    def __init__(self, device: str, pad: int=0, \n",
    "                 truncate_len: int=512, labeled=True):\n",
    "        self.device = device\n",
    "        self.pad = pad\n",
    "        self.truncate_len = truncate_len\n",
    "        self.labeled = labeled\n",
    "        \n",
    "    def __call__(self, batch):\n",
    "\n",
    "        if self.labeled:\n",
    "            batch_features, batch_offsets, batch_labels = zip(*batch)\n",
    "\n",
    "        else:\n",
    "            batch_features, batch_offsets = zip(*batch)\n",
    "\n",
    "        max_len_features_in_batch = compute_max_len(batch_features, self.truncate_len)\n",
    "        max_len_offsets_in_batch = compute_max_len(batch_offsets, self.truncate_len)\n",
    "\n",
    "        collate_sample = {}\n",
    "        \n",
    "        # Features        \n",
    "        padded_features = pad_sequence(batch_features, max_len_features_in_batch, self.pad)\n",
    "        features_tensor = torch.tensor(padded_features, device=self.device)\n",
    "        collate_sample['features'] = features_tensor\n",
    "        \n",
    "        # Offsets\n",
    "        padded_offsets = pad_sequence(batch_offsets, max_len_offsets_in_batch, self.pad)\n",
    "        offsets_tensor = torch.tensor(padded_offsets, device=self.device)\n",
    "        collate_sample['offsets'] = offsets_tensor\n",
    "        \n",
    "        if not self.labeled:\n",
    "            return collate_sample\n",
    "\n",
    "        # Labels\n",
    "        padded_labels = pad_sequence(batch_labels, max_len_offsets_in_batch, self.pad)\n",
    "        labels_tensor = torch.tensor(padded_labels, dtype=torch.uint8, device=self.device)\n",
    "        collate_sample['labels'] = labels_tensor\n",
    "        \n",
    "        return collate_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8185e7a8",
   "metadata": {
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1660751850397,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "8185e7a8"
   },
   "outputs": [],
   "source": [
    "class Ambiguous_Detection_Head(nn.Module):\n",
    "    def __init__(self, bert_hidden_size: int, args: ModelArguments):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.args = args\n",
    "        self.bert_hidden_size = bert_hidden_size\n",
    "\n",
    "        input_size = bert_hidden_size\n",
    "        if args.output_strategy == \"concat\":\n",
    "            input_size *= 4\n",
    "\n",
    "        self.ffnn = nn.Sequential(\n",
    "            nn.Linear(input_size, args.head_hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(args.dropout),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(args.head_hidden_size, args.num_output)\n",
    "\n",
    "    def forward(self, bert_outputs, offsets):\n",
    "        embeddings = self._retrieve_pronouns_embeddings(bert_outputs, offsets)\n",
    "\n",
    "        x = self.ffnn(embeddings)\n",
    "\n",
    "\n",
    "        output = self.classifier(x)\n",
    "        return output\n",
    "    \n",
    "    def _retrieve_pronouns_embeddings(self, bert_embeddings: torch.Tensor, \n",
    "                                      pronouns_offsets: torch.Tensor):\n",
    "        \n",
    "        # bert_embeddings shape: batch_size x seq_length x embed_dim\n",
    "        # entities_and_pron_offsets shape: batch_size x seq_length\n",
    "\n",
    "        pronouns_embeddings = []\n",
    "        \n",
    "        # Consider embeddings and offsets in each batch separately\n",
    "        for embeddings, offsets in zip(bert_embeddings, pronouns_offsets):\n",
    "            pronouns_embeddings.append(embeddings[offsets])\n",
    "\n",
    "        # Merge outputs\n",
    "        merged_pronouns_embeddings = torch.stack(pronouns_embeddings, dim=0)\n",
    "        \n",
    "        # shape: batch_size x seq_length x embedding_dim\n",
    "        return merged_pronouns_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb7c679d",
   "metadata": {
    "executionInfo": {
     "elapsed": 372,
     "status": "ok",
     "timestamp": 1660751878734,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "eb7c679d"
   },
   "outputs": [],
   "source": [
    "class CR_Model(nn.Module):\n",
    "    \"\"\"The main model.\"\"\"\n",
    "\n",
    "    def __init__(self, bert_model: str, tokenizer, args: ModelArguments):\n",
    "        super().__init__()\n",
    "\n",
    "        self.args = args\n",
    "\n",
    "        if bert_model in {\"bert-base-uncased\", \"bert-base-cased\"}:\n",
    "            self.bert_hidden_size = 768\n",
    "        elif bert_model in {\"bert-large-uncased\", \"bert-large-cased\"}:\n",
    "            self.bert_hidden_size = 1024\n",
    "        else:\n",
    "            self.bert_hidden_size = args.bert_hidden_size\n",
    "\n",
    "        self.bert = BertModel.from_pretrained(\n",
    "            bert_model).to(device, non_blocking=True)\n",
    "        \n",
    "        # If the tag tokens (e.g., <p>, <a> etc.) are present in the features,\n",
    "        # the embedding dimension of the bert embeddings must be changed\n",
    "        # to be compliant with the new size of the tokenizer vocabulary. \n",
    "        if args.resize_embeddings:\n",
    "            self.bert.resize_token_embeddings(len(tokenizer.vocab))\n",
    "        \n",
    "        self.head = Ambiguous_Detection_Head(self.bert_hidden_size, args).to(\n",
    "            device, non_blocking=True) \n",
    "\n",
    "    def forward(self, sample):\n",
    "        x = sample['features']\n",
    "        x_offsets = sample['offsets']\n",
    "\n",
    "        bert_outputs = self.bert(\n",
    "            x, attention_mask=(x > 0).long(),\n",
    "            token_type_ids=None, output_hidden_states=True)\n",
    "\n",
    "        if self.args.output_strategy == \"last\":\n",
    "            out = bert_outputs.last_hidden_state\n",
    "\n",
    "        elif self.args.output_strategy == \"concat\":\n",
    "            out = torch.cat([bert_outputs.hidden_states[x] for x in [-1, -2, -3, -4]], dim=-1)\n",
    "\n",
    "        elif self.args.output_strategy == \"sum\":\n",
    "            layers_to_sum = torch.stack([bert_outputs.hidden_states[x] for x in [-1, -2, -3, -4]], dim=0)\n",
    "            out = torch.sum(layers_to_sum, dim=0)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported output strategy.\")\n",
    "\n",
    "        head_outputs = self.head(out, x_offsets)\n",
    "        return head_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a41065",
   "metadata": {
    "id": "21a41065"
   },
   "source": [
    "**Gradient Scaling**\n",
    "\n",
    "If the forward pass for a particular op has float16 inputs, the backward pass for that op will produce float16 gradients. Gradient values with small magnitudes may not be representable in float16. These values will flush to zero (“underflow”), so the update for the corresponding parameters will be lost.\n",
    "\n",
    "To prevent underflow, “gradient scaling” multiplies the network’s loss(es) by a scale factor and invokes a backward pass on the scaled loss(es). Gradients flowing backward through the network are then scaled by the same factor. In other words, gradient values have a larger magnitude, so they don’t flush to zero.\n",
    "\n",
    "The method `step(optimizer, *args, **kwargs)` internally invokes `unscale_(optimizer)`and if no inf/NaN gradients are found, invokes `optimizer.step()` using the unscaled gradients. Otherwise `optimizer.step()` is skipped to avoid corrupting the params.\n",
    "\n",
    "\\**Note for Gradient Clipping*\n",
    "\n",
    "If you wish to modify the gradients (like in gradient clipping), you should unscale them first. If you attempted to clip *without* unscaling, the gradients' norm magnitude would also be scaled, so your requested threshold would be invalid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e7bbea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenClassificationTrainer:    \n",
    "    def __init__(\n",
    "        self,\n",
    "        device: str,\n",
    "        model: nn.Module,\n",
    "        args: CustomTrainingArguments,\n",
    "        train_dataloader: DataLoader,\n",
    "        valid_dataloader: DataLoader,\n",
    "        criterion: torch.nn,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        scheduler: torch.optim.lr_scheduler = None,\n",
    "        pad: int = 0,\n",
    "    ):\n",
    "        \n",
    "        self.model = model\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.device = device\n",
    "        self.pad = pad\n",
    "        \n",
    "        assert args is not None, \"No training arguments passed!\"\n",
    "        self.args = args\n",
    "        \n",
    "    def train(self):\n",
    "        args = self.args\n",
    "        valid_dataloader = self.valid_dataloader\n",
    "        epochs = args.num_train_epochs\n",
    "        \n",
    "        train_losses = []\n",
    "        train_acc_list = []\n",
    "        valid_losses = []\n",
    "        valid_acc_list = []\n",
    "        \n",
    "        if args.use_early_stopping:\n",
    "            patience_counter = 0 \n",
    "\n",
    "        scaler = GradScaler() if args.use_scaler else None\n",
    "\n",
    "        training_start_time = time.time()\n",
    "        print(\"\\nTraining...\")\n",
    "        for epoch in range(epochs):\n",
    "            train_loss, train_acc = self._inner_training_loop(scaler)\n",
    "            train_losses.append(train_loss)\n",
    "            train_acc_list.append(train_acc)\n",
    "\n",
    "            valid_loss, valid_acc = self.evaluate(valid_dataloader)\n",
    "            valid_losses.append(valid_loss)\n",
    "            valid_acc_list.append(valid_acc)\n",
    "\n",
    "            if self.scheduler is not None:\n",
    "                self._print_sceduler_lr()\n",
    "                self.scheduler.step()\n",
    "\n",
    "            self._print_epoch_log(epoch, epochs, train_loss, valid_loss, valid_acc)\n",
    "\n",
    "            if args.use_early_stopping and len(valid_acc_list) >= 2:\n",
    "                stop, patience_counter = self._early_stopping(patience_counter, epoch, valid_acc_list)\n",
    "                if stop:\n",
    "                    break\n",
    "        \n",
    "        training_time = time.time() - training_start_time\n",
    "        print(f'Training time: {self._print_time(training_time)}')\n",
    "\n",
    "        metrics_history = {\n",
    "            \"train_losses\": train_losses,\n",
    "            \"train_acc\": train_acc_list,\n",
    "            \"valid_losses\": valid_losses,\n",
    "            \"valid_acc\": valid_acc_list,\n",
    "        }\n",
    "\n",
    "#         print(metrics_history)\n",
    "        if args.save_model:\n",
    "            self._save_model(args.task_type, epoch, valid_acc, scaler, metrics_history)\n",
    "    \n",
    "        return metrics_history\n",
    "\n",
    "    def _inner_training_loop(self, scaler):\n",
    "        args = self.args\n",
    "        train_dataloader = self.train_dataloader\n",
    "        \n",
    "        train_loss = 0.0\n",
    "        train_correct, total_count = 0.0, 0.0\n",
    "\n",
    "        self.model.train()\n",
    "        for step, sample in enumerate(train_dataloader):\n",
    "            ### Empty gradients ###\n",
    "            self.optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            ### Forward ###\n",
    "            if scaler is None:\n",
    "                predictions = self.model(sample)\n",
    "                labels = sample['labels']\n",
    "                train_correct, total_count = self.compute_metrics(predictions, labels, \n",
    "                                                              train_correct, total_count)\n",
    "                labels = labels.view(-1)\n",
    "                predictions = predictions.view(-1, predictions.shape[-1])\n",
    "                loss = self.criterion(predictions, labels)\n",
    "            else:\n",
    "                with torch.autocast(device_type=self.device):\n",
    "                    predictions = self.model(sample)\n",
    "                    labels = sample['labels']\n",
    "                    train_correct, total_count = self.compute_metrics(predictions, labels, \n",
    "                                                              train_correct, total_count)\n",
    "                    \n",
    "                    labels = labels.view(-1)\n",
    "                    predictions = predictions.view(-1, predictions.shape[-1])\n",
    "                    loss = self.criterion(predictions, labels)\n",
    "                    \n",
    "            \n",
    "            ### Backward  ###\n",
    "            if scaler is None:\n",
    "                loss.backward()\n",
    "            else: \n",
    "                # Backward pass without mixed precision\n",
    "                # It's not recommended to use mixed precision for backward pass\n",
    "                # Because we need more precise loss\n",
    "                scaler.scale(loss).backward()\n",
    "            \n",
    "            if args.grad_clipping is not None:\n",
    "                if scaler is not None:\n",
    "                    scaler.unscale_(self.optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), args.grad_clipping)\n",
    "            \n",
    "            ### Update weights ### \n",
    "            if scaler is None:\n",
    "                self.optimizer.step()\n",
    "            else:\n",
    "                scaler.step(self.optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            if step % args.logging_steps == args.logging_steps - 1:\n",
    "                running_loss = train_loss / (step + 1)\n",
    "                running_acc = train_correct / total_count\n",
    "                self._print_step_log(step, running_loss, running_acc)\n",
    "                \n",
    "        return train_loss / len(train_dataloader), train_correct / total_count\n",
    "  \n",
    "    def evaluate(self, eval_dataloader):\n",
    "        valid_loss = 0.0\n",
    "        eval_correct, total_count = 0, 0\n",
    "        \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for sample in eval_dataloader:\n",
    "                \n",
    "                predictions = self.model(sample)\n",
    "                labels = sample['labels']\n",
    "                eval_correct, total_count = self.compute_metrics(predictions, labels, \n",
    "                                                                 eval_correct, total_count)\n",
    "                \n",
    "                labels = labels.view(-1)\n",
    "                predictions = predictions.view(-1, predictions.shape[-1])\n",
    "                loss = self.criterion(predictions, labels)\n",
    "                valid_loss += loss.item()\n",
    "\n",
    "        \n",
    "        return valid_loss / len(eval_dataloader), eval_correct / total_count\n",
    "\n",
    "    def compute_metrics(self, predictions, labels, num_correct, total_count):  \n",
    "        # Iterate one batch at a time\n",
    "        for one_batch_predictions, one_batch_labels in zip(predictions, labels):\n",
    "            num_batch_correct, batch_count = 0.0, 0.0\n",
    "\n",
    "            mask = one_batch_labels != self.pad\n",
    "            one_batch_labels = one_batch_labels[mask]\n",
    "\n",
    "            one_batch_predictions = one_batch_predictions[mask]\n",
    "            maximum_logits, predicted_labels = one_batch_predictions.max(1)\n",
    "\n",
    "            # It may happen that more than one pronoun is classify as ambiguous\n",
    "            multiple_ambiguous_pronouns_mask = predicted_labels == 2\n",
    "            ambiguous_pronouns_logits = maximum_logits[multiple_ambiguous_pronouns_mask]\n",
    "\n",
    "            # More than one pronoun is classify as ambiguous\n",
    "            if len(ambiguous_pronouns_logits) > 1:\n",
    "                # Get the highest logit among the ambiguous ones\n",
    "                highest_ambiguous_pronoun_logit = ambiguous_pronouns_logits.max()\n",
    "\n",
    "                # Identity the position of the logit that should correspond to the ambiguous prononun class (2)\n",
    "                ambiguous_pronoun_mask = maximum_logits == highest_ambiguous_pronoun_logit\n",
    "\n",
    "                # All the predictions that are not of that class are set to the \"not ambiguous class\" (1)\n",
    "                predicted_labels[~ambiguous_pronoun_mask] = 1\n",
    "\n",
    "                # However, it may happen again that we have multiple pronouns classified as ambiguous, \n",
    "                # since there may be more than one logit with value = highest_ambiguous_pronoun_logit\n",
    "\n",
    "\n",
    "            # When the model predicts that all the pronouns are not ambiguous (no class 2)\n",
    "            if not torch.any(predicted_labels == 2):\n",
    "                # Try to select the most probable ambiguous pronoun\n",
    "\n",
    "                probable_ambiguous_index = one_batch_predictions[:,-1].argmax(dim=0)\n",
    "                predicted_labels[probable_ambiguous_index] = 2\n",
    "\n",
    "            label_ambiguous_mask = one_batch_labels == 2\n",
    "            num_batch_correct += (one_batch_labels[label_ambiguous_mask] == predicted_labels[label_ambiguous_mask]).sum().item()\n",
    "            batch_count += 1\n",
    "        \n",
    "        num_correct += num_batch_correct\n",
    "        total_count += batch_count\n",
    "    \n",
    "        return num_correct, total_count\n",
    "\n",
    "    def _early_stopping(self, patience_counter, epoch, valid_acc_list):\n",
    "        args = self.args\n",
    "\n",
    "        # stop = args.early_stopping_mode == 'min' and epoch > 0 and valid_acc_list[-1] > valid_acc_list[-2]\n",
    "        stop = args.early_stopping_mode == 'max' and epoch > 0 and valid_acc_list[-1] < valid_acc_list[-2]\n",
    "        if stop:\n",
    "            if patience_counter >= args.early_stopping_patience:\n",
    "                print('Early stop.')\n",
    "                return stop, patience_counter\n",
    "            else:\n",
    "                print('-- Patience.\\n')\n",
    "                patience_counter += 1\n",
    "\n",
    "        return False, patience_counter   \n",
    "    \n",
    "    def _print_time(self, s):\n",
    "        m = math.floor(s / 60)\n",
    "        s -= m * 60\n",
    "        return '%dm %ds' % (m, s)\n",
    "\n",
    "    def _print_sceduler_lr(self):\n",
    "        print('-' * 17)\n",
    "        print(f\"| LR: {self.scheduler.get_last_lr()[0]:.3e} |\")\n",
    "\n",
    "    def _print_step_log(self, step, running_loss, running_acc):\n",
    "        print(f'\\t| step {step+1:4d}/{len(self.train_dataloader):d} | train_loss: {running_loss:.3f} | ' \\\n",
    "                f'train_acc: {running_acc:.3f} |')\n",
    "\n",
    "    def _print_epoch_log(self, epoch, epochs, train_loss, valid_loss, valid_acc):\n",
    "        print('-' * 76)\n",
    "        print(f'| epoch {epoch+1:>3d}/{epochs:<3d} | train_loss: {train_loss:.3f} | ' \\\n",
    "                f'valid_loss: {valid_loss:.3f} | valid_acc: {valid_acc:.3f} |')\n",
    "        print('-' * 76)\n",
    "        \n",
    "    \n",
    "    def _save_model(self, task_type, epoch, valid_acc, scaler, metrics_history):\n",
    "        print(\"Saving model...\")\n",
    "        params_to_save = {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": self.model.state_dict(),\n",
    "            \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "            \"metrics_history\": metrics_history,\n",
    "        }\n",
    "        \n",
    "        if self.scheduler is not None:\n",
    "            params_to_save[\"scheduler_state_dict\"] = self.scheduler.state_dict()\n",
    "            \n",
    "        if scaler is not None:\n",
    "            params_to_save[\"scaler_state_dict\"] = scaler.state_dict()\n",
    "            \n",
    "        save_path = f\"{self.args.output_dir}my_model{str(task_type)}_{str(valid_acc)[2:5]}_{epoch+1}\"\n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H-%M-%S\")\n",
    "        \n",
    "        if os.path.exists(f\"{save_path}_{current_time}.pth\"):\n",
    "            torch.save(params_to_save, f\"{save_path}_{current_time}_new.pth\")\n",
    "        else:\n",
    "            torch.save(params_to_save, f\"{save_path}_{current_time}.pth\")\n",
    "        \n",
    "        print(\"Model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7a11aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_weights(modules):\n",
    "    for module in modules:\n",
    "        for param in module.parameters():\n",
    "            if hasattr(param, 'requires_grad'):\n",
    "                param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31aa4455",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2064,
     "status": "ok",
     "timestamp": 1660753117653,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "31aa4455",
    "outputId": "790097d0-16fa-439c-b121-325837a47121",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomTrainingArguments(output_dir='../../model/checkpoints/', task_type=1, save_model=False, num_train_epochs=2, logging_steps=250, learning_rate=5e-06, grad_clipping=None, use_early_stopping=True, early_stopping_mode='max', early_stopping_patience=2, use_scaler=True)\n"
     ]
    }
   ],
   "source": [
    "model = CR_Model(model_name_or_path, tokenizer, model_args).to(device, non_blocking=True)\n",
    "\n",
    "# last_frozen_layer = 12\n",
    "# modules = [model.bert.embeddings, *model.bert.encoder.layer[:last_frozen_layer]]\n",
    "# # modules = [*model.bert.encoder.layer[:last_frozen_layer]]\n",
    "# freeze_weights(modules)\n",
    "\n",
    "yaml_file = \"./train_notebook2.yaml\"\n",
    "# Read configuration file with all the necessary parameters\n",
    "with open(yaml_file) as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    \n",
    "training_args = CustomTrainingArguments(**config['training_args'])\n",
    "\n",
    "# Make sure that the learning rate is read as a number and not as a string\n",
    "training_args.learning_rate = float(training_args.learning_rate)\n",
    "print(training_args)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor([0, 0.1, 0.9]), ignore_index=0).to(device=device, non_blocking=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=training_args.learning_rate)\n",
    "# scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.1)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "scheduler = None\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "collator = Collator_Token_Classification(device)\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, \n",
    "                              collate_fn=collator, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_ds, batch_size=batch_size, \n",
    "                              collate_fn=collator, shuffle=False)\n",
    "\n",
    "trainer = TokenClassificationTrainer(str(device), model, training_args, \n",
    "                  train_dataloader, valid_dataloader, \n",
    "                  criterion, optimizer, scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7c8f03a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 735134,
     "status": "ok",
     "timestamp": 1660753855156,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "e7c8f03a",
    "outputId": "8349c872-e0c2-4428-f04b-6ed2f8496ffc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training...\n",
      "\t| step  250/750 | train_loss: 0.431 | train_acc: 0.684 |\n",
      "\t| step  500/750 | train_loss: 0.322 | train_acc: 0.768 |\n",
      "\t| step  750/750 | train_loss: 0.271 | train_acc: 0.807 |\n",
      "----------------------------------------------------------------------------\n",
      "| epoch   1/2   | train_loss: 0.271 | valid_loss: 0.166 | valid_acc: 0.877 |\n",
      "----------------------------------------------------------------------------\n",
      "\t| step  250/750 | train_loss: 0.119 | train_acc: 0.944 |\n",
      "\t| step  500/750 | train_loss: 0.114 | train_acc: 0.936 |\n",
      "\t| step  750/750 | train_loss: 0.109 | train_acc: 0.943 |\n",
      "----------------------------------------------------------------------------\n",
      "| epoch   2/2   | train_loss: 0.109 | valid_loss: 0.120 | valid_acc: 0.912 |\n",
      "----------------------------------------------------------------------------\n",
      "Training time: 4m 49s\n"
     ]
    }
   ],
   "source": [
    "metrics_history = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3280693e",
   "metadata": {
    "id": "3280693e"
   },
   "outputs": [],
   "source": [
    "metrics_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "449e8539",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_list = []\n",
    "y_pred_list = []\n",
    "logits = []\n",
    "\n",
    "eval_correct, total_count = 0.0, 0.0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    collator = Collator_Token_Classification(device)\n",
    "    dataloader = DataLoader(valid_ds, batch_size=1, collate_fn=collator, shuffle=False)\n",
    "    for idx, sample in enumerate(dataloader):\n",
    "        predictions = model(sample)\n",
    "        labels = sample['labels']\n",
    "  \n",
    "        # Iterate one batch at a time\n",
    "        for one_batch_predictions, one_batch_labels in zip(predictions, labels):\n",
    "            eval_batch_correct, batch_count = 0.0, 0.0\n",
    "            logits.append(one_batch_predictions)\n",
    "\n",
    "            mask = one_batch_labels != 0\n",
    "            one_batch_labels = one_batch_labels[mask]\n",
    "            y_true_list.append(one_batch_labels.tolist())\n",
    "\n",
    "            one_batch_predictions = one_batch_predictions[mask]\n",
    "            maximum_logits, predicted_labels = one_batch_predictions.max(1)\n",
    "\n",
    "            # It may happen that more than one pronoun is classify as ambiguous\n",
    "            multiple_ambiguous_pronouns_mask = predicted_labels == 2\n",
    "            ambiguous_pronouns_logits = maximum_logits[multiple_ambiguous_pronouns_mask]\n",
    "\n",
    "            # More than one pronoun is classify as ambiguous\n",
    "            if len(ambiguous_pronouns_logits) > 1:\n",
    "                # Get the highest logit among the ambiguous ones\n",
    "                highest_ambiguous_pronoun_logit = ambiguous_pronouns_logits.max()\n",
    "\n",
    "                # Identity the position of the logit that should correspond to the ambiguous prononun class (2)\n",
    "                ambiguous_pronoun_mask = maximum_logits == highest_ambiguous_pronoun_logit\n",
    "\n",
    "                # All the predictions that are not of that class are set to the \"not ambiguous class\" (1)\n",
    "                predicted_labels[~ambiguous_pronoun_mask] = 1\n",
    "\n",
    "                # However, it may happen again that we have multiple pronouns classified as ambiguous, \n",
    "                # since there may be more than one logit with value = highest_ambiguous_pronoun_logit\n",
    "\n",
    "\n",
    "            # When the model predicts that all the pronouns are not ambiguous (no class 2)\n",
    "            if not torch.any(predicted_labels == 2):\n",
    "                # Try to select the most probable ambiguous pronoun\n",
    "                probable_ambiguous_index = one_batch_predictions[:,-1].argmax(dim=0)\n",
    "                predicted_labels[probable_ambiguous_index] = 2\n",
    "\n",
    "\n",
    "            y_pred_list.append(predicted_labels.tolist())\n",
    "\n",
    "\n",
    "            label_ambiguous_mask = one_batch_labels == 2\n",
    "            eval_batch_correct += (one_batch_labels[label_ambiguous_mask] == predicted_labels[label_ambiguous_mask]).sum().item()\n",
    "            batch_count += 1\n",
    "        \n",
    "        eval_correct += eval_batch_correct\n",
    "        total_count += batch_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e408582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "413.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e81905b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "454.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da6da556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9096916299559471"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_correct / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f5e693",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Training.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.7 (DL)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
