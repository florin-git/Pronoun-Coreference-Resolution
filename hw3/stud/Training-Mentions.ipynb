{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wIOz40JYJddq",
   "metadata": {
    "id": "wIOz40JYJddq"
   },
   "outputs": [],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3244dc15",
   "metadata": {
    "executionInfo": {
     "elapsed": 5489,
     "status": "ok",
     "timestamp": 1660751770217,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "3244dc15"
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    Trainer,\n",
    "    BertTokenizer,\n",
    "    AutoTokenizer,\n",
    "    BertConfig,\n",
    "    BertModel,\n",
    ")\n",
    "import transformers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import stanza\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import yaml\n",
    "import dill as pickle\n",
    "from typing import *\n",
    "from datetime import datetime\n",
    "from collections import namedtuple\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "SEED = 10\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Display the entire text\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1494436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stanza.download('en', processors='tokenize,pos')\n",
    "# stanza.download(lang=\"en\",package=None,processors={\"ner\":\"ontonotes\"})\n",
    "# stanza.download('en', processors='constituency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58276aa2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 259,
     "status": "ok",
     "timestamp": 1660751781007,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "58276aa2",
    "outputId": "150bbcf1-dbcd-480d-9e85-82e77346e83f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "model_name_or_path = \"bert-base-cased\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "kYGIp3MoJug2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15143,
     "status": "ok",
     "timestamp": 1660751806072,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "kYGIp3MoJug2",
    "outputId": "aad7d923-b163-4609-93a9-a07790cbfba2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "QFqvmoaqhbyn",
   "metadata": {
    "executionInfo": {
     "elapsed": 1526,
     "status": "ok",
     "timestamp": 1660751810222,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "QFqvmoaqhbyn"
   },
   "outputs": [],
   "source": [
    "curr_location = \"/content/drive/MyDrive/Colab Notebooks/Deep Learning/NLP/nlp2022-hw3/hw3/stud/\"\n",
    "os.chdir(curr_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fM1EDyRLifxE",
   "metadata": {
    "executionInfo": {
     "elapsed": 1348,
     "status": "ok",
     "timestamp": 1660751818200,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "fM1EDyRLifxE"
   },
   "outputs": [],
   "source": [
    "from arguments import CustomTrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3633ef51",
   "metadata": {
    "executionInfo": {
     "elapsed": 279,
     "status": "ok",
     "timestamp": 1660751819788,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "3633ef51"
   },
   "outputs": [],
   "source": [
    "train_clean_path = \"../../model/data/train_clean.tsv\"\n",
    "valid_clean_path = \"../../model/data/valid_clean.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "B1CvSmUrKc1y",
   "metadata": {
    "executionInfo": {
     "elapsed": 1177,
     "status": "ok",
     "timestamp": 1660751822725,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "B1CvSmUrKc1y"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(filepath_or_buffer=train_clean_path, sep=\"\\t\")\n",
    "df_valid = pd.read_csv(filepath_or_buffer=valid_clean_path, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677693f1",
   "metadata": {},
   "source": [
    "Is a token classification: for each token I need to say if it is ambiguous or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4ccf9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I should introduce a mention tag for the pronoun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f5ec9c1",
   "metadata": {
    "id": "1f5ec9c1"
   },
   "outputs": [],
   "source": [
    "FEMININE = 0\n",
    "MASCULINE = 1\n",
    "UNKNOWN = 2\n",
    "\n",
    "def get_gender(pronoun: str):\n",
    "    gender_mapping = {\n",
    "        'she': FEMININE,\n",
    "        'her': FEMININE,\n",
    "        'he': MASCULINE,\n",
    "        'his': MASCULINE,\n",
    "        'him': MASCULINE,\n",
    "    }\n",
    "\n",
    "    return gender_mapping.get(pronoun.lower(), UNKNOWN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfba488",
   "metadata": {},
   "source": [
    "# For training don't consider neither"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45423e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAP_AmbiguousDetection_Dataset(Dataset):\n",
    "    \"\"\"Custom GAP Dataset class\"\"\"\n",
    "\n",
    "    def __init__(self, df, tokenizer, stanza_processor, tag_labels, labeled=True):\n",
    "        self.df = df\n",
    "\n",
    "        self.labeled = labeled\n",
    "        self.tokenizer = tokenizer\n",
    "        self.stanza_processor = stanza_processor\n",
    "        self.tag_labels = tag_labels\n",
    "        \n",
    "        self.samples = []\n",
    "        self._convert_tokens_to_ids()\n",
    "        \n",
    "        \n",
    "    def _assign_class_to_tokens(self, entities_offsets, coreferent_ent_offset):\n",
    "        labels = []\n",
    "        for offset in entities_offsets:\n",
    "            if coreferent_ent_offset is not None and offset == coreferent_ent_offset[0]:\n",
    "                labels.append(2)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "                \n",
    "        return labels  \n",
    "        \n",
    "    def _convert_tokens_to_ids(self):\n",
    "        CLS = [self.tokenizer.cls_token]\n",
    "        SEP = [self.tokenizer.sep_token]\n",
    "        \n",
    "        tag_labels = self.tag_labels\n",
    "        pronoun_tag = tag_labels['pronoun_tag']\n",
    "        start_entity_tag = tag_labels['start_entity_tag']\n",
    "        end_entity_tag = tag_labels['end_entity_tag']\n",
    "        start_coref_entity_tag = tag_labels['start_coref_entity_tag']\n",
    "        end_coref_entity_tag = tag_labels['end_coref_entity_tag']\n",
    "        \n",
    "        Sample = namedtuple(\"Sample\", ['tokens', 'start_entities_offsets', 'end_entities_offsets', 'coreferent_ent_offset', 'ambiguous_pron_offset'])\n",
    "        if self.labeled:\n",
    "            Sample = namedtuple(\"Sample\", Sample._fields + (\"labels\",))\n",
    "\n",
    "        for _, row in self.df.iterrows():\n",
    "            coreferent_ent_offset_tuple = None\n",
    "            tokens, entities_offsets = self.tokenize(row)\n",
    "            tokens_to_convert = CLS + tokens + SEP\n",
    "            sample = {'tokens': self.tokenizer.convert_tokens_to_ids(tokens_to_convert)}\n",
    "            \n",
    "            # Because of the introduction of CLS we have to add 1 to the offsets\n",
    "            if entities_offsets[pronoun_tag]:\n",
    "                sample['ambiguous_pron_offset'] = entities_offsets[pronoun_tag][0] + 1\n",
    "            if entities_offsets[start_coref_entity_tag]:\n",
    "                coreferent_ent_offset_tuple = (entities_offsets[start_coref_entity_tag][0] + 1, \n",
    "                                               entities_offsets[end_coref_entity_tag][0] + 1)\n",
    " \n",
    "            sample['coreferent_ent_offset'] = coreferent_ent_offset_tuple\n",
    "\n",
    "            start_entities_offsets = [off + 1 for off in entities_offsets[start_entity_tag]]\n",
    "            end_entities_offsets = [off + 1 for off in entities_offsets[end_entity_tag]]\n",
    "\n",
    "            \n",
    "            # all_entities_offsets = list(zip([off + 1 for off in entities_offsets[start_entity_tag]], \n",
    "            #                                 [off + 1 for off in entities_offsets[end_entity_tag]]))\n",
    "\n",
    "            if coreferent_ent_offset_tuple is not None:\n",
    "                # Add coreferent mention offsets\n",
    "                start_entities_offsets = sorted(start_entities_offsets + [coreferent_ent_offset_tuple[0]])\n",
    "                end_entities_offsets = sorted(end_entities_offsets + [coreferent_ent_offset_tuple[1]])\n",
    "                # all_entities_offsets = sorted(all_entities_offsets + [coreferent_ent_offset_tuple])\n",
    "            \n",
    "            # sample['all_entities_offsets'] = all_entities_offsets\n",
    "            sample['start_entities_offsets'] = start_entities_offsets\n",
    "            sample['end_entities_offsets'] = end_entities_offsets\n",
    "            \n",
    "\n",
    "\n",
    "            if self.labeled:\n",
    "                # sample['labels'] = self._assign_class_to_tokens(all_entities_offsets, coreferent_ent_offset_tuple)\n",
    "                sample['labels'] = self._assign_class_to_tokens(start_entities_offsets, coreferent_ent_offset_tuple)\n",
    "\n",
    "            sample_namedtuple = Sample(**sample)\n",
    "            self.samples.append(sample_namedtuple)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_coreferent_entity_offset(row):\n",
    "        not_coref_A = row[\"is_coref_A\"] in [\"FALSE\", False]\n",
    "        not_coref_B = row[\"is_coref_B\"] in [\"FALSE\", False]\n",
    "        if not_coref_A and not_coref_B:\n",
    "            return -1\n",
    "        is_coref_A = row[\"is_coref_A\"] in [\"TRUE\", True]\n",
    "        return row[\"offset_A\"] if is_coref_A else row[\"offset_B\"]\n",
    "    \n",
    "    def _delimit_entities(self, row):\n",
    "        \n",
    "        text = row['text']\n",
    "        pronoun_offset = row['p_offset']\n",
    "\n",
    "        coreferent_entity_offset = -1\n",
    "        if self.labeled:\n",
    "            coreferent_entity_offset = self.get_coreferent_entity_offset(row)\n",
    "        \n",
    "        # Parse the text using 'stanza'\n",
    "        doc_processed = self.stanza_processor(text)\n",
    "        \n",
    "        tag_labels = self.tag_labels\n",
    "        pronoun_tag = tag_labels['pronoun_tag']\n",
    "        start_entity_tag = tag_labels['start_entity_tag']\n",
    "        end_entity_tag = tag_labels['end_entity_tag']\n",
    "        start_coref_entity_tag = tag_labels['start_coref_entity_tag']\n",
    "        end_coref_entity_tag = tag_labels['end_coref_entity_tag']\n",
    "         \n",
    "#         offsets = []\n",
    "        count_entities = 0\n",
    "\n",
    "        # Insert pronoun tag\n",
    "        text = self._insert_tag(text, (pronoun_offset, None), pronoun_tag)\n",
    "\n",
    "        # Number of characters inserted to delimit an entity\n",
    "        len_tags = len(start_entity_tag) + len(end_entity_tag)\n",
    "\n",
    "        for ent in doc_processed.ents:\n",
    "            if ent.type == \"PERSON\":\n",
    "                # For every tag inserted we have to shift the offsets by the tag length\n",
    "                start_off = ent.start_char + len_tags*count_entities\n",
    "                end_off = ent.end_char + len_tags*count_entities\n",
    "\n",
    "                \n",
    "                # Because of the new tags, also the pronoun and the coreferent entity offsets are shifted\n",
    "                current_coreferent_entity_offset = coreferent_entity_offset + len_tags*count_entities\n",
    "                current_pronoun_offset = pronoun_offset + len_tags*count_entities\n",
    "                if start_off > current_pronoun_offset:\n",
    "                    start_off += len(pronoun_tag)\n",
    "                    end_off += len(pronoun_tag)\n",
    "                    current_coreferent_entity_offset += len(pronoun_tag)\n",
    "\n",
    "#                 offsets.append((start_off, end_off))\n",
    "                \n",
    "                # In order to identify the coreferent entity, I use special tags\n",
    "                if coreferent_entity_offset != -1 and start_off == current_coreferent_entity_offset:\n",
    "                    text = self._insert_tag(text, (start_off, end_off), start_coref_entity_tag, end_coref_entity_tag)\n",
    "\n",
    "                else:\n",
    "                    text = self._insert_tag(text, (start_off, end_off), start_entity_tag, end_entity_tag)\n",
    "                \n",
    "                count_entities += 1\n",
    "        \n",
    "        return text\n",
    "        \n",
    "\n",
    "    def _insert_tag(self, text, offsets, start_tag: str, end_tag: str = None):\n",
    "        start_off, end_off = offsets \n",
    "\n",
    "        # Starting tag only\n",
    "        if end_tag is None:\n",
    "            text = text[:start_off] + start_tag + text[start_off:]\n",
    "            return text\n",
    "\n",
    "        text = text[:start_off] + start_tag + text[start_off:end_off] + end_tag + text[end_off:]\n",
    "        return text\n",
    "    \n",
    "    \n",
    "    def tokenize(self, row):\n",
    "        final_tokens = []\n",
    "        tag_labels = self.tag_labels\n",
    "        entities_offsets = {tag: [] for tag in tag_labels.values()}\n",
    "        \n",
    "        start_entity_tag = tag_labels['start_entity_tag']\n",
    "        end_entity_tag = tag_labels['end_entity_tag']\n",
    "        start_coref_entity_tag = tag_labels['start_coref_entity_tag']\n",
    "        end_coref_entity_tag = tag_labels['end_coref_entity_tag']\n",
    "\n",
    "\n",
    "        text = self._delimit_entities(row)\n",
    "        \n",
    "        for token in self.tokenizer.tokenize(text):       \n",
    "            if token in [*tag_labels.values()]:\n",
    "                entities_offsets[token].append(len(final_tokens)) \n",
    "                continue\n",
    "            \n",
    "            # Replace the special tags with the general entity tags \n",
    "            if token == start_coref_entity_tag:\n",
    "                final_tokens.append(start_entity_tag)\n",
    "\n",
    "            elif token == end_coref_entity_tag:\n",
    "                final_tokens.append(end_entity_tag)\n",
    "\n",
    "            else:\n",
    "                final_tokens.append(token)\n",
    "\n",
    "        return final_tokens, entities_offsets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3a63d4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_neither_ent = df_train.loc[(df_train['is_coref_A'] == False) & (df_train['is_coref_B'] == False)]\n",
    "# df_train_trues = df_train.loc[(df_train['is_coref_A'] == True) | (df_train['is_coref_B'] == True)]\n",
    "# df_valid_trues = df_valid.loc[(df_valid['is_coref_A'] == True) | (df_valid['is_coref_B'] == True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e97196f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_neither_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bdf09b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_labels = {\n",
    "    \"pronoun_tag\": \"<P>\",\n",
    "    \"start_entity_tag\": \"<E>\",\n",
    "    \"end_entity_tag\": \"</E>\",\n",
    "    \"start_coref_entity_tag\": \"<C>\",\n",
    "    \"end_coref_entity_tag\": \"</C>\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6844631",
   "metadata": {
    "id": "e6844631"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-27 10:38:57 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2022-08-27 10:38:57 INFO: Use device: gpu\n",
      "2022-08-27 10:38:57 INFO: Loading: tokenize\n",
      "2022-08-27 10:39:00 INFO: Loading: ner\n",
      "2022-08-27 10:39:00 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"../../model/tokenizer/\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "stanza_processor = stanza.Pipeline(lang='en', processors='tokenize,ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7997cbe1",
   "metadata": {
    "executionInfo": {
     "elapsed": 5692,
     "status": "ok",
     "timestamp": 1660751846338,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "7997cbe1"
   },
   "outputs": [],
   "source": [
    "train_ds = GAP_AmbiguousDetection_Dataset(df_train[:50], tokenizer, stanza_processor, tag_labels)\n",
    "valid_ds = GAP_AmbiguousDetection_Dataset(df_valid[:30], tokenizer, stanza_processor, tag_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02cca986",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_save_path = \"../../model/datasets/train_no_tags.ds\"\n",
    "valid_ds_save_path = \"../../model/datasets/valid_no_tags.ds\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df910ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(train_ds_save_path, 'wb') as file:\n",
    "#     pickle.dump(train_ds, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41a61db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(valid_ds_save_path, 'wb') as file:\n",
    "#     pickle.dump(valid_ds, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f24b1266",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_ds_save_path, 'rb') as file:\n",
    "    train_ds = pickle.load(file)\n",
    "\n",
    "with open(valid_ds_save_path, 'rb') as file:\n",
    "    valid_ds = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "accf23c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Reb Chaim Yaakov's wife is the sister of Rabbi Moishe Sternbuch, as is the wife of Rabbi Meshulam Dovid Soloveitchik, making the two Rabbis his uncles. Reb Asher's brother Rabbi Shlomo Arieli is the author of a critical edition of the novallae of Rabbi Akiva Eiger. Before his marriage, Rabbi Arieli studied in the Ponevezh Yeshiva headed by Rabbi Shmuel Rozovsky, and he later studied under his father-in-law in the Mirrer Yeshiva.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 6\n",
    "sent = df_train['text'][idx]\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5e55e644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                                                                                                                                                                                                                                                                                                                                                                                                               train-1\n",
       "text          Zoe Telford -- played the police officer girlfriend of Simon, Maggie. Dumped by Simon in the final episode of series 1, after he slept with Jenny, and is not seen again. Phoebe Thomas played Cheryl Cassidy, Pauline's friend and also a year 11 pupil in Simon's class. Dumped her boyfriend following Simon's advice after he wouldn't have sex with her but later realised this was due to him catching crabs off her friend Pauline.\n",
       "pron                                                                                                                                                                                                                                                                                                                                                                                                                                                 her\n",
       "p_offset                                                                                                                                                                                                                                                                                                                                                                                                                                             274\n",
       "entity_A                                                                                                                                                                                                                                                                                                                                                                                                                                  Cheryl Cassidy\n",
       "offset_A                                                                                                                                                                                                                                                                                                                                                                                                                                             191\n",
       "is_coref_A                                                                                                                                                                                                                                                                                                                                                                                                                                          True\n",
       "entity_B                                                                                                                                                                                                                                                                                                                                                                                                                                         Pauline\n",
       "offset_B                                                                                                                                                                                                                                                                                                                                                                                                                                             207\n",
       "is_coref_B                                                                                                                                                                                                                                                                                                                                                                                                                                         False\n",
       "url                                                                                                                                                                                                                                                                                                                                                                              http://en.wikipedia.org/wiki/List_of_Teachers_(UK_TV_series)_characters\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dbeafb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n",
      "1281\n",
      "1730\n",
      "2309\n",
      "2472\n",
      "2592\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_ds)):\n",
    "    if len(train_ds[i].labels) == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d85d4946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lemhouse entered school to pursue a degree in Visual Communications (Graphic Design). Upon finishing school he started Lemhouse Design.'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[209:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eedaa5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sample(tokens=[101, 3414, 4934, 1968, 1144, 1145, 1125, 4374, 3573, 1107, 1199, 1476, 2441, 117, 1259, 7206, 3089, 1399, 117, 4266, 1399, 113, 2679, 114, 117, 21129, 113, 2678, 114, 117, 1109, 8947, 1183, 10341, 113, 2573, 114, 117, 12050, 1106, 9322, 2706, 113, 2573, 114, 117, 19869, 112, 18653, 1693, 113, 2477, 114, 117, 1109, 2896, 12853, 2772, 113, 2424, 114, 117, 3369, 112, 5581, 113, 2449, 114, 117, 1109, 1130, 118, 12077, 113, 2333, 114, 117, 2185, 1335, 1752, 27400, 1162, 113, 2253, 114, 117, 1109, 4254, 20092, 3291, 4455, 1513, 1107, 1738, 113, 2253, 114, 117, 1422, 17037, 2772, 113, 2278, 114, 117, 1109, 5135, 1104, 9859, 13335, 7008, 113, 1997, 114, 1105, 138, 3921, 20840, 113, 1630, 114, 119, 2611, 1107, 29000, 1123, 1578, 117, 1131, 1310, 3679, 3176, 119, 102], start_entities_offsets=[], end_entities_offsets=[], coreferent_ent_offset=None, ambiguous_pron_offset=125, labels=[])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b31404c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'her'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(1123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8d5fc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_tag(text, offsets, start_tag: str, end_tag: str = None):\n",
    "    start_off, end_off = offsets \n",
    "\n",
    "    # Starting tag only\n",
    "    if end_tag is None:\n",
    "        text = text[:start_off] + start_tag + text[start_off:]\n",
    "        return text\n",
    "\n",
    "    text = text[:start_off] + start_tag + text[start_off:end_off] + end_tag + text[end_off:]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4013eb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<E>Reb Chaim Yaakov's</E> wife is the sister of <E>Rabbi Moishe Sternbuch</E>, as is the wife of <E>Rabbi Meshulam Dovid Soloveitchik</E>, making the two Rabbis his uncles. <E>Reb Asher's</E> brother <E>Rabbi Shlomo Arieli</E> is the author of a critical edition of the novallae of <E>Rabbi Akiva Eiger</E>. Before <P>his marriage, <E>Rabbi Arieli</E> studied in the Ponevezh Yeshiva headed by <E>Rabbi Shmuel Rozovsky</E>, and he later studied under his father-in-law in the Mirrer Yeshiva.\""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = sent\n",
    "pronoun_offset = df_train['p_offset'][idx]\n",
    "coref_ds = df_train.iloc[idx]\n",
    "coreferent_entity_offset = GAP_AmbiguousDetection_Dataset.get_coreferent_entity_offset(coref_ds)\n",
    "# coreferent_entity_offset = -1\n",
    "# Parse the text using 'stanza'\n",
    "doc_processed = stanza_processor(text)\n",
    "\n",
    "pronoun_tag = tag_labels['pronoun_tag']\n",
    "start_entity_tag = tag_labels['start_entity_tag']\n",
    "end_entity_tag = tag_labels['end_entity_tag']\n",
    "start_coref_entity_tag = tag_labels['start_coref_entity_tag']\n",
    "end_coref_entity_tag = tag_labels['end_coref_entity_tag']\n",
    "    \n",
    "#         offsets = []\n",
    "count_entities = 0\n",
    "\n",
    "# Insert pronoun tag\n",
    "text = insert_tag(text, (pronoun_offset, None), pronoun_tag)\n",
    "\n",
    "# Number of characters inserted to delimit an entity\n",
    "len_tags = len(start_entity_tag) + len(end_entity_tag)\n",
    "doc_processed = stanza_processor(sent)\n",
    "\n",
    "for ent in doc_processed.ents:\n",
    "    if ent.type == \"PERSON\":\n",
    "        # For every tag inserted we have to shift the offsets by the tag length\n",
    "        start_off = ent.start_char + len_tags*count_entities\n",
    "        end_off = ent.end_char + len_tags*count_entities\n",
    "\n",
    "        \n",
    "        # Because of the new tags, also the pronoun and the coreferent entity offsets are shifted\n",
    "        current_coreferent_entity_offset = coreferent_entity_offset + len_tags*count_entities\n",
    "        current_pronoun_offset = pronoun_offset + len_tags*count_entities\n",
    "        if start_off > current_pronoun_offset:\n",
    "            start_off += len(pronoun_tag)\n",
    "            end_off += len(pronoun_tag)\n",
    "            current_coreferent_entity_offset += len(pronoun_tag)\n",
    "\n",
    "#                 offsets.append((start_off, end_off))\n",
    "        \n",
    "        # In order to identify the coreferent entity, I use special tags\n",
    "        if coreferent_entity_offset != -1 and start_off == current_coreferent_entity_offset:\n",
    "            text = insert_tag(text, (start_off, end_off), start_coref_entity_tag, end_coref_entity_tag)\n",
    "\n",
    "        else:\n",
    "            text = insert_tag(text, (start_off, end_off), start_entity_tag, end_entity_tag)\n",
    "        \n",
    "        count_entities += 1\n",
    "\n",
    "text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13177dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for e in doc_processed.ents:\n",
    "#     print(e) if e.type == \"ORG\" else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03da7b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print([(ent.text, ent.type )for ent in doc_processed.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "38c62c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    entities_offsets = {tag: [] for tag in tag_labels.values()}\n",
    "    final_tokens = []\n",
    "    \n",
    "    start_entity_tag = tag_labels['start_entity_tag']\n",
    "    end_entity_tag = tag_labels['end_entity_tag']\n",
    "    start_coref_entity_tag = tag_labels['start_coref_entity_tag']\n",
    "    end_coref_entity_tag = tag_labels['end_coref_entity_tag']\n",
    "\n",
    "    \n",
    "    for token in tokenizer.tokenize(text):\n",
    "        # Replace the special tags with the general entity tags\n",
    "        if token in [*tag_labels.values()]:\n",
    "            # If end tag, append the index of previous token\n",
    "#             if \"/\" in token:\n",
    "#                 entities_offsets[token].append(len(final_tokens) - 1)\n",
    "\n",
    "#             else:\n",
    "            entities_offsets[token].append(len(final_tokens))\n",
    "                \n",
    "            continue\n",
    "                \n",
    "        if token == start_coref_entity_tag:\n",
    "            final_tokens.append(start_entity_tag)\n",
    "\n",
    "        elif token == end_coref_entity_tag:\n",
    "            final_tokens.append(end_entity_tag)\n",
    "\n",
    "        else:\n",
    "            final_tokens.append(token)\n",
    "\n",
    "    print(final_tokens, entities_offsets)\n",
    "    return final_tokens, entities_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "86f76284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Re', '##b', 'Cha', '##im', 'Ya', '##ak', '##ov', \"'\", 's', 'wife', 'is', 'the', 'sister', 'of', 'Rabbi', 'Mo', '##ish', '##e', 'Stern', '##bu', '##ch', ',', 'as', 'is', 'the', 'wife', 'of', 'Rabbi', 'Me', '##shu', '##lam', 'Do', '##vid', 'Solo', '##ve', '##itch', '##ik', ',', 'making', 'the', 'two', 'Rabbi', '##s', 'his', 'uncle', '##s', '.', 'Re', '##b', 'Asher', \"'\", 's', 'brother', 'Rabbi', 'S', '##hl', '##omo', 'Ariel', '##i', 'is', 'the', 'author', 'of', 'a', 'critical', 'edition', 'of', 'the', 'no', '##val', '##la', '##e', 'of', 'Rabbi', 'A', '##ki', '##va', 'E', '##iger', '.', 'Before', 'his', 'marriage', ',', 'Rabbi', 'Ariel', '##i', 'studied', 'in', 'the', 'Po', '##ne', '##vez', '##h', 'Yes', '##hiva', 'headed', 'by', 'Rabbi', 'S', '##hm', '##uel', 'R', '##oz', '##ovsky', ',', 'and', 'he', 'later', 'studied', 'under', 'his', 'father', '-', 'in', '-', 'law', 'in', 'the', 'Mir', '##rer', 'Yes', '##hiva', '.'] {'<P>': [81], '<E>': [0, 14, 27, 47, 53, 73, 84, 98], '</E>': [9, 21, 37, 52, 59, 79, 87, 105], '<C>': [], '</C>': []}\n"
     ]
    }
   ],
   "source": [
    "tokens, offsets = tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2d1a971f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<E>', 'Rabbi', 'S', '##hm', '##uel', 'R', '##oz', '##ovsky']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[113:121]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e7b0bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<E>Killian</E> in 1978--79, an assistant district attorney for Brunswick Judicial Circuit in 1979--80, and a practicing attorney in Glynn County in 1980--90. <E>Williams</E> was elected a Superior Court judge in 1990, taking the bench in 1991. In November 2010 <C>Williams</C> competed against <E>Mary Helen Moses</E> in <P>her most recent bid for re-election.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b1fb987",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Collator:\n",
    "    def __init__(self, device, labeled=True):\n",
    "        self.device = device\n",
    "        self.labeled = labeled\n",
    "        \n",
    "    def __call__(self, batch, truncate_len=512):\n",
    "        \"\"\"Batch preparation.\n",
    "\n",
    "        1. Pad the sequences\n",
    "        2. Transform the target.\n",
    "        \"\"\"\n",
    "\n",
    "        # ['tokens', 'all_entities_offsets', 'coreferent_ent_offset', 'ambiguous_pron_offset', 'labels']\n",
    "        if self.labeled:\n",
    "            batch_features, batch_start_entities_offsets, batch_end_entities_offsets, _, _, batch_labels = zip(*batch)\n",
    "        \n",
    "        else:\n",
    "            batch_features, batch_start_entities_offsets, batch_end_entities_offsets, _, _ = zip(*batch)\n",
    "        \n",
    "        collate_sample = {}\n",
    "\n",
    "        max_len_features_in_batch = self.compute_max_len(batch_features, truncate_len)\n",
    "        max_len_offsets_in_batch = self.compute_max_len(batch_start_entities_offsets, truncate_len)\n",
    "\n",
    "        # Features        \n",
    "        padded_features = self.pad_sequence(batch_features, max_len_features_in_batch, 0)\n",
    "        features_tensor = torch.tensor(padded_features, device=device)\n",
    "        collate_sample['features'] = features_tensor\n",
    "\n",
    "        # Offsets\n",
    "        padded_start_entities_offsets = self.pad_sequence(batch_start_entities_offsets, max_len_offsets_in_batch, 0)\n",
    "        start_entities_offsets_tensor = torch.tensor(padded_start_entities_offsets, device=device)\n",
    "        # collate_sample['start_entities_offsets'] = start_entities_offsets_tensor\n",
    "\n",
    "        padded_end_entities_offsets = self.pad_sequence(batch_end_entities_offsets, max_len_offsets_in_batch, 0)\n",
    "        end_entities_offsets_tensor = torch.tensor(padded_end_entities_offsets, device=device)\n",
    "        # collate_sample['end_entities_offsets'] = end_entities_offsets_tensor\n",
    "\n",
    "        collate_sample['entities_offsets'] = list(zip(start_entities_offsets_tensor, end_entities_offsets_tensor))\n",
    "\n",
    "        # Labels\n",
    "        if not self.labeled:\n",
    "            return collate_sample\n",
    "\n",
    "        padded_labels = self.pad_sequence(batch_labels, max_len_offsets_in_batch, 0)\n",
    "        labels_tensor = torch.tensor(padded_labels, dtype=torch.uint8, device=device)\n",
    "        collate_sample['labels'] = labels_tensor\n",
    "        \n",
    "        return collate_sample\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_max_len(sentences, truncate_len) -> int:\n",
    "        # calculate the max sentence length in the dataset\n",
    "        max_len = min(\n",
    "            max((len(x) for x in sentences)),\n",
    "            truncate_len\n",
    "        )\n",
    "        return max_len\n",
    "    \n",
    "    @staticmethod\n",
    "    def pad_sequence(list_sequences: List[List[Any]], max_len: int, pad: int) -> List[Any]:\n",
    "    \n",
    "        features = np.full((len(list_sequences), max_len), pad, dtype=np.int64)\n",
    "\n",
    "        # Padding\n",
    "        for i, row in enumerate(list_sequences):\n",
    "            features[i, :len(row)] = row\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3eead60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch, labeled = True, truncate_len=512):\n",
    "    # ['tokens', 'all_entities_offsets', 'coreferent_ent_offset', 'ambiguous_pron_offset', 'labels']\n",
    "    if labeled:\n",
    "        batch_features, batch_start_entities_offsets, batch_end_entities_offsets, _, _, batch_labels = zip(*batch)\n",
    "    \n",
    "    else:\n",
    "        batch_features, batch_start_entities_offsets, batch_end_entities_offsets, _, _ = zip(*batch)\n",
    "    \n",
    "    collate_sample = {}\n",
    "\n",
    "    max_len_features_in_batch = compute_max_len(batch_features, truncate_len)\n",
    "    max_len_offsets_in_batch = compute_max_len(batch_start_entities_offsets, truncate_len)\n",
    "\n",
    "    # Features        \n",
    "    padded_features = pad_sequence(batch_features, max_len_features_in_batch, 0)\n",
    "    features_tensor = torch.tensor(padded_features, device=device)\n",
    "    collate_sample['features'] = features_tensor\n",
    "\n",
    "    # Offsets\n",
    "    padded_start_entities_offsets = pad_sequence(batch_start_entities_offsets, max_len_offsets_in_batch, 0)\n",
    "    start_entities_offsets_tensor = torch.tensor(padded_start_entities_offsets, device=device)\n",
    "    # collate_sample['start_entities_offsets'] = start_entities_offsets_tensor\n",
    "\n",
    "    padded_end_entities_offsets = pad_sequence(batch_end_entities_offsets, max_len_offsets_in_batch, 0)\n",
    "    end_entities_offsets_tensor = torch.tensor(padded_end_entities_offsets, device=device)\n",
    "    # collate_sample['end_entities_offsets'] = end_entities_offsets_tensor\n",
    "\n",
    "    collate_sample['entities_offsets'] = list(zip(start_entities_offsets_tensor, end_entities_offsets_tensor))\n",
    "\n",
    "    # Labels\n",
    "    if not labeled:\n",
    "        return collate_sample\n",
    "\n",
    "    padded_labels = pad_sequence(batch_labels, max_len_offsets_in_batch, 0)\n",
    "    labels_tensor = torch.tensor(padded_labels, dtype=torch.uint8, device=device)\n",
    "    collate_sample['labels'] = labels_tensor\n",
    "    \n",
    "    return collate_sample\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00e20f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorefHead(nn.Module):\n",
    "    def __init__(self, bert_hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.bert_hidden_size = bert_hidden_size\n",
    "        self.head_hidden_size = 512\n",
    "\n",
    "        # a) Always BN -> AC, (Nothing b/w them).\n",
    "        # b) BN -> Dropout over Dropout -> BN, but try both. [Newer research, finds 1st better ]\n",
    "        # c) BN eliminates the need of Dropout, no need to use Dropout.\n",
    "        # e) BN before Dropout is data Leakage.\n",
    "        # f) Best thing is to try every combination.\n",
    "        # SO CALLED BEST METHOD -\n",
    "        # Layer -> BN -> AC -> Dropout ->Layer\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            #             nn.BatchNorm1d(bert_hidden_size * 3),\n",
    "            #             nn.Dropout(0.5),\n",
    "            #             nn.LeakyReLU(),\n",
    "            #             nn.Linear(bert_hidden_size * 3, self.head_hidden_size),\n",
    "            #             nn.BatchNorm1d(self.head_hidden_size),\n",
    "            #             nn.Dropout(0.5),\n",
    "            #             nn.Linear(self.head_hidden_size, self.head_hidden_size),\n",
    "            #             nn.ReLU(),\n",
    "            #             nn.BatchNorm1d(self.head_hidden_size),\n",
    "            #             nn.Dropout(0.5),\n",
    "#             nn.Dropout(0.1),\n",
    "#             nn.Linear(bert_hidden_size * 3, self.head_hidden_size),\n",
    "#             nn.BatchNorm1d(self.head_hidden_size),\n",
    "#             nn.LeakyReLU(),\n",
    "#             nn.Linear(self.head_hidden_size, 3)\n",
    "            nn.Linear(bert_hidden_size, self.head_hidden_size),\n",
    "            # nn.BatchNorm1d(self.head_hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "        )\n",
    "\n",
    "        \n",
    "        self.classifier = nn.Linear(self.head_hidden_size, 3)\n",
    "        \n",
    "        self._init_linear_weights(0.5)\n",
    "\n",
    "    def forward(self, bert_outputs, offsets):\n",
    "        embeddings = self._retrieve_entities_embeddings(bert_outputs, offsets)\n",
    "\n",
    "        x = self.fc(embeddings)\n",
    "        # x, _ = self.lstm(x)\n",
    "        # x = self.relu(x)\n",
    "\n",
    "        output = self.classifier(x)\n",
    "        return output\n",
    "    \n",
    "    def _init_linear_weights(self, initrange):\n",
    "        for module in self.fc:\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.uniform_(module.weight,initrange, initrange)\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "        \n",
    "        self.classifier.weight.data.uniform_(-initrange, initrange)\n",
    "        self.classifier.bias.data.zero_()\n",
    "    \n",
    "    def _retrieve_entities_embeddings(self, bert_embeddings, entities_offsets):\n",
    "        batch_embeddings = []\n",
    "\n",
    "        # Consider embeddings and offsets in each batch separately\n",
    "        for embeddings, offsets in zip(bert_embeddings, entities_offsets):\n",
    "            entities_embeddings = []\n",
    "\n",
    "            for start, end in zip(*offsets):\n",
    "                if (start, end) == (0, 0): # Dealing with padding\n",
    "                    entities_embeddings.append(torch.zeros(embeddings.shape[-1], device=device))\n",
    "                else:\n",
    "                    # The embedding of an entity is the mean of all the subtokens embeddings that represent it \n",
    "                    entities_embeddings.append(embeddings[start:end].mean(dim=0))\n",
    "\n",
    "            batch_embeddings.append(torch.stack(entities_embeddings, dim=0))\n",
    "\n",
    "        # Merge outputs\n",
    "        merged_entities_embeddings = torch.stack(batch_embeddings, dim=0)\n",
    "\n",
    "        # shape: batch_size x seq_length x embedding_dim\n",
    "        return merged_entities_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae11350c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i, module in enumerate(model.head.fc):\n",
    "#     if isinstance(module, nn.Linear):\n",
    "#         print(i, module.bias)\n",
    "#         nn.init.uniform_(module.weight)\n",
    "#         self.classifier.weight.data.uniform_(-initrange, initrange)\n",
    "#         self.classifier.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64d65d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAPModel(nn.Module):\n",
    "    \"\"\"The main model.\"\"\"\n",
    "\n",
    "    def __init__(self, bert_model: str, tokenizer):\n",
    "        super().__init__()\n",
    "\n",
    "        if bert_model in {\"bert-base-uncased\", \"bert-base-cased\"}:\n",
    "            self.bert_hidden_size = 768\n",
    "        elif bert_model in {\"bert-large-uncased\", \"bert-large-cased\"}:\n",
    "            self.bert_hidden_size = 1024\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported BERT model.\")\n",
    "\n",
    "        # configuration = BertConfig(bert_model, output_hidden_states=True)\n",
    "        # configuration.vocab_size = len(tokenizer.vocab)\n",
    "        self.bert = BertModel.from_pretrained(bert_model).to(device, non_blocking=True)\n",
    "\n",
    "        embedding_layer = self.bert.embeddings.word_embeddings\n",
    "\n",
    "        old_num_tokens, old_embedding_dim = embedding_layer.weight.shape\n",
    "\n",
    "        # Creating new embedding layer with more entries\n",
    "        new_embeddings = nn.Embedding(\n",
    "            len(tokenizer.vocab), old_embedding_dim\n",
    "        )\n",
    "\n",
    "        # Setting device and type accordingly\n",
    "        new_embeddings.to(\n",
    "            embedding_layer.weight.device,\n",
    "            dtype=embedding_layer.weight.dtype,\n",
    "        )\n",
    "\n",
    "        # Copying the old entries\n",
    "        new_embeddings.weight.data[:old_num_tokens, :] = embedding_layer.weight.data[\n",
    "            :old_num_tokens, :\n",
    "        ]\n",
    "\n",
    "        self.bert.embeddings.word_embeddings = new_embeddings\n",
    "        self.head = CorefHead(self.bert_hidden_size).to(device, non_blocking=True)\n",
    "\n",
    "    def forward(self, sample):\n",
    "        x = sample['features']\n",
    "        x_offsets = sample['entities_offsets']\n",
    "\n",
    "        bert_outputs = self.bert(x, attention_mask=(x > 0).long(),token_type_ids=None)\n",
    "#         concat_bert = torch.cat((bert_outputs[-1],bert_outputs[-2],bert_outputs[-3]),dim=-1)\n",
    "        # concat_bert = torch.cat((bert_outputs.hidden_states[-1], bert_outputs.hidden_states[-2],\n",
    "        #                          bert_outputs.hidden_states[-3], bert_outputs.hidden_states[-4]), dim=-1)\n",
    "        \n",
    "        out = bert_outputs.last_hidden_state\n",
    "\n",
    "        # layers_to_sum = torch.stack([bert_outputs.hidden_states[x] for x in [-1, -2, -3, -4]], dim=0)\n",
    "        # out = torch.sum(layers_to_sum, dim=0)\n",
    "\n",
    "        # out = torch.cat([bert_outputs.hidden_states[x] for x in [-1, -2, -3, -4]], dim=-1)\n",
    "\n",
    "        head_outputs = self.head(out, x_offsets)\n",
    "#         return concat_bert\n",
    "        return head_outputs\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "61a7e11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "collator = Collator(device)\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, \n",
    "                              collate_fn=collator, shuffle=False)\n",
    "\n",
    "valid_dataloader = DataLoader(valid_ds, batch_size=batch_size, \n",
    "                              collate_fn=collator, shuffle=False)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0a70fda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_name = \"bert-base-cased\"\n",
    "\n",
    "configuration = BertConfig(bert_model_name, output_hidden_states=True, output_attentions=True)\n",
    "configuration.vocab_size = len(tokenizer.vocab)\n",
    "bert = BertModel(configuration).to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8228be89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_model_name = \"bert-base-cased\"\n",
    "bert = BertModel.from_pretrained(bert_model_name).to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cecd053f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b328631e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(28996, 768, padding_idx=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.embeddings.word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4336fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer.weight.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95773ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = bert.embeddings.word_embeddings\n",
    "\n",
    "old_num_tokens, old_embedding_dim = embedding_layer.weight.shape\n",
    "\n",
    "# Creating new embedding layer with more entries\n",
    "new_embeddings = nn.Embedding(\n",
    "        len(tokenizer.vocab), old_embedding_dim\n",
    ")\n",
    "\n",
    "# Setting device and type accordingly\n",
    "new_embeddings.to(\n",
    "    embedding_layer.weight.device,\n",
    "    dtype=embedding_layer.weight.dtype,\n",
    ")\n",
    "\n",
    "# Copying the old entries\n",
    "new_embeddings.weight.data[:old_num_tokens, :] = embedding_layer.weight.data[\n",
    "    :old_num_tokens, :\n",
    "]\n",
    "\n",
    "bert.embeddings.word_embeddings = new_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1431cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.4784e-04, -4.1569e-02,  1.3084e-02,  ..., -3.8919e-03,\n",
       "         -3.3549e-02,  1.4984e-02],\n",
       "        [ 1.6883e-02, -3.1068e-02,  4.2053e-03,  ..., -1.4740e-02,\n",
       "         -3.5611e-02, -3.6223e-03],\n",
       "        [-5.7234e-04, -2.6736e-02,  8.0395e-03,  ..., -1.0025e-02,\n",
       "         -3.3116e-02, -1.6517e-02],\n",
       "        ...,\n",
       "        [ 9.9409e-01,  5.7340e-01,  1.2208e+00,  ..., -1.0702e+00,\n",
       "          1.5929e-01, -1.6526e+00],\n",
       "        [-9.8284e-01, -4.7983e-01,  1.0092e+00,  ...,  1.9583e+00,\n",
       "         -9.4387e-01,  1.8374e-01],\n",
       "        [ 1.0656e+00,  1.0088e+00, -1.7623e-01,  ...,  6.8488e-01,\n",
       "          2.8528e-01,  6.5319e-01]], device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.embeddings.word_embeddings.weight.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd327e2",
   "metadata": {},
   "source": [
    "2148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ea87975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, sample in enumerate(train_dataloader):\n",
    "    features = sample['features']\n",
    "    entities_offsets = sample['entities_offsets']        \n",
    "    output = bert(features, attention_mask=(features > 0).long(), token_type_ids=None)\n",
    "    \n",
    "#     res = head(output.hidden_states[-1], offsets)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ce85a20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_embeddings = output.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "44cac713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3617, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_embeddings[1][20:21].mean(0)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "baa78150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5782, -0.9481, -0.8416,  ..., -1.0011, -0.5545,  0.2845],\n",
       "         [-0.2335, -1.8323, -0.7915,  ..., -0.7340, -0.2332, -0.0700],\n",
       "         [ 1.1578, -0.5641, -1.4273,  ...,  0.2484, -1.3667,  0.1463],\n",
       "         ...,\n",
       "         [-0.2578, -0.8541, -0.7586,  ..., -1.2105, -0.6433, -0.1823],\n",
       "         [-0.3026, -0.5799, -1.1335,  ..., -0.6303, -1.2873, -0.6189],\n",
       "         [ 0.7272, -0.5913, -0.8269,  ..., -0.3852, -1.4903,  0.1380]],\n",
       "\n",
       "        [[-1.2102, -0.2077, -0.7168,  ..., -1.2219, -0.3596,  0.3617],\n",
       "         [-0.0474, -0.3812, -1.5421,  ..., -0.7341, -0.8667,  0.4135],\n",
       "         [ 0.7614, -0.9988, -1.0558,  ...,  0.2296, -0.9178, -0.9329],\n",
       "         ...,\n",
       "         [ 0.1762, -0.4342, -1.1592,  ..., -0.0296, -1.0140, -0.1219],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "       grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "batch_embeddings = []\n",
    "\n",
    "# Consider embeddings and offsets in each batch separately\n",
    "for embeddings, offsets in zip(bert_embeddings, entities_offsets):\n",
    "    entities_embeddings = []\n",
    "\n",
    "    for start, end in zip(*offsets):\n",
    "        if (start, end) == (0, 0): # Dealing with padding\n",
    "            entities_embeddings.append(torch.zeros(embeddings.shape[-1], device=device))\n",
    "        else:\n",
    "            # The embedding of an entity is the mean of all the subtokens embeddings that represent it \n",
    "            entities_embeddings.append(embeddings[start:end].mean(dim=0))\n",
    "\n",
    "    batch_embeddings.append(torch.stack(entities_embeddings, dim=0))\n",
    "\n",
    "# Merge outputs\n",
    "merged_entities_embeddings = torch.stack(batch_embeddings, dim=0)\n",
    "\n",
    "# shape: batch_size x seq_length x embedding_dim\n",
    "merged_entities_embeddings\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8b1fcb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_tag(text, offsets, start_tag: str, end_tag: str = None):\n",
    "    start_off, end_off = offsets \n",
    "\n",
    "    # Starting tag only\n",
    "    if end_tag is None:\n",
    "        text = text[:start_off] + start_tag + text[start_off:]\n",
    "        return text\n",
    "\n",
    "    text = text[:start_off] + start_tag + text[start_off:end_off] + end_tag + text[end_off:]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cd7221ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97a57b5da96f47288c6e57d83d77f350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc96e9eb3e74f51a5c7ed6bc5bf9e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.25G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertForQuestionAnswering\n",
    "\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "10eac0a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e3aa13f54b46c985796e3b59ee7cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d8f7f2f7804490a8bbc83528996896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer_qa = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "28cff8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad (https://huggingface.co/distilbert-base-cased-distilled-squad)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "qa_model = pipeline(\"question-answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "65d9194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, sentence in enumerate(df_train['text']):\n",
    "    if \"*\" in sentence:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a3096fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['McCarthy', 'T', '##tra', '##ult']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"McCarthy Ttrault\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ba532797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     train-24\n",
       "text          Louis McNeill begin her publishing career selling short poems to the Saturday Evening Post. In 1931 her first collection, Mountain White, was published. She went on to publish six other collections. In the 1980s McNeill's literary reputation was re-established by the poet Maggie Anderson, who edited McNeill's memoir for the University of Pittsburgh Press, as well as a new and selected poems in 1991. In 1979 then-governor Jay Rockefeller named her West Virginia's poet laureate.\n",
       "pron                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        her\n",
       "p_offset                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    447\n",
       "entity_A                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Maggie Anderson\n",
       "offset_A                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    273\n",
       "is_coref_A                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                False\n",
       "entity_B                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                McNeill\n",
       "offset_B                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    301\n",
       "is_coref_B                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 True\n",
       "url                                                                                                                                                                                                                                                                                                                                                                                                                                                                 http://en.wikipedia.org/wiki/Louise_McNeill\n",
       "Name: 23, dtype: object"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d0dc2149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"her West Virginia's poet laureate.\""
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['text'][23][447:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "dc98ebae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.6841534376144409,\n",
       " 'start': 425,\n",
       " 'end': 440,\n",
       " 'answer': 'Jay Rockefeller'}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Rockefeller named her West Virginia. Who is her?\"\n",
    "context = df_train['text'][23]\n",
    "qa_model(question = question, context = context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb3fa8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMultipleChoice: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMultipleChoice\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForMultipleChoice.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "prompt = \"In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.\"\n",
    "choice0 = \"It is eaten with a fork and a knife.\"\n",
    "choice1 = \"It is eaten while held in the hand.\"\n",
    "labels = torch.tensor(0).unsqueeze(0)  # choice0 is correct (according to Wikipedia ;)), batch size 1\n",
    "\n",
    "encoding = tokenizer([prompt, prompt], [choice0, choice1], return_tensors=\"pt\", padding=True)\n",
    "outputs = model(**{k: v.unsqueeze(0) for k, v in encoding.items()}, labels=labels)  # batch size is 1\n",
    "\n",
    "# the linear classifier still needs to be trained\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aadcfeba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 35])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding['input_ids'].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f489d7",
   "metadata": {
    "id": "f4f489d7"
   },
   "source": [
    "GradScaler: https://pytorch.org/docs/stable/notes/amp_examples.html#gradient-clipping\n",
    "\n",
    "https://pytorch.org/docs/stable/amp.html#gradient-scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a41065",
   "metadata": {
    "id": "21a41065"
   },
   "source": [
    "**Gradient Scaling**\n",
    "\n",
    "If the forward pass for a particular op has float16 inputs, the backward pass for that op will produce float16 gradients. Gradient values with small magnitudes may not be representable in float16. These values will flush to zero (“underflow”), so the update for the corresponding parameters will be lost.\n",
    "\n",
    "To prevent underflow, “gradient scaling” multiplies the network’s loss(es) by a scale factor and invokes a backward pass on the scaled loss(es). Gradients flowing backward through the network are then scaled by the same factor. In other words, gradient values have a larger magnitude, so they don’t flush to zero.\n",
    "\n",
    "The method `step(optimizer, *args, **kwargs)` internally invokes `unscale_(optimizer)`and if no inf/NaN gradients are found, invokes `optimizer.step()` using the unscaled gradients. Otherwise `optimizer.step()` is skipped to avoid corrupting the params.\n",
    "\n",
    "\\**Note for Gradient Clipping*\n",
    "\n",
    "If you wish to modify the gradients (like in gradient clipping), you should unscale them first. If you attempted to clip *without* unscaling, the gradients' norm magnitude would also be scaled, so your requested threshold would be invalid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "766de1e5",
   "metadata": {
    "executionInfo": {
     "elapsed": 242,
     "status": "ok",
     "timestamp": 1660751890792,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "766de1e5"
   },
   "outputs": [],
   "source": [
    "# class Trainer:\n",
    "    \n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         model: nn.Module,\n",
    "#         args: CustomTrainingArguments,\n",
    "#         train_dataloader: DataLoader,\n",
    "#         valid_dataloader: DataLoader,\n",
    "#         criterion: torch.nn,\n",
    "#         optimizer: torch.optim.Optimizer,\n",
    "#         scheduler: torch.optim.lr_scheduler = None,\n",
    "        \n",
    "#     ):\n",
    "        \n",
    "#         self.model = model\n",
    "#         self.train_dataloader = train_dataloader\n",
    "#         self.valid_dataloader = valid_dataloader\n",
    "#         self.criterion = criterion\n",
    "#         self.optimizer = optimizer\n",
    "#         self.scheduler = scheduler\n",
    "        \n",
    "#         if args is None:\n",
    "#             output_dir = \"../../model/tmp_trainer\"\n",
    "#             print(f\"No 'TrainingArguments' passed, using 'output_dir={output_dir}'.\")\n",
    "#             args = CustomTrainingArguments(output_dir=output_dir)\n",
    "        \n",
    "#         self.args = args\n",
    "        \n",
    "#     def train(self):\n",
    "#         args = self.args\n",
    "#         valid_dataloader = self.valid_dataloader\n",
    "#         epochs = args.num_train_epochs\n",
    "        \n",
    "#         train_losses = []\n",
    "#         train_acc_list = []\n",
    "#         valid_losses = []\n",
    "#         valid_acc_list = []\n",
    "        \n",
    "#         if args.early_stopping:\n",
    "#             patience_counter = 0 \n",
    "\n",
    "#         scaler = GradScaler()\n",
    "\n",
    "#         if args.resume_from_checkpoint is not None:\n",
    "#             self._resume_model(args.resume_from_checkpoint, scaler)\n",
    "\n",
    "#         training_start_time = time.time()\n",
    "#         print(\"\\nTraining...\")\n",
    "#         for epoch in range(epochs):\n",
    "#             train_loss, train_acc = self._inner_training_loop(scaler)\n",
    "#             train_losses.append(train_loss)\n",
    "#             train_acc_list.append(train_acc)\n",
    "\n",
    "#             valid_loss, valid_acc = self.evaluate(valid_dataloader)\n",
    "#             valid_losses.append(valid_loss)\n",
    "#             valid_acc_list.append(valid_acc)\n",
    "\n",
    "#             if self.scheduler is not None:\n",
    "#                 print('-' * 17)\n",
    "#                 print(f\"| LR: {self.scheduler.get_last_lr()[0]:.3e} |\")\n",
    "#                 self.scheduler.step()\n",
    "\n",
    "#             self._print_epoch_log(epoch, epochs, train_loss, valid_loss, valid_acc)\n",
    "\n",
    "#             if args.early_stopping and len(valid_acc_list) >= 2:\n",
    "#                 # stop = args.early_stopping_mode == 'min' and epoch > 0 and valid_acc_list[-1] > valid_acc_list[-2]\n",
    "#                 stop = args.early_stopping_mode == 'max' and epoch > 0 and valid_acc_list[-1] < valid_acc_list[-2]\n",
    "#                 if stop:\n",
    "#                     if patience_counter >= args.early_stopping_patience:\n",
    "#                         print('Early stop.')\n",
    "#                         break\n",
    "#                     else:\n",
    "#                         print('-- Patience.\\n')\n",
    "#                         patience_counter += 1\n",
    "        \n",
    "#         training_time = time.time() - training_start_time\n",
    "#         print(f'Training time: {training_time:.2f}s')\n",
    "\n",
    "#         metrics_history = {\n",
    "#             \"train_losses\": train_losses,\n",
    "#             \"train_acc\": train_acc_list,\n",
    "#             \"valid_losses\": valid_losses,\n",
    "#             \"valid_acc\": valid_acc_list,\n",
    "#         }\n",
    "#         print(metrics_history)\n",
    "#         if args.save_model:\n",
    "#             self._save_model(epoch, valid_acc, scaler, metrics_history)\n",
    "    \n",
    "#         return #metrics_history\n",
    "\n",
    "#     def _inner_training_loop(self, scaler):\n",
    "#         args = self.args\n",
    "#         train_dataloader = self.train_dataloader\n",
    "        \n",
    "#         train_loss = 0.0\n",
    "#         train_correct, total_count = 0.0, 0.0\n",
    "\n",
    "#         self.model.train()\n",
    "#         for step, (features, labels) in enumerate(train_dataloader):\n",
    "#             # Empty gradients\n",
    "#             self.optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "#             # Forward\n",
    "#             # predictions = self.model(features, offsets)\n",
    "#             # loss = self.criterion(predictions, labels)\n",
    "# #             with torch.cuda.amp.autocast(): # autocast as a context manager\n",
    "#             predictions = self.model(features)\n",
    "\n",
    "#             predictions = predictions.view(-1, predictions.shape[-1])\n",
    "#             labels = labels.view(-1)\n",
    "#             loss = self.criterion(predictions, labels)\n",
    "\n",
    "#             mask = labels != 0\n",
    "#             predictions = predictions.argmax(1)\n",
    "#             predictions = predictions[mask]\n",
    "#             labels = labels[mask]\n",
    "#             train_correct += (predictions == labels).sum().item()\n",
    "#             total_count += labels.shape[0]\n",
    "            \n",
    "#             # Backward  \n",
    "#             loss.backward()\n",
    "#             # Backward pass without mixed precision\n",
    "#             # It's not recommended to use mixed precision for backward pass\n",
    "#             # Because we need more precise loss\n",
    "# #             scaler.scale(loss).backward()\n",
    "            \n",
    "#             if args.grad_clipping is not None:\n",
    "# #                 scaler.unscale_(optimizer)\n",
    "#                 torch.nn.utils.clip_grad_norm_(self.model.parameters(), args.grad_clipping)\n",
    "            \n",
    "#             # Update weights \n",
    "#             self.optimizer.step()\n",
    "# #             scaler.step(self.optimizer)\n",
    "# #             scaler.update()\n",
    "\n",
    "#             train_loss += loss.item()\n",
    "\n",
    "#             if step % args.logging_steps == args.logging_steps - 1:\n",
    "#                 running_loss = train_loss / (step + 1)\n",
    "#                 running_acc = train_correct / total_count\n",
    "#                 self._print_step_log(step, running_loss, running_acc)\n",
    "                \n",
    "#         return train_loss / len(train_dataloader), train_correct / total_count\n",
    "\n",
    "\n",
    "#     def evaluate(self, eval_dataloader):\n",
    "#         valid_loss = 0.0\n",
    "#         eval_correct, total_count = 0, 0\n",
    "        \n",
    "#         self.model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             for (features, labels) in eval_dataloader:\n",
    "                \n",
    "#                 predictions = self.model(features)\n",
    "                \n",
    "#                 predictions = predictions.view(-1, predictions.shape[-1])\n",
    "#                 labels = labels.view(-1)\n",
    "#                 loss = self.criterion(predictions, labels)\n",
    "#                 valid_loss += loss.item()\n",
    "                \n",
    "#                 mask = labels != 0\n",
    "#                 predictions = predictions.argmax(1)\n",
    "#                 predictions = predictions[mask]\n",
    "#                 labels = labels[mask]\n",
    "#                 eval_correct += (predictions == labels).sum().item()\n",
    "#                 total_count += labels.shape[0]\n",
    "        \n",
    "#         return valid_loss / len(eval_dataloader), eval_correct / total_count\n",
    "\n",
    "\n",
    "#     def _print_step_log(self, step, running_loss, running_acc):\n",
    "#         print(f'\\t| step {step+1:3d}/{len(self.train_dataloader):d} | train_loss: {running_loss:.3f} | ' \\\n",
    "#                 f'train_acc: {running_acc:.3f} |')\n",
    "\n",
    "#     def _print_epoch_log(self, epoch, epochs, train_loss, valid_loss, valid_acc):\n",
    "#         print('-' * 76)\n",
    "#         print(f'| epoch {epoch+1:>3d}/{epochs:<3d} | train_loss: {train_loss:.3f} | ' \\\n",
    "#                 f'valid_loss: {valid_loss:.3f} | valid_acc: {valid_acc:.3f} |')\n",
    "#         print('-' * 76)\n",
    "        \n",
    "    \n",
    "#     def _save_model(self, epoch, valid_acc, scaler):\n",
    "#         print(\"Saving model...\")\n",
    "#         if self.scheduler is None:\n",
    "#             torch.save({\n",
    "#                     \"epoch\": epoch,\n",
    "#                     \"model_state_dict\": self.model.state_dict(),\n",
    "#                     \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "#                     \"scaler_state_dict\": scaler.state_dict(),\n",
    "#                 }, f\"{self.args.output_dir}my_model_{str(valid_acc)[2:5]}_{epoch+1}.pth\")\n",
    "#         else:\n",
    "#             torch.save({\n",
    "#                     \"epoch\": epoch,\n",
    "#                     \"model_state_dict\": self.model.state_dict(),\n",
    "#                     \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "#                     \"scheduler_state_dict\": self.scheduler.state_dict(),\n",
    "#                     \"scaler_state_dict\": scaler.state_dict(),\n",
    "#                 }, f\"{self.args.output_dir}my_model_{str(valid_acc)[2:5]}_{epoch+1}.pth\")\n",
    "\n",
    "#         print(\"Model saved.\")\n",
    "\n",
    "#     def _resume_model(self, path, scaler):\n",
    "#         checkpoint = torch.load(path, map_location=device)\n",
    "#         self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#         self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "#         scaler.load_state_dict(checkpoint['scaler_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00c6f4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        args: CustomTrainingArguments,\n",
    "        train_dataloader: DataLoader,\n",
    "        valid_dataloader: DataLoader,\n",
    "        criterion: torch.nn,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        scheduler: torch.optim.lr_scheduler = None,\n",
    "        \n",
    "    ):\n",
    "        \n",
    "        self.model = model\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        \n",
    "        if args is None:\n",
    "            output_dir = \"../../model/tmp_trainer\"\n",
    "            print(f\"No 'TrainingArguments' passed, using 'output_dir={output_dir}'.\")\n",
    "            args = CustomTrainingArguments(output_dir=output_dir)\n",
    "        \n",
    "        self.args = args\n",
    "        \n",
    "    def train(self):\n",
    "        args = self.args\n",
    "        valid_dataloader = self.valid_dataloader\n",
    "        epochs = args.num_train_epochs\n",
    "        \n",
    "        train_losses = []\n",
    "        train_acc_list = []\n",
    "        valid_losses = []\n",
    "        valid_acc_list = []\n",
    "        \n",
    "        if args.early_stopping:\n",
    "            patience_counter = 0 \n",
    "\n",
    "        scaler = GradScaler()\n",
    "\n",
    "        if args.resume_from_checkpoint is not None:\n",
    "            self._resume_model(args.resume_from_checkpoint, scaler)\n",
    "\n",
    "        training_start_time = time.time()\n",
    "        print(\"\\nTraining...\")\n",
    "        for epoch in range(epochs):\n",
    "            train_loss, train_acc = self._inner_training_loop(scaler)\n",
    "            train_losses.append(train_loss)\n",
    "            train_acc_list.append(train_acc)\n",
    "\n",
    "            valid_loss, valid_acc = self.evaluate(valid_dataloader)\n",
    "            valid_losses.append(valid_loss)\n",
    "            valid_acc_list.append(valid_acc)\n",
    "\n",
    "            if self.scheduler is not None:\n",
    "                print('-' * 17)\n",
    "                print(f\"| LR: {self.scheduler.get_last_lr()[0]:.3e} |\")\n",
    "                self.scheduler.step()\n",
    "\n",
    "            self._print_epoch_log(epoch, epochs, train_loss, valid_loss, valid_acc)\n",
    "\n",
    "            if args.early_stopping and len(valid_acc_list) >= 2:\n",
    "                # stop = args.early_stopping_mode == 'min' and epoch > 0 and valid_acc_list[-1] > valid_acc_list[-2]\n",
    "                stop = args.early_stopping_mode == 'max' and epoch > 0 and valid_acc_list[-1] < valid_acc_list[-2]\n",
    "                if stop:\n",
    "                    if patience_counter >= args.early_stopping_patience:\n",
    "                        print('Early stop.')\n",
    "                        break\n",
    "                    else:\n",
    "                        print('-- Patience.\\n')\n",
    "                        patience_counter += 1\n",
    "        \n",
    "        training_time = time.time() - training_start_time\n",
    "        print(f'Training time: {self._print_time(training_time)}')\n",
    "\n",
    "        metrics_history = {\n",
    "            \"train_losses\": train_losses,\n",
    "            \"train_acc\": train_acc_list,\n",
    "            \"valid_losses\": valid_losses,\n",
    "            \"valid_acc\": valid_acc_list,\n",
    "        }\n",
    "        print(metrics_history)\n",
    "        if args.save_model:\n",
    "            self._save_model(\"2\", epoch, valid_acc, scaler, metrics_history)\n",
    "    \n",
    "        return #metrics_history\n",
    "\n",
    "    def _inner_training_loop(self, scaler):\n",
    "        args = self.args\n",
    "        train_dataloader = self.train_dataloader\n",
    "        \n",
    "        train_loss = 0.0\n",
    "        train_correct, total_count = 0.0, 0.0\n",
    "\n",
    "        self.model.train()\n",
    "        for step, sample in enumerate(train_dataloader):\n",
    "            # Empty gradients\n",
    "            self.optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            # Forward\n",
    "            # predictions = self.model(features, offsets)\n",
    "            # loss = self.criterion(predictions, labels)\n",
    "#             with torch.cuda.amp.autocast(): # autocast as a context manager\n",
    "            predictions = self.model(sample)\n",
    "\n",
    "            predictions = predictions.view(-1, predictions.shape[-1])\n",
    "            labels = sample['labels']\n",
    "            labels = labels.view(-1)\n",
    "            loss = self.criterion(predictions, labels)\n",
    "\n",
    "            mask = labels != 0\n",
    "            predictions = predictions.argmax(1)\n",
    "            predictions = predictions[mask]\n",
    "            labels = labels[mask]\n",
    "            train_correct += (predictions == labels).sum().item()\n",
    "            total_count += labels.shape[0]\n",
    "            \n",
    "            # Backward  \n",
    "            loss.backward()\n",
    "            # Backward pass without mixed precision\n",
    "            # It's not recommended to use mixed precision for backward pass\n",
    "            # Because we need more precise loss\n",
    "#             scaler.scale(loss).backward()\n",
    "            \n",
    "            if args.grad_clipping is not None:\n",
    "#                 scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), args.grad_clipping)\n",
    "            \n",
    "            # Update weights \n",
    "            self.optimizer.step()\n",
    "#             scaler.step(self.optimizer)\n",
    "#             scaler.update()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            if step % args.logging_steps == args.logging_steps - 1:\n",
    "                running_loss = train_loss / (step + 1)\n",
    "                running_acc = train_correct / total_count\n",
    "                self._print_step_log(step, running_loss, running_acc)\n",
    "                \n",
    "        return train_loss / len(train_dataloader), train_correct / total_count\n",
    "\n",
    "\n",
    "    def evaluate(self, eval_dataloader):\n",
    "        valid_loss = 0.0\n",
    "        eval_correct, total_count = 0, 0\n",
    "        \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for sample in eval_dataloader:\n",
    "                \n",
    "                predictions = self.model(sample)\n",
    "                \n",
    "                predictions = predictions.view(-1, predictions.shape[-1])\n",
    "                labels = sample['labels']\n",
    "                labels = labels.view(-1)\n",
    "                loss = self.criterion(predictions, labels)\n",
    "                valid_loss += loss.item()\n",
    "                \n",
    "#                 accuracy = compute_score(predictions, labels)\n",
    "                \n",
    "                mask = labels != 0\n",
    "                predictions = predictions.argmax(1)\n",
    "                predictions = predictions[mask]\n",
    "                labels = labels[mask]\n",
    "                eval_correct += (predictions == labels).sum().item()\n",
    "                total_count += labels.shape[0]\n",
    "        \n",
    "        return valid_loss / len(eval_dataloader), eval_correct / total_count\n",
    "\n",
    "    \n",
    "    def compute_score(self, predictions: torch.Tensor, labels: torch.Tensor):\n",
    "        mask = labels != 0\n",
    "        labels = labels[mask]        \n",
    "        \n",
    "        predictions = predictions[mask]\n",
    "        maximum_logits, predicted_labels = predictions.max(1)\n",
    "        \n",
    "        # It may happen that more than one pronoun is classify as ambiguous\n",
    "        multiple_ambiguous_pronouns_mask = predicted_labels == 2\n",
    "        ambiguous_pronouns_logits = maximum_logits[multiple_ambiguous_pronouns_mask]\n",
    "\n",
    "        # More than one pronoun is classify as ambiguous\n",
    "        if len(ambiguous_pronouns_logits) > 1:\n",
    "            # Get the highest logit among the ambiguous ones\n",
    "            highest_ambiguous_pronoun_logit = ambiguous_pronouns_logits.max()\n",
    "\n",
    "            # Identity the position of the logit that should correspond to the ambiguous prononun class (2)\n",
    "            ambiguous_pronoun_mask = maximum_logits == highest_ambiguous_pronoun_logit\n",
    "\n",
    "            # All the predictions that are not of that class are set to the \"not ambiguous class\" (1)\n",
    "            predicted_labels[~ambiguous_pronoun_mask] = 1\n",
    "\n",
    "            # However, it may happen again that we have multiple pronouns classified as ambiguous, \n",
    "            # since there may be more than one logit with value = highest_ambiguous_pronoun_logit\n",
    "        \n",
    "        \n",
    "        label_ambiguous_mask = labels == 2\n",
    "        eval_correct += int(labels[label_ambiguous_mask] == predicted_labels[label_ambiguous_mask])\n",
    "        \n",
    "        return eval_correct\n",
    "    \n",
    "    def _print_time(self, s):\n",
    "        m = math.floor(s / 60)\n",
    "        s -= m * 60\n",
    "        return '%dm %ds' % (m, s)\n",
    "\n",
    "    def _print_step_log(self, step, running_loss, running_acc):\n",
    "        print(f'\\t| step {step+1:3d}/{len(self.train_dataloader):d} | train_loss: {running_loss:.3f} | ' \\\n",
    "                f'train_acc: {running_acc:.3f} |')\n",
    "\n",
    "    def _print_epoch_log(self, epoch, epochs, train_loss, valid_loss, valid_acc):\n",
    "        print('-' * 76)\n",
    "        print(f'| epoch {epoch+1:>3d}/{epochs:<3d} | train_loss: {train_loss:.3f} | ' \\\n",
    "                f'valid_loss: {valid_loss:.3f} | valid_acc: {valid_acc:.3f} |')\n",
    "        print('-' * 76)\n",
    "        \n",
    "    \n",
    "    def _save_model(self, task_type, epoch, valid_acc, scaler, metrics_history):\n",
    "        print(\"Saving model...\")\n",
    "        params_to_save = {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": self.model.state_dict(),\n",
    "            \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "            \"metrics_history\": metrics_history,\n",
    "        }\n",
    "        \n",
    "        if self.scheduler is not None:\n",
    "            params_to_save[\"scheduler_state_dict\"] = self.scheduler.state_dict()\n",
    "            \n",
    "        if scaler is not None:\n",
    "            params_to_save[\"scaler_state_dict\"] = scaler.state_dict(),\n",
    "            \n",
    "        save_path = f\"{self.args.output_dir}my_model{str(task_type)}_{str(valid_acc)[2:5]}_{epoch+1}\"\n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H-%M-%S\")\n",
    "        \n",
    "        if os.path.exists(f\"{save_path}_{current_time}.pth\"):\n",
    "            torch.save(params_to_save, f\"{save_path}_{current_time}_new.pth\")\n",
    "        else:\n",
    "            torch.save(params_to_save, f\"{save_path}_{current_time}.pth\")\n",
    "        \n",
    "        print(\"Model saved.\")\n",
    "\n",
    "    def _resume_model(self, path, scaler):\n",
    "        checkpoint = torch.load(path, map_location=device)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scaler.load_state_dict(checkpoint['scaler_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7a11aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({\n",
    "#     \"model_state_dict\": model.state_dict(),\n",
    "#     \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "# #     \"scheduler_state_dict\": self.scheduler.state_dict(),\n",
    "# #     \"scaler_state_dict\": scaler.state_dict(),\n",
    "# }, f\"../../model/checkpoints/my_model_{str(946)}_{2}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31aa4455",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2064,
     "status": "ok",
     "timestamp": 1660753117653,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "31aa4455",
    "outputId": "790097d0-16fa-439c-b121-325837a47121",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomTrainingArguments(output_dir='../../model/checkpoints/', resume_from_checkpoint=None, save_model=False, num_train_epochs=2, logging_steps=250, learning_rate=5e-05, grad_clipping=None, early_stopping=True, early_stopping_mode='max', early_stopping_patience=2)\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"bert-base-cased\"\n",
    "model = GAPModel(model_name_or_path, tokenizer).to(device, non_blocking=True)\n",
    "\n",
    "# last_frozen_layer = 6\n",
    "\n",
    "# modules = [model.bert.embeddings, *model.bert.encoder.layer[:last_frozen_layer]]\n",
    "# for module in modules:\n",
    "#     for param in module.parameters():\n",
    "#         param.requires_grad = False\n",
    "\n",
    "yaml_file = \"./train_notebook.yaml\"\n",
    "# Read configuration file with all the necessary parameters\n",
    "with open(yaml_file) as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    \n",
    "training_args = CustomTrainingArguments(**config['training_args'])\n",
    "\n",
    "# Make sure that the learning rate is read as a number and not as a string\n",
    "training_args.learning_rate = float(training_args.learning_rate)\n",
    "print(training_args)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=0).to(device=device, non_blocking=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=training_args.learning_rate)\n",
    "# scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.1)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "scheduler = None\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "collator = Collator(device)\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, \n",
    "                              collate_fn=collator, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_ds, batch_size=batch_size, \n",
    "                              collate_fn=collator, shuffle=False)\n",
    "\n",
    "trainer = Trainer(model, training_args, \n",
    "                  train_dataloader, valid_dataloader, \n",
    "                  criterion, optimizer, scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e7c8f03a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 735134,
     "status": "ok",
     "timestamp": 1660753855156,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "e7c8f03a",
    "outputId": "8349c872-e0c2-4428-f04b-6ed2f8496ffc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training...\n",
      "----------------------------------------------------------------------------\n",
      "| epoch   1/2   | train_loss: 3.198 | valid_loss: 4.452 | valid_acc: 0.825 |\n",
      "----------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12896\\2758054707.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmetrics_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12896\\1218446353.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nTraining...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m             \u001b[0mtrain_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0mtrain_acc_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12896\\1218446353.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, scaler)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;31m# Update weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;31m#             scaler.step(self.optimizer)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;31m#             scaler.update()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\DL\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\DL\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\DL\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    151\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weight_decay'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m                    \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m                    maximize=group['maximize'])\n\u001b[0m\u001b[0;32m    154\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\DL\\lib\\site-packages\\torch\\optim\\_functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metrics_history = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3280693e",
   "metadata": {
    "id": "3280693e"
   },
   "outputs": [],
   "source": [
    "# epoch   2/2   | train_loss: 0.375 | valid_loss: 0.335 | valid_acc: 0.877 000005\n",
    "metrics_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f948bb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, \"../../model/checkpoints/my_model2_876_2_17-06-10.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "102f37c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../model/checkpoints/my_model2_922_2_17-42-11.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bb7f80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b0aafda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true_list = []\n",
    "# y_pred_list = []\n",
    "\n",
    "# eval_correct, total_count = 0.0, 0.0\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     dataloader = DataLoader(valid_ds, batch_size=1, collate_fn=collate_batch, shuffle=False)\n",
    "#     for (features, labels) in dataloader:\n",
    "#         predicted_labels = model(features)\n",
    "\n",
    "#         predicted_labels = predicted_labels.view(-1, predicted_labels.shape[-1])\n",
    "#         labels = labels.view(-1)\n",
    "\n",
    "#         mask = labels != 0\n",
    "#         predicted_labels = predicted_labels.argmax(1)\n",
    "#         predicted_labels = predicted_labels[mask].tolist()\n",
    "        \n",
    "#         y_pred_list.append(predicted_labels)\n",
    "        \n",
    "        \n",
    "#         labels = labels[mask].tolist()\n",
    "#         y_true_list.append(labels)\n",
    "        \n",
    "        \n",
    "# #         eval_correct += (predicted_labels == labels).sum().item()\n",
    "# #         total_count += labels.shape[0]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "992233ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False,  True])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It may happen that more than one pronoun is classify as ambiguous\n",
    "multiple_ambiguous_pronouns_mask = a[1] == 2\n",
    "\n",
    "ambiguous_pronouns_logits = a[0][multiple_ambiguous_pronouns_mask]\n",
    "\n",
    "# No ambiguity\n",
    "if len(ambiguous_pronouns_logits) <= 1:\n",
    "    print(\"RVFE\")\n",
    "\n",
    "# More than one pronoun is classify as ambiguous\n",
    "\n",
    "# Get the highest logit among the ambiguous ones\n",
    "highest_ambiguous_pronoun_logit = ambiguous_pronouns_logits.max()\n",
    "\n",
    "# Identity the position of the logit that should correspond to the ambiguous prononun class (2)\n",
    "ambiguous_pronoun_mask = a[0] == highest_ambiguous_pronoun_logit\n",
    "\n",
    "# All the predictions that are not of that class are set to the \"not ambiguous class\" (1)\n",
    "a[1][~ambiguous_pronoun_mask] = 1\n",
    "\n",
    "# However, With this function, it may happen again that we have multiple pronouns classified as ambiguous, \n",
    "# since there may be more than one logit with value = highest_ambiguous_pronoun_logit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9baedcf",
   "metadata": {},
   "source": [
    "182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8371862e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ds[181].labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "01ced096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['labels'].numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "78086d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181\n"
     ]
    }
   ],
   "source": [
    "y_true_list = []\n",
    "y_pred_list = []\n",
    "logits = []\n",
    "\n",
    "\n",
    "eval_correct, total_count = 0.0, 0.0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    collator = Collator(device)\n",
    "    dataloader = DataLoader(valid_ds, batch_size=1, collate_fn=collator, shuffle=False)\n",
    "    for idx, sample in enumerate(dataloader):\n",
    "        if sample['labels'].numel() == 0:\n",
    "            print(idx)\n",
    "            continue\n",
    "        \n",
    "        predictions = model(sample)\n",
    "        predictions = predictions.view(-1, predictions.shape[-1])\n",
    "        labels = sample['labels']\n",
    "        labels = labels.view(-1)\n",
    "\n",
    "        logits.append(predictions)\n",
    "\n",
    "        mask = labels != 0\n",
    "        labels = labels[mask]\n",
    "        y_true_list.append(labels.tolist())\n",
    "        \n",
    "        \n",
    "        predictions = predictions[mask]\n",
    "        maximum_logits, predicted_labels = predictions.max(1)\n",
    "\n",
    "        \n",
    "        # It may happen that more than one pronoun is classify as ambiguous\n",
    "#         multiple_ambiguous_pronouns_mask = predicted_labels == 2\n",
    "#         ambiguous_pronouns_logits = maximum_logits[multiple_ambiguous_pronouns_mask]\n",
    "        \n",
    "#         # More than one pronoun is classify as ambiguous\n",
    "#         if len(ambiguous_pronouns_logits) > 1:\n",
    "#             # Get the highest logit among the ambiguous ones\n",
    "#             highest_ambiguous_pronoun_logit = ambiguous_pronouns_logits.max()\n",
    "\n",
    "#             # Identity the position of the logit that should correspond to the ambiguous prononun class (2)\n",
    "#             ambiguous_pronoun_mask = maximum_logits == highest_ambiguous_pronoun_logit\n",
    "\n",
    "#             # All the predictions that are not of that class are set to the \"not ambiguous class\" (1)\n",
    "#             predicted_labels[~ambiguous_pronoun_mask] = 1\n",
    "\n",
    "            # However, it may happen again that we have multiple pronouns classified as ambiguous, \n",
    "            # since there may be more than one logit with value = highest_ambiguous_pronoun_logit\n",
    "        \n",
    "        \n",
    "        # # When the model predicts that all the pronouns are not ambiguous (no class 2)\n",
    "        # if not torch.any(predicted_labels == 2):\n",
    "        #     # Try to select the most probable ambiguous pronoun\n",
    "        #     probable_ambiguous_index = predictions[:,-1].argmax()\n",
    "        #     predicted_labels[probable_ambiguous_index] = 2\n",
    "        \n",
    "        \n",
    "        y_pred_list.append(predicted_labels.tolist())\n",
    "        \n",
    "        \n",
    "        label_ambiguous_mask = labels == 2\n",
    "        eval_correct += (labels[label_ambiguous_mask] == predicted_labels[label_ambiguous_mask]).sum().item()\n",
    "        total_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "912f03e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453.0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6ae4af2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170.0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c1436200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37527593818984545"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_correct / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "83c33ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3744493392070485"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_correct / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "5ff402f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor([1, 2, 1])\n",
    "t2 = torch.tensor([2, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "e2d0aed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True])"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 == t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "e8b5fd12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(t1 != t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6318eb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "ambigous = t1 == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "72efff0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t1[ambigous] == t2[ambigous])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "78d8c357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False, False])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "30a47a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_list = []\n",
    "y_pred_list = []\n",
    "logits = []\n",
    "\n",
    "eval_correct, total_count = 0.0, 0.0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    dataloader = DataLoader(valid_ds, batch_size=1, collate_fn=collate_batch, shuffle=False)\n",
    "    for (features, offsets, labels) in dataloader:\n",
    "        predicted_labels = model(features, offsets)\n",
    "\n",
    "        predicted_labels = predicted_labels.view(-1, predicted_labels.shape[-1])\n",
    "        labels = labels.view(-1)\n",
    "        \n",
    "        logits.append(predicted_labels)\n",
    "\n",
    "        mask = labels != 0\n",
    "        predictions = predicted_labels.argmax(1)\n",
    "        predictions = predictions[mask].tolist()\n",
    "        \n",
    "        y_pred_list.append(predictions)\n",
    "        \n",
    "        \n",
    "        labels = labels[mask].tolist()\n",
    "        y_true_list.append(labels)\n",
    "        \n",
    "        \n",
    "#         eval_correct += (predicted_labels == labels).sum().item()\n",
    "#         total_count += labels.shape[0]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d7616b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = torch.nn.functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "28822a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True, False], device='cuda:0')"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[4]= False\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "427c9bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.3443,  4.5501, -1.0523],\n",
       "        [-3.3901,  4.5434, -0.9574],\n",
       "        [-3.3125,  4.5226, -1.0784],\n",
       "        [-3.6061,  4.0081, -0.1762],\n",
       "        [-3.3012,  4.5141, -1.1606],\n",
       "        [-3.3566,  4.4317, -1.0823],\n",
       "        [-3.7792,  3.9054, -0.0202],\n",
       "        [-3.8278,  3.0091,  1.3090],\n",
       "        [-3.5415,  3.3520,  0.2863]], device='cuda:0')"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[206]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "7e718c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = logits[206].max(1)\n",
    "maximum_logits, predicted_classes = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "386d725c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.5501, 4.5434, 4.5226, 4.0081, 4.5141, 4.4317, 3.9054, 3.0091, 3.3520],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximum_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "c9bcca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_logits = torch.tensor([1,1,4,2])\n",
    "predicted_labels = torch.tensor([1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "a29811c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 4, 2],\n",
       "        [1, 1, 1, 1]])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.stack([maximum_logits, predicted_classes], dim=0)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "4538a24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ef\n"
     ]
    }
   ],
   "source": [
    "if not torch.any(predicted_labels == 2):\n",
    "    print(\"ef\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "c944741d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# When the model predicts that all the pronouns are not ambiguous (all class 1)\n",
    "if len(predicted_classes) == predicted_classes.sum().item():\n",
    "    # Try to select the most probable ambiguous one\n",
    "    probable_ambiguous_index = logits[184][:,-1].argmax()\n",
    "    \n",
    "    print(predicted_classes[probable_ambiguous_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "2d3d4f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It may happen that more than one pronoun is classify as ambiguous\n",
    "multiple_ambiguous_pronouns_mask = a[1] == 2\n",
    "\n",
    "ambiguous_pronouns_logits = a[0][multiple_ambiguous_pronouns_mask]\n",
    "\n",
    "# No ambiguity\n",
    "if len(ambiguous_pronouns_logits) <= 1:\n",
    "    print(\"RVFE\")\n",
    "\n",
    "# More than one pronoun is classify as ambiguous\n",
    "\n",
    "# Get the highest logit among the ambiguous ones\n",
    "highest_ambiguous_pronoun_logit = ambiguous_pronouns_logits.max()\n",
    "\n",
    "# Identity the position of the logit that should correspond to the ambiguous prononun class (2)\n",
    "ambiguous_pronoun_mask = a[0] == highest_ambiguous_pronoun_logit\n",
    "\n",
    "# All the predictions that are not of that class are set to the \"not ambiguous class\" (1)\n",
    "a[1][~ambiguous_pronoun_mask] = 1\n",
    "\n",
    "# However, With this function, it may happen again that we have multiple pronouns classified as ambiguous, \n",
    "# since there may be more than one logit with value = highest_ambiguous_pronoun_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "79eb4952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 2])"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "0ec5aa6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ambiguous_pronouns_logits.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "fb962562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1] == ambiguous_pronouns_logits.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "fe0a3956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1][multiple_ambiguous_pronouns_mask][ambiguous_pronouns_logits.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "359a5f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 2, 2])"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "fe19cf58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "torch.index_select(predicted_classes[multiple_ambiguous_pronouns_mask], dim=0, index=torch.tensor([1]))\n",
    "\n",
    "torch.select(predicted_classes[multiple_ambiguous_pronouns_mask], dim=0, index=torch.tensor(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "09b1a1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2])"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = torch.index_select(a[1][multiple_ambiguous_pronouns_mask], dim=0, index=ambiguous_pronouns_logits.argmax())\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "335c8afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2])"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "10353ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.select(a[1][multiple_ambiguous_pronouns_mask], dim=0, index=ambiguous_pronouns_logits.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "b388c0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the highest logit among the ambiguous ones\n",
    "ambiguous_pronoun_logit = a[0][multiple_ambiguous_pronouns_mask].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "0d1caea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  True], device='cuda:0')"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identity the position of the logit that should correspond to the ambiguous prononun class (2)\n",
    "ambiguous_pronoun_mask = a[0] == ambiguous_pronoun_logit\n",
    "ambiguous_pronoun_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "c63ef1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the predictions that are not of that class are set to not ambiguous (1)\n",
    "a[1][~ambiguous_pronoun_mask] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "8df6a085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 2], device='cuda:0')"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "fbc6297d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pron = a[0][ambiguous].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "a06462dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False,  True,  True], device='cuda:0')"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ambiguous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "01497eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = a[0][ambiguous].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "d246f07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1, device='cuda:0')"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][ambiguous].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "33c8230b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  True], device='cuda:0')"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pro = a[0] == m\n",
    "pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "f9b51434",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[1][~pro] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "5901dc16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 2], device='cuda:0')"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "833ce8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.7404, 4.1840, 2.3523, 3.0847], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if a[0][ambiguous].shape != 1:\n",
    "    print(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1024a1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].argmax(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5748038c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx, pred_list in enumerate(y_pred_list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2a209ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "208c36cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_pred_ = 0\n",
    "for idx, pred_list in enumerate(y_pred_list):\n",
    "    c = 0\n",
    "    for num in pred_list:\n",
    "        if num == 2:\n",
    "            c += 1\n",
    "            \n",
    "    if c > 1:\n",
    "        print(idx)\n",
    "        count_pred_ += 1\n",
    "        \n",
    "    elif c == 0:\n",
    "        print(idx)\n",
    "        count_pred_ += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "927fefd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_pred_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ad8e9ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 2, 1]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_list[65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d2a8f92f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Pred\n",
      "Id: 1\n",
      "2 1\n",
      "Id: 2\n",
      "2 1\n",
      "Id: 3\n",
      "2 1\n",
      "Id: 4\n",
      "2 1\n",
      "Id: 5\n",
      "2 1\n",
      "Id: 7\n",
      "2 1\n",
      "Id: 8\n",
      "2 1\n",
      "Id: 11\n",
      "2 1\n",
      "Id: 14\n",
      "2 1\n",
      "Id: 15\n",
      "1 2\n",
      "Id: 16\n",
      "2 1\n",
      "Id: 17\n",
      "1 2\n",
      "Id: 18\n",
      "2 1\n",
      "Id: 20\n",
      "2 1\n",
      "Id: 22\n",
      "2 1\n",
      "Id: 23\n",
      "2 1\n",
      "Id: 28\n",
      "2 1\n",
      "Id: 29\n",
      "2 1\n",
      "Id: 30\n",
      "2 1\n",
      "Id: 31\n",
      "2 1\n",
      "Id: 34\n",
      "2 1\n",
      "Id: 36\n",
      "2 1\n",
      "Id: 37\n",
      "2 1\n",
      "Id: 39\n",
      "2 1\n",
      "Id: 42\n",
      "2 1\n",
      "Id: 45\n",
      "2 1\n",
      "Id: 46\n",
      "2 1\n",
      "Id: 48\n",
      "2 1\n",
      "Id: 53\n",
      "2 1\n",
      "Id: 53\n",
      "1 2\n",
      "Id: 54\n",
      "2 1\n",
      "Id: 55\n",
      "2 1\n",
      "Id: 57\n",
      "2 1\n",
      "Id: 59\n",
      "2 1\n",
      "Id: 60\n",
      "2 1\n",
      "Id: 62\n",
      "2 1\n",
      "Id: 64\n",
      "2 1\n",
      "Id: 64\n",
      "1 2\n",
      "Id: 65\n",
      "2 1\n",
      "Id: 67\n",
      "2 1\n",
      "Id: 72\n",
      "2 1\n",
      "Id: 73\n",
      "1 2\n",
      "Id: 74\n",
      "2 1\n",
      "Id: 76\n",
      "1 2\n",
      "Id: 76\n",
      "2 1\n",
      "Id: 77\n",
      "2 1\n",
      "Id: 77\n",
      "1 2\n",
      "Id: 79\n",
      "2 1\n",
      "Id: 80\n",
      "1 2\n",
      "Id: 82\n",
      "1 2\n",
      "Id: 83\n",
      "2 1\n",
      "Id: 83\n",
      "1 2\n",
      "Id: 85\n",
      "2 1\n",
      "Id: 87\n",
      "1 2\n",
      "Id: 87\n",
      "2 1\n",
      "Id: 89\n",
      "2 1\n",
      "Id: 90\n",
      "2 1\n",
      "Id: 90\n",
      "1 2\n",
      "Id: 95\n",
      "2 1\n",
      "Id: 99\n",
      "2 1\n",
      "Id: 102\n",
      "2 1\n",
      "Id: 105\n",
      "2 1\n",
      "Id: 106\n",
      "1 2\n",
      "Id: 107\n",
      "2 1\n",
      "Id: 111\n",
      "2 1\n",
      "Id: 113\n",
      "2 1\n",
      "Id: 114\n",
      "2 1\n",
      "Id: 115\n",
      "2 1\n",
      "Id: 118\n",
      "2 1\n",
      "Id: 122\n",
      "1 2\n",
      "Id: 122\n",
      "1 2\n",
      "Id: 126\n",
      "2 1\n",
      "Id: 129\n",
      "2 1\n",
      "Id: 130\n",
      "2 1\n",
      "Id: 130\n",
      "1 2\n",
      "Id: 136\n",
      "1 2\n",
      "Id: 136\n",
      "2 1\n",
      "Id: 137\n",
      "2 1\n",
      "Id: 140\n",
      "2 1\n",
      "Id: 141\n",
      "1 2\n",
      "Id: 143\n",
      "2 1\n",
      "Id: 143\n",
      "1 2\n",
      "Id: 148\n",
      "2 1\n",
      "Id: 149\n",
      "2 1\n",
      "Id: 151\n",
      "2 1\n",
      "Id: 152\n",
      "2 1\n",
      "Id: 153\n",
      "2 1\n",
      "Id: 155\n",
      "2 1\n",
      "Id: 156\n",
      "2 1\n",
      "Id: 157\n",
      "2 1\n",
      "Id: 159\n",
      "2 1\n",
      "Id: 160\n",
      "1 2\n",
      "Id: 162\n",
      "2 1\n",
      "Id: 163\n",
      "2 1\n",
      "Id: 165\n",
      "1 2\n",
      "Id: 172\n",
      "2 1\n",
      "Id: 173\n",
      "2 1\n",
      "Id: 174\n",
      "2 1\n",
      "Id: 176\n",
      "2 1\n",
      "Id: 180\n",
      "2 1\n",
      "Id: 183\n",
      "2 1\n",
      "Id: 185\n",
      "2 1\n",
      "Id: 186\n",
      "1 2\n",
      "Id: 187\n",
      "1 2\n",
      "Id: 187\n",
      "2 1\n",
      "Id: 189\n",
      "2 1\n",
      "Id: 189\n",
      "1 2\n",
      "Id: 192\n",
      "2 1\n",
      "Id: 193\n",
      "1 2\n",
      "Id: 194\n",
      "2 1\n",
      "Id: 196\n",
      "2 1\n",
      "Id: 199\n",
      "2 1\n",
      "Id: 200\n",
      "2 1\n",
      "Id: 202\n",
      "2 1\n",
      "Id: 203\n",
      "2 1\n",
      "Id: 204\n",
      "2 1\n",
      "Id: 205\n",
      "2 1\n",
      "Id: 206\n",
      "2 1\n",
      "Id: 208\n",
      "2 1\n",
      "Id: 216\n",
      "2 1\n",
      "Id: 218\n",
      "2 1\n",
      "Id: 220\n",
      "2 1\n",
      "Id: 224\n",
      "2 1\n",
      "Id: 225\n",
      "2 1\n",
      "Id: 227\n",
      "2 1\n",
      "Id: 228\n",
      "2 1\n",
      "Id: 231\n",
      "2 1\n",
      "Id: 233\n",
      "2 1\n",
      "Id: 234\n",
      "2 1\n",
      "Id: 235\n",
      "2 1\n",
      "Id: 236\n",
      "1 2\n",
      "Id: 236\n",
      "2 1\n",
      "Id: 237\n",
      "2 1\n",
      "Id: 240\n",
      "2 1\n",
      "Id: 242\n",
      "2 1\n",
      "Id: 243\n",
      "2 1\n",
      "Id: 245\n",
      "2 1\n",
      "Id: 247\n",
      "2 1\n",
      "Id: 251\n",
      "2 1\n",
      "Id: 252\n",
      "2 1\n",
      "Id: 253\n",
      "2 1\n",
      "Id: 254\n",
      "1 2\n",
      "Id: 254\n",
      "2 1\n",
      "Id: 255\n",
      "2 1\n",
      "Id: 255\n",
      "1 2\n",
      "Id: 255\n",
      "1 2\n",
      "Id: 256\n",
      "2 1\n",
      "Id: 258\n",
      "2 1\n",
      "Id: 259\n",
      "2 1\n",
      "Id: 262\n",
      "2 1\n",
      "Id: 263\n",
      "2 1\n",
      "Id: 263\n",
      "1 2\n",
      "Id: 264\n",
      "2 1\n",
      "Id: 270\n",
      "2 1\n",
      "Id: 271\n",
      "1 2\n",
      "Id: 271\n",
      "2 1\n",
      "Id: 272\n",
      "2 1\n",
      "Id: 273\n",
      "2 1\n",
      "Id: 275\n",
      "1 2\n",
      "Id: 276\n",
      "2 1\n",
      "Id: 278\n",
      "2 1\n",
      "Id: 279\n",
      "2 1\n",
      "Id: 282\n",
      "2 1\n",
      "Id: 283\n",
      "1 2\n",
      "Id: 283\n",
      "2 1\n",
      "Id: 289\n",
      "2 1\n",
      "Id: 290\n",
      "2 1\n",
      "Id: 292\n",
      "2 1\n",
      "Id: 296\n",
      "2 1\n",
      "Id: 297\n",
      "2 1\n",
      "Id: 301\n",
      "2 1\n",
      "Id: 302\n",
      "2 1\n",
      "Id: 303\n",
      "2 1\n",
      "Id: 304\n",
      "2 1\n",
      "Id: 305\n",
      "1 2\n",
      "Id: 308\n",
      "2 1\n",
      "Id: 309\n",
      "1 2\n",
      "Id: 309\n",
      "1 2\n",
      "Id: 312\n",
      "2 1\n",
      "Id: 313\n",
      "2 1\n",
      "Id: 314\n",
      "2 1\n",
      "Id: 316\n",
      "2 1\n",
      "Id: 320\n",
      "2 1\n",
      "Id: 321\n",
      "2 1\n",
      "Id: 322\n",
      "2 1\n",
      "Id: 323\n",
      "2 1\n",
      "Id: 324\n",
      "2 1\n",
      "Id: 326\n",
      "2 1\n",
      "Id: 328\n",
      "2 1\n",
      "Id: 329\n",
      "2 1\n",
      "Id: 332\n",
      "2 1\n",
      "Id: 333\n",
      "2 1\n",
      "Id: 334\n",
      "2 1\n",
      "Id: 335\n",
      "2 1\n",
      "Id: 338\n",
      "2 1\n",
      "Id: 338\n",
      "1 2\n",
      "Id: 339\n",
      "2 1\n",
      "Id: 340\n",
      "2 1\n",
      "Id: 341\n",
      "2 1\n",
      "Id: 342\n",
      "2 1\n",
      "Id: 346\n",
      "2 1\n",
      "Id: 348\n",
      "1 2\n",
      "Id: 350\n",
      "2 1\n",
      "Id: 355\n",
      "2 1\n",
      "Id: 357\n",
      "2 1\n",
      "Id: 358\n",
      "2 1\n",
      "Id: 364\n",
      "2 1\n",
      "Id: 366\n",
      "1 2\n",
      "Id: 367\n",
      "1 2\n",
      "Id: 368\n",
      "1 2\n",
      "Id: 371\n",
      "2 1\n",
      "Id: 372\n",
      "2 1\n",
      "Id: 374\n",
      "2 1\n",
      "Id: 375\n",
      "1 2\n",
      "Id: 378\n",
      "2 1\n",
      "Id: 381\n",
      "2 1\n",
      "Id: 384\n",
      "2 1\n",
      "Id: 386\n",
      "2 1\n",
      "Id: 387\n",
      "2 1\n",
      "Id: 388\n",
      "1 2\n",
      "Id: 389\n",
      "2 1\n",
      "Id: 392\n",
      "2 1\n",
      "Id: 393\n",
      "1 2\n",
      "Id: 395\n",
      "2 1\n",
      "Id: 396\n",
      "2 1\n",
      "Id: 398\n",
      "2 1\n",
      "Id: 401\n",
      "2 1\n",
      "Id: 402\n",
      "1 2\n",
      "Id: 402\n",
      "2 1\n",
      "Id: 408\n",
      "2 1\n",
      "Id: 409\n",
      "2 1\n",
      "Id: 410\n",
      "2 1\n",
      "Id: 414\n",
      "1 2\n",
      "Id: 419\n",
      "2 1\n",
      "Id: 420\n",
      "2 1\n",
      "Id: 425\n",
      "2 1\n",
      "Id: 425\n",
      "1 2\n",
      "Id: 426\n",
      "2 1\n",
      "Id: 431\n",
      "2 1\n",
      "Id: 432\n",
      "2 1\n",
      "Id: 433\n",
      "1 2\n",
      "Id: 433\n",
      "2 1\n",
      "Id: 435\n",
      "1 2\n",
      "Id: 437\n",
      "2 1\n",
      "Id: 438\n",
      "2 1\n",
      "Id: 439\n",
      "2 1\n",
      "Id: 441\n",
      "2 1\n",
      "Id: 442\n",
      "2 1\n",
      "Id: 443\n",
      "2 1\n",
      "Id: 447\n",
      "2 1\n",
      "Id: 450\n",
      "2 1\n",
      "Id: 452\n",
      "2 1\n"
     ]
    }
   ],
   "source": [
    "print(\"True\", \"Pred\")\n",
    "count = 0\n",
    "count_wrong = 0\n",
    "for sentence_id, (true, pred) in enumerate(zip(y_true_list, y_pred_list)):\n",
    "\n",
    "    for idx, elem in enumerate(true):\n",
    "        if (elem == 2 and pred[idx] == 1) or (elem == 1 and pred[idx] == 2):\n",
    "#         if pred[idx] != elem:\n",
    "            print(\"Id:\", sentence_id)\n",
    "            print(elem, pred[idx])\n",
    "            count_wrong += 1\n",
    "    \n",
    "#     print(\"\\n\")\n",
    "    count += 1\n",
    "    \n",
    "#     if count == 100:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e271dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd07b832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4613686534216336"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - count_wrong / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9febb1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8458149779735683"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - count_wrong / len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "29cf2011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "for i, num in enumerate(y_true_list[18]):\n",
    "    if num == 2:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34657e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for idx, n in enumerate(y_pred_list[18]):\n",
    "    if n == 2:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cca2315a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 1, 2]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_list[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0acb56cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 1]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_list[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af4f6331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.4895,  5.2925, -0.8361],\n",
       "        [-3.7354,  1.9461,  2.5019],\n",
       "        [-3.8786,  2.7945,  1.8456],\n",
       "        [-3.7035,  1.9725,  2.2364]], device='cuda:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "16b7aac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e4add84a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertLayer(\n",
       "  (attention): BertAttention(\n",
       "    (self): BertSelfAttention(\n",
       "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (output): BertSelfOutput(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (intermediate): BertIntermediate(\n",
       "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (intermediate_act_fn): GELUActivation()\n",
       "  )\n",
       "  (output): BertOutput(\n",
       "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bert.encoder.layer[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4261128d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                                                                                                                                                                                                                                                                      validation-19\n",
       "text          But that backfires when Andy decides to renege on the prices with Dwight's client, thus voiding both a major sale for the company and wrecks Dwight's sales record. Dwight later tells false stories to Andy when the manager is in need of being caught up on his branch, in hopes of sabotaging Andy.\n",
       "pron                                                                                                                                                                                                                                                                                                              his\n",
       "p_offset                                                                                                                                                                                                                                                                                                          255\n",
       "entity_A                                                                                                                                                                                                                                                                                                       Dwight\n",
       "offset_A                                                                                                                                                                                                                                                                                                          164\n",
       "is_coref_A                                                                                                                                                                                                                                                                                                      False\n",
       "entity_B                                                                                                                                                                                                                                                                                                         Andy\n",
       "offset_B                                                                                                                                                                                                                                                                                                          200\n",
       "is_coref_B                                                                                                                                                                                                                                                                                                       True\n",
       "url                                                                                                                                                                                                                                                                         http://en.wikipedia.org/wiki/Andy_Bernard\n",
       "Name: 18, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.iloc[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "30ae9b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = GAP_AmbiguousDetection_Dataset(df_valid[18:19], tokenizer, stanza_processor, tag_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9e8602b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Andy when the manager is in need of being caught up on his branch, in hopes of sabotaging Andy.'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df_valid['text'][18]\n",
    "text[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "65125526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['But', 'that', 'back', '##fires', 'when', '<E>', 'Andy', '</E>', 'decides', 'to', 're', '##ne', '##ge', 'on', 'the', 'prices', 'with', 'Dwight', \"'\", 's', 'client', ',', 'thus', 'void', '##ing', 'both', 'a', 'major', 'sale', 'for', 'the', 'company', 'and', 'wreck', '##s', 'Dwight', \"'\", 's', 'sales', 'record', '.', '<E>', 'Dwight', '</E>', 'later', 'tells', 'false', 'stories', 'to', '<E>', 'Andy', '</E>', 'when', 'the', 'manager', 'is', 'in', 'need', 'of', 'being', 'caught', 'up', 'on', '<P>', 'his', 'branch', ',', 'in', 'hopes', 'of', 'sa', '##bot', '##aging', '<E>', 'Andy', '</E>', '.'], {'<P>': [64], '<E>': [6, 42, 74], '</E>': [7, 43, 75], '<C>': [50], '</C>': [51]})\n"
     ]
    }
   ],
   "source": [
    "print(sent.tokenize(df_valid.iloc[18]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "6bc39dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.0"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_ds) - eval_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "e5b5657b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b13971",
   "metadata": {},
   "source": [
    "## Observation: The model fails when the coreferenced mentions are both wrong? (valid 405)\n",
    "\n",
    "## Also fails when the mention comes after the pronoun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "fc28b349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                                                                                                                                                                                                                                                                                                                                                                validation-173\n",
       "text          Lizzie also is very sure Sasha is dead. She also shows a disliking towards Tyreese. After Lizzie kills Mika, Carol and Tyreese realize that she is too psychotic to be kept around & had to be executed in order for Judith to be safe, so Carol leads her out to the fields to look at the flowers, and as Lizzie tried to apologize for having threatened Carol and Tyreese, Carol executed her.\n",
       "pron                                                                                                                                                                                                                                                                                                                                                                                                         her\n",
       "p_offset                                                                                                                                                                                                                                                                                                                                                                                                     247\n",
       "entity_A                                                                                                                                                                                                                                                                                                                                                                                                  Lizzie\n",
       "offset_A                                                                                                                                                                                                                                                                                                                                                                                                     300\n",
       "is_coref_A                                                                                                                                                                                                                                                                                                                                                                                                  True\n",
       "entity_B                                                                                                                                                                                                                                                                                                                                                                                                   Carol\n",
       "offset_B                                                                                                                                                                                                                                                                                                                                                                                                     348\n",
       "is_coref_B                                                                                                                                                                                                                                                                                                                                                                                                 False\n",
       "url                                                                                                                                                                                                                                                                                                                                 http://en.wikipedia.org/wiki/List_of_The_Walking_Dead_(TV_series)_characters\n",
       "Name: 172, dtype: object"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.iloc[172]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "39b0b27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'her out to the fields to look at the flowers, and as Lizzie tried to apologize for having threatened Carol and Tyreese, Carol executed her.'"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid['text'][172][247:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "9eacf29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'she'"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 172\n",
    "tokenizer.convert_ids_to_tokens(valid_ds[index][0])[valid_ds[index][1][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577f7f88",
   "metadata": {},
   "source": [
    "# Remove double punctuation symbols. -- '' (valid_ds 64 67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f9277db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_valid['text'][64].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "240ce35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.convert_ids_to_tokens(valid_ds[67][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "d59e6346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.7543,  4.1640, -0.2318],\n",
       "        [-3.6449,  1.0342,  3.1476],\n",
       "        [-3.5492,  3.7941, -0.2013]], device='cuda:0')"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[171]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "49ea8506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0198, 0.0193, 0.0199, 0.0195, 0.0249, 0.0259, 0.6350, 0.1268, 0.0598,\n",
       "        0.0491], device='cuda:0')"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "F.softmax(logits[184][:,2], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "5211e48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.4585, -1.4833, -1.4543, -1.4747, -1.2275, -1.1908,  2.0098,  0.3989,\n",
       "        -0.3531, -0.5495], device='cuda:0')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[184][:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "3790cacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "tokens_labels = []\n",
    "scores = []\n",
    "\n",
    "for idx, feature in enumerate(valid_ds):\n",
    "    tokens = feature[0]\n",
    "    offsets = feature[1]\n",
    "    \n",
    "    tokens_labels.append(tokenizer.convert_ids_to_tokens(tokens))\n",
    "    \n",
    "    score = [0 for _ in range(len(tokens))]\n",
    "    \n",
    "    for i_off, off in enumerate(offsets):\n",
    "        score[off] =  round(F.softmax(logits[idx][:,2], dim=0)[i_off].item(), 5)\n",
    "  \n",
    "    scores.append(score)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "e8657ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[34, 48, 61, 75, 99]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ds[98][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "9d0c795d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores[447]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "129ad16e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2400x800 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = 171\n",
    "\n",
    "figure(figsize=(30, 10), dpi=80)\n",
    "# Create a barplot showing the start word score for all of the tokens.\n",
    "ax = sns.barplot(x=tokens_labels[index], y=scores[index], ci=None)\n",
    "\n",
    "# Turn the xlabels vertical.\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"center\")\n",
    "\n",
    "# Turn on the vertical grid to help align words to scores.\n",
    "ax.grid(True)\n",
    "\n",
    "plt.title('Start Word Scores')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "a20cf6e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              validation-88\n",
       "text          Jenkins reaction to those comments saw him reach the semi final of the 2010 European Championship Darts, losing narrowly again to Phil Taylor in a classic 11-10, but showing a welcome return to form. Jenkins had a decent 2010 Grand Slam of Darts, beating Tony O'Shea in the 2nd round before succombing to a final leg decider to James Wade. Following his Grand Slam of Darts quarter final defeat to Wade, Jenkins said in an interview that he believed players raise their game when they play him, as an example, Raymond van Barneveld struggled for form during the premier league campaign, but managed to beat Jenkins twice and hit a nine darter aganist him.\n",
       "pron                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      him\n",
       "p_offset                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  490\n",
       "entity_A                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Raymond van Barneveld\n",
       "offset_A                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  510\n",
       "is_coref_A                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              False\n",
       "entity_B                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Jenkins\n",
       "offset_B                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  607\n",
       "is_coref_B                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               True\n",
       "url                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                http://en.wikipedia.org/wiki/Terry_Jenkins\n",
       "Name: 87, dtype: object"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.iloc[87]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "1a2a7354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'In',\n",
       " '1924',\n",
       " 'Arthur',\n",
       " 'Raymond',\n",
       " 'Hi',\n",
       " '##bbe',\n",
       " '##rt',\n",
       " 'was',\n",
       " 'born',\n",
       " 'in',\n",
       " 'End',\n",
       " '##er',\n",
       " '##by',\n",
       " ',',\n",
       " 'Leicestershire',\n",
       " ',',\n",
       " 'the',\n",
       " 'son',\n",
       " 'of',\n",
       " 'Canon',\n",
       " 'H',\n",
       " '.',\n",
       " 'V',\n",
       " '.',\n",
       " 'Hi',\n",
       " '##bbe',\n",
       " '##rt',\n",
       " '(',\n",
       " 'd',\n",
       " '.',\n",
       " '1980',\n",
       " ')',\n",
       " 'and',\n",
       " 'his',\n",
       " 'wife',\n",
       " 'Maud',\n",
       " '##e',\n",
       " ',',\n",
       " 'and',\n",
       " 'was',\n",
       " 'educated',\n",
       " 'at',\n",
       " 'Ra',\n",
       " '##dley',\n",
       " 'College',\n",
       " ',',\n",
       " 'before',\n",
       " 'he',\n",
       " 'went',\n",
       " 'up',\n",
       " 'to',\n",
       " 'Or',\n",
       " '##iel',\n",
       " 'College',\n",
       " 'at',\n",
       " 'the',\n",
       " 'University',\n",
       " 'of',\n",
       " 'Oxford',\n",
       " '.',\n",
       " 'He',\n",
       " 'was',\n",
       " 'awarded',\n",
       " 'the',\n",
       " 'degrees',\n",
       " 'of',\n",
       " 'B',\n",
       " '.',\n",
       " 'A',\n",
       " '.',\n",
       " 'and',\n",
       " 'later',\n",
       " 'MA',\n",
       " '.',\n",
       " 'He',\n",
       " 'left',\n",
       " 'Or',\n",
       " '##iel',\n",
       " 'College',\n",
       " 'to',\n",
       " 'join',\n",
       " 'the',\n",
       " 'Army',\n",
       " ',',\n",
       " 'where',\n",
       " 'a',\n",
       " 'sergeant',\n",
       " 'major',\n",
       " 'referred',\n",
       " 'to',\n",
       " 'Hi',\n",
       " '##bbe',\n",
       " '##rt',\n",
       " 'as',\n",
       " 'Christopher',\n",
       " 'Robin',\n",
       " 'based',\n",
       " 'upon',\n",
       " 'his',\n",
       " 'youthful',\n",
       " 'looks',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_labels[98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "169cc6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1140"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ds[87][0][104]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "71f54e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'him'"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(1140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "665abfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = output.view(-1, output.shape[-1])\n",
    "labels = labels.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8c74e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = labels != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b75363f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# l = labels[mask].tolist() \n",
    "l = labels[mask]\n",
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf023c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred.argmax(1)\n",
    "# p = pred[mask].tolist()\n",
    "p = pred[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18c4a500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(p == l).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "316eef0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d69cca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function taken from the 'evaluate.py' script\n",
    "def flat_list(l: List[List[Any]]) -> List[Any]:\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    -------\n",
    "        A single list containing all elements that\n",
    "        were in the input list.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    l: List[List[Any]]\n",
    "        A list of lists of any type\n",
    "    \"\"\"\n",
    "    return [_e for e in l for _e in e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "599df696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9973)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchmetrics import F1Score\n",
    "\n",
    "f1 = F1Score(3)\n",
    "f1(torch.tensor(flat_list(y_pred_list)), torch.tensor(flat_list(y_true_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a223155d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efb3d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8e9715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fb954d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4149b3ad",
   "metadata": {
    "id": "4149b3ad",
    "outputId": "bb0ab979-3747-4941-f533-1e06ca29d047"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "| LR: 1.000e-05 |\n",
      "| epoch   2/10  |\n"
     ]
    }
   ],
   "source": [
    "epoch = 1\n",
    "epochs = 10\n",
    "s = 0.00001\n",
    "print('-' * 17)\n",
    "print(f\"| LR: {s:.3e} |\")\n",
    "print(f'| epoch {epoch+1:>3d}/{epochs:<3d} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8569d8f9",
   "metadata": {
    "id": "8569d8f9",
    "outputId": "57936374-9bc5-47ed-a694-4ad2953e0ea5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(metrics_history['train_acc'])\n",
    "plt.plot(metrics_history['valid_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e847996d",
   "metadata": {
    "id": "e847996d",
    "outputId": "931b0268-2a3b-443c-dc6c-525121e52d23"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_linear_schedule_with_warmup() missing 3 required positional arguments: 'optimizer', 'num_warmup_steps', and 'num_training_steps'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21352\\2506784198.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mscheduler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_linear_schedule_with_warmup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: get_linear_schedule_with_warmup() missing 3 required positional arguments: 'optimizer', 'num_warmup_steps', and 'num_training_steps'"
     ]
    }
   ],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcc7055",
   "metadata": {
    "id": "bfcc7055",
    "outputId": "91099e06-378b-4b8b-c1d2-5cd2fbd75b71"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_resumed = GAPModel(model_name_or_path).to(device, non_blocking=True)\n",
    "optimizer_resumed = torch.optim.Adam(model_resumed.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a3799f",
   "metadata": {
    "id": "f9a3799f"
   },
   "outputs": [],
   "source": [
    "path = \"../../model/checkpoints/my_model_861_6.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683896dc",
   "metadata": {
    "id": "683896dc"
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(path, map_location=device)\n",
    "model_resumed.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer_resumed.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0617e0d",
   "metadata": {
    "id": "e0617e0d"
   },
   "outputs": [],
   "source": [
    "# del checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02d185d",
   "metadata": {
    "id": "a02d185d",
    "outputId": "a19a33b5-747b-414b-f51a-15fdae74ea22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    initial_lr: 5e-06\n",
       "    lr: 2.5e-06\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer_resumed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7d971b",
   "metadata": {
    "id": "dd7d971b",
    "outputId": "45dc87cc-1d6a-4de3-8cfc-8d18e52d9139"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(checkpoint['scheduler_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5c3b5f",
   "metadata": {
    "id": "da5c3b5f"
   },
   "outputs": [],
   "source": [
    "scheduler_resumed = torch.optim.lr_scheduler.StepLR(optimizer_resumed, step_size=4, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d60c3a",
   "metadata": {
    "id": "b3d60c3a"
   },
   "outputs": [],
   "source": [
    "scheduler_resumed.load_state_dict(checkpoint['scheduler_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd48209e",
   "metadata": {
    "id": "dd48209e",
    "outputId": "6dedfb7b-a93e-4b32-9275-77da7aad5749"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../model/checkpoints\\my_model_861_6.pth\n",
      "861_6\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "directory = \"../../model/checkpoints/*.pth\"\n",
    "files = glob.glob(directory)\n",
    "\n",
    "for file in files:\n",
    "    print(file)\n",
    "    print(file[-9:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d78d01",
   "metadata": {
    "id": "01d78d01",
    "outputId": "d8d325cb-1780-40be-a878-d38f59c6a88e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41, 42, 44, 44, 61]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(train_ds[0][0])\n",
    "# tokens[train_ds[0][1][0] - 1]\n",
    "train_ds[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ad9afe",
   "metadata": {
    "id": "36ad9afe",
    "outputId": "6b9cc51f-8378-4a0a-f39f-a9f85115b9f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cheryl', 'cassidy']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[42:44]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095dabb5",
   "metadata": {
    "id": "095dabb5"
   },
   "source": [
    "A List with your predictions.\n",
    "\n",
    "Each prediction is a tuple, composed by two tuples:\n",
    "(ambigous_pronoun, ambiguous_pronoun_offset), (coreferent_entity, coreferent_entity_offset))\n",
    "\n",
    "for example:\n",
    "    [(('her', 274), ('Pauline', 418))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf34075",
   "metadata": {
    "id": "6bf34075"
   },
   "source": [
    "I need to know the original positions.\n",
    "\n",
    "The model return the label prediction (0 1 2)\n",
    "\n",
    "If pred == 0 => A\n",
    "\n",
    "elif pred == 1 => B\n",
    "\n",
    "else => --\n",
    "\n",
    "I have to know:\n",
    "1. The pronoun and its pos\n",
    "2. The predicted entity and its pos\n",
    "\n",
    "\n",
    "1. I can retrieve the pronoun through the last offset in offsets after encoding the ids.\n",
    "    I also need its original position.\n",
    "    \n",
    "2. \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180d6256",
   "metadata": {
    "id": "180d6256"
   },
   "outputs": [],
   "source": [
    "def read_dataset(path: str) -> List[Dict]:\n",
    "    samples: List[Dict] = []\n",
    "    pron_counter = Counter()\n",
    "    with open(path) as f:\n",
    "        next(f)\n",
    "        for line in f:\n",
    "            (\n",
    "                id,\n",
    "                text,\n",
    "                pron,\n",
    "                p_offset,\n",
    "                entity_A,\n",
    "                offset_A,\n",
    "                is_coref_A,\n",
    "                entity_B,\n",
    "                offset_B,\n",
    "                is_coref_B,\n",
    "                url,\n",
    "            ) = line.strip().split(\"\\t\")\n",
    "            pron_counter[pron.lower()] += 1\n",
    "            samples.append(\n",
    "                {\n",
    "                    \"id\": id,\n",
    "                    \"text\": text,\n",
    "                    \"pron\": pron,\n",
    "                    \"p_offset\": int(p_offset),\n",
    "                    \"entity_A\": entity_A,\n",
    "                    \"offset_A\": int(offset_A),\n",
    "                    \"is_coref_A\": is_coref_A,\n",
    "                    \"entity_B\": entity_B,\n",
    "                    \"offset_B\": int(offset_B),\n",
    "                    \"is_coref_B\": is_coref_B,\n",
    "                    \"url\": url,\n",
    "                }\n",
    "            )\n",
    "    print(pron_counter)\n",
    "    return samples, pron_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a8bee5",
   "metadata": {
    "id": "b8a8bee5"
   },
   "outputs": [],
   "source": [
    "train_path = \"../../model/data/train.tsv\"\n",
    "valid_path = \"../../model/data/dev.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab5e64b",
   "metadata": {
    "id": "4ab5e64b",
    "outputId": "067c9bad-ec3a-4414-8989-e1fdaf39e8a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'his': 904, 'her': 773, 'he': 610, 'she': 555, 'him': 157})\n",
      "Counter({'her': 140, 'his': 108, 'he': 93, 'she': 87, 'him': 26})\n"
     ]
    }
   ],
   "source": [
    "train_dataset, train_pron_counter = read_dataset(train_path)\n",
    "valid_dataset, valid_pron_counter = read_dataset(valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbc6e74",
   "metadata": {
    "id": "7cbc6e74",
    "outputId": "611ea31b-3883-4644-c1df-057ce66f683e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'train-1',\n",
       " 'text': \"Zoe Telford -- played the police officer girlfriend of Simon, Maggie. Dumped by Simon in the final episode of series 1, after he slept with Jenny, and is not seen again. Phoebe Thomas played Cheryl Cassidy, Pauline's friend and also a year 11 pupil in Simon's class. Dumped her boyfriend following Simon's advice after he wouldn't have sex with her but later realised this was due to him catching crabs off her friend Pauline.\",\n",
       " 'pron': 'her',\n",
       " 'p_offset': 274,\n",
       " 'entity_A': 'Cheryl Cassidy',\n",
       " 'offset_A': 191,\n",
       " 'is_coref_A': 'TRUE',\n",
       " 'entity_B': 'Pauline',\n",
       " 'offset_B': 207,\n",
       " 'is_coref_B': 'FALSE',\n",
       " 'url': 'http://en.wikipedia.org/wiki/List_of_Teachers_(UK_TV_series)_characters'}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e635bc0e",
   "metadata": {
    "id": "e635bc0e"
   },
   "outputs": [],
   "source": [
    "def get_entity_and_offset_from_id(label_id, sentence):\n",
    "    if label_id == 0: # Entity A\n",
    "        return sentence['entity_A'], sentence['offset_A']\n",
    "    elif label_id == 1: # Entity B\n",
    "        return sentence['entity_B'], sentence['offset_B']\n",
    "    else: # Neither\n",
    "        return None, None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a00c15d",
   "metadata": {
    "id": "3a00c15d",
    "outputId": "2390d1d4-9f8b-4102-ee5b-1d15fa04e839"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_entity_and_offset_from_id(2, train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca534a6",
   "metadata": {
    "id": "6ca534a6"
   },
   "outputs": [],
   "source": [
    "def predict(model, sentences: List[Dict]) -> List[Tuple[Tuple[str, int], Tuple[str, int]]]:\n",
    "    df = pd.DataFrame(sentences)\n",
    "    \n",
    "    # tokenizer will be self.tokenizer in the final implementation\n",
    "    dataset = GAPDataset(df, tokenizer)\n",
    "    collator = Collator(device)\n",
    "\n",
    "    predictions = []\n",
    "    \n",
    "    #self.model.eval()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        dataloader = DataLoader(dataset, batch_size=1, \n",
    "                                collate_fn=collator, shuffle=False)\n",
    "        \n",
    "        for (features, offsets, labels), sentence in zip(dataloader, sentences):\n",
    "            \n",
    "#             predictions = self.model(features, offsets).argmax(1).item()\n",
    "            predicted_label_id = model(features, offsets).argmax(1).item()\n",
    "            pred_entity, pred_entity_offset = get_entity_and_offset_from_id(predicted_label_id, sentence)\n",
    "            pron, pron_offset = sentence['pron'],  sentence['p_offset']\n",
    "            \n",
    "            predictions.append(((pron, pron_offset), (pred_entity, pred_entity_offset)))\n",
    "            \n",
    "    return predictions\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c427614f",
   "metadata": {
    "id": "c427614f"
   },
   "outputs": [],
   "source": [
    "pred = predict(model_resumed, valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bba0ffa",
   "metadata": {
    "id": "9bba0ffa"
   },
   "outputs": [],
   "source": [
    "gold_values = []\n",
    "for sentence in valid_dataset:\n",
    "    gold_both_wrong = sentence[\"is_coref_A\"] == \"FALSE\" and sentence[\"is_coref_B\"] == \"FALSE\"\n",
    "    if gold_both_wrong:\n",
    "        gold_entity_offset = None\n",
    "        gold_entity = None\n",
    "    else:\n",
    "        gold_entity_offset = (\n",
    "            sentence[\"offset_A\"] if sentence[\"is_coref_A\"] == \"TRUE\" else sentence[\"offset_B\"]\n",
    "        )\n",
    "        gold_entity = (\n",
    "            sentence[\"entity_A\"] if sentence[\"is_coref_A\"] == \"TRUE\" else sentence[\"entity_B\"]\n",
    "        )\n",
    "    \n",
    "    \n",
    "    gold_values.append(((sentence['pron'], sentence['p_offset']),(gold_entity, gold_entity_offset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94057fda",
   "metadata": {
    "id": "94057fda",
    "outputId": "dd206596-b432-4181-f96d-97e7a2f3f1ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {}\n",
    "\n",
    "a.setdefault(\"age\", 0)\n",
    "a.setdefault(\"age\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940ba563",
   "metadata": {
    "id": "940ba563",
    "outputId": "dd0b78b1-dc5f-4023-dd76-677df3ffe869"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 0, 'a': 0}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['a'] = 0\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86c72b7",
   "metadata": {
    "id": "b86c72b7"
   },
   "outputs": [],
   "source": [
    "wrong = []\n",
    "for p, g in zip(pred, gold_values):\n",
    "    if g[1][0] != p[1][0]:\n",
    "        wrong.append((g, p))\n",
    "#     print(p[1], g[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5f3f38",
   "metadata": {
    "id": "5d5f3f38"
   },
   "outputs": [],
   "source": [
    "pr = wrong[0][0][0][0]\n",
    "get_gender(\"she\")\n",
    "\n",
    "gender = {}\n",
    "\n",
    "for pair in wrong:\n",
    "    pr = pair[0][0][0]\n",
    "    gender.setdefault(get_gender(pr.lower()), 0)\n",
    "    gender[get_gender(pr.lower())] += 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ef2627",
   "metadata": {
    "id": "19ef2627",
    "outputId": "39bd69ff-30b3-4107-9796-c65d11499e76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 35, 0: 34}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d475e6f",
   "metadata": {
    "id": "2d475e6f",
    "outputId": "b09b0735-78cd-41d6-f2ab-a67274d07c31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'validation-2',\n",
       " 'text': \"Kathleen Nott was born in Camberwell, London. Her father, Philip, was a lithographic printer, and her mother, Ellen, ran a boarding house in Brixton; Kathleen was their third daughter. She was educated at Mary Datchelor Girls' School (now closed), London, before attending King's College, London.\",\n",
       " 'pron': 'She',\n",
       " 'p_offset': 185,\n",
       " 'entity_A': 'Ellen',\n",
       " 'offset_A': 110,\n",
       " 'is_coref_A': 'FALSE',\n",
       " 'entity_B': 'Kathleen',\n",
       " 'offset_B': 150,\n",
       " 'is_coref_B': 'TRUE',\n",
       " 'url': 'http://en.wikipedia.org/wiki/Kathleen_Nott'}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f429bd56",
   "metadata": {
    "id": "f429bd56"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(predictions_s, samples):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for pred, label in zip(predictions_s, samples):\n",
    "        gold_pron_offset = label[\"p_offset\"]\n",
    "        pred_pron_offset = pred[0][1] if len(pred[0]) > 0 else None\n",
    "        gold_pron = label[\"pron\"]\n",
    "        pred_pron = pred[0][0] if len(pred[0]) > 0 else None\n",
    "        gold_both_wrong = label[\"is_coref_A\"] == \"FALSE\" and label[\"is_coref_B\"] == \"FALSE\"\n",
    "        pred_entity_offset = pred[1][1] if len(pred[1]) > 0 else None\n",
    "        pred_entity = pred[1][0] if len(pred[1]) > 0 else None\n",
    "              \n",
    "        if gold_both_wrong:\n",
    "            if pred_entity is None and gold_pron_offset == pred_pron_offset and gold_pron == pred_pron:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "        else:\n",
    "            gold_entity_offset = (\n",
    "                label[\"offset_A\"] if label[\"is_coref_A\"] == \"TRUE\" else label[\"offset_B\"]\n",
    "            )\n",
    "            gold_entity = (\n",
    "                label[\"entity_A\"] if label[\"is_coref_A\"] == \"TRUE\" else label[\"entity_B\"]\n",
    "            )\n",
    "            if (\n",
    "                gold_pron_offset == pred_pron_offset\n",
    "                and gold_pron == pred_pron\n",
    "                and gold_entity_offset == pred_entity_offset\n",
    "                and gold_entity == pred_entity\n",
    "            ):\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    \n",
    "    print(f\"# instances: {total}\")\n",
    "    acc = float(correct) / total\n",
    "    print(f\"# accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f970c3d9",
   "metadata": {
    "id": "f970c3d9",
    "outputId": "a73a7b89-4175-45f2-ce1b-1c88e4ee808e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# instances: 454\n",
      "# accuracy: 0.8568\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(pred, valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3908b386",
   "metadata": {
    "id": "3908b386"
   },
   "outputs": [],
   "source": [
    "from arguments import CustomTrainingArguments\n",
    "a = CustomTrainingArguments(output_dir=\"c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaff3c45",
   "metadata": {
    "id": "aaff3c45",
    "outputId": "a920bfef-2e7b-405d-e992-5756cf1ea819"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomTrainingArguments(output_dir='c', resume_from_checkpoint=None, save_model=False, num_train_epochs=3, logging_steps=250, learning_rate=0.0005, grad_clipping=None, early_stopping=False, early_stopping_mode='max', early_stopping_patience=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7ae21f",
   "metadata": {
    "id": "0b7ae21f",
    "outputId": "22c6c145-e93b-4a94-f7fb-47600fbbc5cc"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'resume_from_checkpoint'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9356\\1665919785.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msafe_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0marg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCustomTrainingArguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'training_args'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'resume_from_checkpoint'"
     ]
    }
   ],
   "source": [
    "from arguments import CustomTrainingArguments\n",
    "\n",
    "yaml_file = \"./train.yaml\"\n",
    "\n",
    "# Read configuration file with all the necessary parameters\n",
    "with open(yaml_file) as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    \n",
    "arg = CustomTrainingArguments(**config['training_args'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e9ff37",
   "metadata": {
    "id": "d9e9ff37",
    "outputId": "0b3baa1d-1449-4619-deea-490de73200d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomTrainingArguments(output_dir='../../model/checkpoints/', num_train_epochs=6, logging_steps=250, save_model=False, learning_rate=5e-06, grad_clipping=None, early_stopping=False, early_stopping_mode='max', early_stopping_patience=0)\n"
     ]
    }
   ],
   "source": [
    "print(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a6450b",
   "metadata": {
    "id": "c3a6450b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Training.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.7 (DL)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
