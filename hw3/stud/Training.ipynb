{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wIOz40JYJddq",
   "metadata": {
    "id": "wIOz40JYJddq"
   },
   "outputs": [],
   "source": [
    "# ! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3244dc15",
   "metadata": {
    "executionInfo": {
     "elapsed": 8630,
     "status": "ok",
     "timestamp": 1660493913007,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "3244dc15"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import (\n",
    "    Trainer,\n",
    "    BertTokenizer,\n",
    "    BertModel\n",
    ")\n",
    "import transformers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import time\n",
    "import yaml\n",
    "from typing import *\n",
    "from arguments import CustomTrainingArguments\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "SEED = 10\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Display the entire text\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58276aa2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 208,
     "status": "ok",
     "timestamp": 1660493916533,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "58276aa2",
    "outputId": "0b14ad80-9dd6-4da5-cfab-36c155684301"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "kYGIp3MoJug2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16671,
     "status": "ok",
     "timestamp": 1660493967859,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "kYGIp3MoJug2",
    "outputId": "c91f8476-ea76-432b-e1b9-757f3546e044"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eljw893sJ5t1",
   "metadata": {
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1660494196549,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "eljw893sJ5t1"
   },
   "outputs": [],
   "source": [
    "train_clean_path = \"/content/drive/MyDrive/Colab Notebooks/Deep Learning/NLP/nlp2022-hw3/model/data/train_clean.tsv\"\n",
    "valid_clean_path = \"/content/drive/MyDrive/Colab Notebooks/Deep Learning/NLP/nlp2022-hw3/model/data/valid_clean.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3633ef51",
   "metadata": {
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1660494139597,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "3633ef51"
   },
   "outputs": [],
   "source": [
    "train_clean_path = \"../../model/data/train_clean.tsv\"\n",
    "valid_clean_path = \"../../model/data/valid_clean.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "B1CvSmUrKc1y",
   "metadata": {
    "executionInfo": {
     "elapsed": 1219,
     "status": "ok",
     "timestamp": 1660494199029,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "B1CvSmUrKc1y"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(filepath_or_buffer=train_clean_path, sep=\"\\t\")\n",
    "df_valid = pd.read_csv(filepath_or_buffer=valid_clean_path, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f5ec9c1",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1660494206486,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "1f5ec9c1"
   },
   "outputs": [],
   "source": [
    "FEMININE = 0\n",
    "MASCULINE = 1\n",
    "UNKNOWN = 2\n",
    "\n",
    "def get_gender(pronoun: str):\n",
    "    gender_mapping = {\n",
    "        'she': FEMININE,\n",
    "        'her': FEMININE,\n",
    "        'he': MASCULINE,\n",
    "        'his': MASCULINE,\n",
    "        'him': MASCULINE,\n",
    "    }\n",
    "\n",
    "    return gender_mapping.get(pronoun.lower(), UNKNOWN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4df00da9",
   "metadata": {
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1660494208917,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "4df00da9"
   },
   "outputs": [],
   "source": [
    "class GAPDataset(Dataset):\n",
    "    \"\"\"Custom GAP Dataset class\"\"\"\n",
    "\n",
    "    def __init__(self, df, tokenizer, labeled=True):\n",
    "        self.df = df\n",
    "\n",
    "        self.labeled = labeled\n",
    "        self.tokenizer = tokenizer\n",
    "        self.offsets, self.tokens = [], []\n",
    "#         self.original_offsets = []\n",
    "\n",
    "        if labeled:\n",
    "            self._extract_target()\n",
    "            self.labels = df.target.values.astype(\"uint8\")\n",
    "\n",
    "        self._convert_tokens_to_ids()\n",
    "\n",
    "    @staticmethod\n",
    "    def get_class_id(is_coref_A: Union[str, bool], is_coref_B: Union[str, bool]) -> int:\n",
    "        if is_coref_A == \"TRUE\" or is_coref_A is True:\n",
    "            return 0\n",
    "        elif is_coref_B == \"TRUE\" or is_coref_B is True:\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "        \n",
    "    def _extract_target(self):\n",
    "        self.df['target'] = [self.get_class_id(is_coref_A, is_coref_B) \n",
    "                             for is_coref_A, is_coref_B in zip(self.df['is_coref_A'],  \n",
    "                                                               self.df['is_coref_B'])]\n",
    "        \n",
    "    def _convert_tokens_to_ids(self):\n",
    "        CLS = [self.tokenizer.cls_token]\n",
    "        SEP = [self.tokenizer.sep_token]\n",
    "\n",
    "        for _, row in self.df.iterrows():\n",
    "            tokens, offsets = self._tokenize(row)\n",
    "#             self.original_offsets.append([row.offset_A, row.offset_B, row.p_offset])\n",
    "            self.offsets.append(offsets)\n",
    "            self.tokens.append(self.tokenizer.convert_tokens_to_ids(\n",
    "                CLS + tokens + SEP))\n",
    "\n",
    "    def _tokenize(self, row):\n",
    "        # The order is important because we want the pronoun to come after all the\n",
    "        # coreferenced entities in the output, even if B could come after the pronoun.\n",
    "        break_points = sorted([\n",
    "            (\"A\", row['offset_A'], row['entity_A']),\n",
    "            (\"B\", row['offset_B'], row['entity_B']),\n",
    "            (\"P\", row['p_offset'], row['pron'])\n",
    "        ], key=lambda x: x[0])\n",
    "\n",
    "        tokens, spans, current_pos = [], {}, 0\n",
    "        for name, offset, text in break_points:\n",
    "            tokens.extend(self.tokenizer.tokenize(\n",
    "                row[\"text\"][current_pos:offset]))\n",
    "            # Make sure we do not get it wrong\n",
    "            assert row[\"text\"][offset:offset+len(text)] == text\n",
    "            # Tokenize the target\n",
    "            tmp_tokens = self.tokenizer.tokenize(\n",
    "                row[\"text\"][offset:offset+len(text)])\n",
    "\n",
    "            # [num_tokens until entity, num_tokens including the entity]\n",
    "            spans[name] = [len(tokens), len(tokens) +\n",
    "                           len(tmp_tokens) - 1]  # inclusive\n",
    "            # In the last iteration, the pronoun is appended to the end\n",
    "            tokens.extend(tmp_tokens)\n",
    "            current_pos = offset + len(text)\n",
    "\n",
    "        tokens.extend(self.tokenizer.tokenize(row[\"text\"][current_pos:offset]))\n",
    "\n",
    "        # The pronoun is a single token, so the span is the same\n",
    "        assert spans[\"P\"][0] == spans[\"P\"][1]\n",
    "        return tokens, (spans[\"A\"] + spans[\"B\"] + [spans[\"P\"][0]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokens)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.labeled:\n",
    "            return self.tokens[idx], self.offsets[idx], self.labels[idx] \n",
    "        return self.tokens[idx], self.offsets[idx], None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6844631",
   "metadata": {
    "id": "e6844631"
   },
   "outputs": [],
   "source": [
    "model_name_or_path = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7997cbe1",
   "metadata": {
    "executionInfo": {
     "elapsed": 7540,
     "status": "ok",
     "timestamp": 1660494236683,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "7997cbe1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flori\\miniconda3\\envs\\DL\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "train_ds = GAPDataset(df_train[:100], tokenizer)\n",
    "valid_ds = GAPDataset(df_valid[:50], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3e93a13",
   "metadata": {
    "id": "c3e93a13",
    "outputId": "d48fd267-ff92-4ad1-8064-6769064f6cf4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"her boyfriend following Simon's advice after he wouldn't have sex with her but later realised this was due to him catching crabs off her friend Pauline.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['text'][0][274:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72067558",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660494236685,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "72067558"
   },
   "outputs": [],
   "source": [
    "def collate_batch(batch, truncate_len=400):\n",
    "    \"\"\"Batch preparation.\n",
    "\n",
    "    1. Pad the sequences\n",
    "    2. Transform the target.\n",
    "    \"\"\"\n",
    "    batch_features, batch_offsets, batch_labels = zip(*batch)\n",
    "\n",
    "    max_len = min(\n",
    "        max((len(x) for x in batch_features)),\n",
    "        truncate_len\n",
    "    )\n",
    "\n",
    "    # Features\n",
    "    features = np.zeros((len(batch), max_len), dtype=np.int64)\n",
    "\n",
    "    # Padding\n",
    "    for i, row in enumerate(batch_features):\n",
    "        features[i, :len(row)] = row\n",
    "\n",
    "    features_tensor = torch.tensor(features, device=device)\n",
    "\n",
    "    # Offsets\n",
    "    offsets_tensor = torch.stack([\n",
    "        torch.tensor(x, dtype=torch.int64, device=device) for x in batch_offsets\n",
    "    ], dim=0) + 1  # Account for the [CLS] token\n",
    "\n",
    "    # Labels\n",
    "    if batch_labels[0] is None:\n",
    "        return features_tensor, offsets_tensor, None\n",
    "\n",
    "    labels_tensor = torch.tensor(\n",
    "        batch_labels, dtype=torch.uint8, device=device)\n",
    "    return features_tensor, offsets_tensor, labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a3c2791",
   "metadata": {
    "id": "9a3c2791"
   },
   "outputs": [],
   "source": [
    "class Collator:\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        \n",
    "    def __call__(self, batch, truncate_len=400):\n",
    "        \"\"\"Batch preparation.\n",
    "\n",
    "        1. Pad the sequences\n",
    "        2. Transform the target.\n",
    "        \"\"\"\n",
    "        batch_features, batch_offsets, batch_labels = zip(*batch)\n",
    "\n",
    "        max_len = min(\n",
    "            max((len(x) for x in batch_features)),\n",
    "            truncate_len\n",
    "        )\n",
    "\n",
    "        # Features\n",
    "        features = np.zeros((len(batch), max_len), dtype=np.int64)\n",
    "\n",
    "        # Padding\n",
    "        for i, row in enumerate(batch_features):\n",
    "            features[i, :len(row)] = row\n",
    "\n",
    "        features_tensor = torch.tensor(features, device=self.device)\n",
    "\n",
    "        # Offsets\n",
    "        offsets_tensor = torch.stack([\n",
    "            torch.tensor(x, dtype=torch.int64, device=self.device) for x in batch_offsets\n",
    "        ], dim=0) + 1  # Account for the [CLS] token\n",
    "\n",
    "        # Labels\n",
    "        if batch_labels[0] is None:\n",
    "            return features_tensor, offsets_tensor, None\n",
    "\n",
    "        labels_tensor = torch.tensor(\n",
    "            batch_labels, dtype=torch.uint8, device=self.device)\n",
    "        return features_tensor, offsets_tensor, labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8185e7a8",
   "metadata": {
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1660494242800,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "8185e7a8"
   },
   "outputs": [],
   "source": [
    "class CorefHead(nn.Module):\n",
    "    def __init__(self, bert_hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.bert_hidden_size = bert_hidden_size\n",
    "        self.head_hidden_size = 512\n",
    "\n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Dropout(0.1),\n",
    "#             nn.Linear(bert_hidden_size * 3, 512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(512, 3)\n",
    "#         )\n",
    "\n",
    "        # a) Always BN -> AC, (Nothing b/w them).\n",
    "        # b) BN -> Dropout over Dropout -> BN, but try both. [Newer research, finds 1st better ]\n",
    "        # c) BN eliminates the need of Dropout, no need to use Dropout.\n",
    "        # e) BN before Dropout is data Leakage.\n",
    "        # f) Best thing is to try every combination.\n",
    "        # SO CALLED BEST METHOD -\n",
    "        # Layer -> BN -> AC -> Dropout ->Layer\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            #             nn.BatchNorm1d(bert_hidden_size * 3),\n",
    "            #             nn.Dropout(0.5),\n",
    "            #             nn.LeakyReLU(),\n",
    "            #             nn.Linear(bert_hidden_size * 3, self.head_hidden_size),\n",
    "            #             nn.BatchNorm1d(self.head_hidden_size),\n",
    "            #             nn.Dropout(0.5),\n",
    "            #             nn.Linear(self.head_hidden_size, self.head_hidden_size),\n",
    "            #             nn.ReLU(),\n",
    "            #             nn.BatchNorm1d(self.head_hidden_size),\n",
    "            #             nn.Dropout(0.5),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(bert_hidden_size * 3, self.head_hidden_size),\n",
    "            nn.BatchNorm1d(self.head_hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(self.head_hidden_size, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, bert_outputs, offsets):\n",
    "        assert bert_outputs.shape[2] == self.bert_hidden_size\n",
    "        embeddings = self._retrieve_entities_and_pron_embeddings(bert_outputs,\n",
    "                                                           offsets)\n",
    "\n",
    "        return self.fc(embeddings)\n",
    "    \n",
    "    def _retrieve_entities_and_pron_embeddings(self, bert_embeddings, entities_and_pron_offsets):\n",
    "        embeddings_A = []\n",
    "        embeddings_B = []\n",
    "        embeddings_pron = []\n",
    "\n",
    "        # Consider embeddings and offsets in each batch separately\n",
    "        for embeddings, off in zip(bert_embeddings, entities_and_pron_offsets):\n",
    "            # The offsets of mention A are the first and the second\n",
    "            # in the 'off' tensor\n",
    "            offsets_ent_A = range(off[0], off[1]+1)\n",
    "            # The offsets of mention B are the third and the fourth\n",
    "            # in the 'off' tensor\n",
    "            offsets_ent_B = range(off[2], off[3]+1)\n",
    "            # The offset of the pronoun is the last in the 'off' tensor\n",
    "            offset_pron = off[-1]\n",
    "\n",
    "            # The embedding of a mention is the mean of\n",
    "            # all the subtokens embeddings that represent it\n",
    "            embeddings_A.append(embeddings[offsets_ent_A].mean(dim=0))\n",
    "            embeddings_B.append(embeddings[offsets_ent_B].mean(dim=0))\n",
    "            embeddings_pron.append(embeddings[offset_pron])\n",
    "\n",
    "        # Merge outputs\n",
    "        merged_entities_and_pron_embeddings = torch.cat([\n",
    "            torch.stack(embeddings_A, dim=0),\n",
    "            torch.stack(embeddings_B, dim=0),\n",
    "            torch.stack(embeddings_pron, dim=0)\n",
    "        ], dim=1)\n",
    "        # print(torch.stack(outputs_A, dim=0))\n",
    "        # torch.stack(outputs_B, dim=0)\n",
    "        # print(torch.stack(outputs_pron, dim=0))\n",
    "\n",
    "        # shape: batch_size x (embedding_dim * 3)\n",
    "        return merged_entities_and_pron_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb7c679d",
   "metadata": {
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1660494246731,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "eb7c679d"
   },
   "outputs": [],
   "source": [
    "class GAPModel(nn.Module):\n",
    "    \"\"\"The main model.\"\"\"\n",
    "\n",
    "    def __init__(self, bert_model: str):\n",
    "        super().__init__()\n",
    "\n",
    "        if bert_model in (\"bert-base-uncased\", \"bert-base-cased\"):\n",
    "            self.bert_hidden_size = 768\n",
    "        elif bert_model in (\"bert-large-uncased\", \"bert-large-cased\"):\n",
    "            self.bert_hidden_size = 1024\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported BERT model.\")\n",
    "\n",
    "        self.bert = BertModel.from_pretrained(\n",
    "            bert_model).to(device, non_blocking=True)\n",
    "        self.head = CorefHead(self.bert_hidden_size).to(\n",
    "            device, non_blocking=True)\n",
    "\n",
    "    def forward(self, x, offsets):\n",
    "        bert_outputs = self.bert(\n",
    "            x, attention_mask=(x > 0).long(),\n",
    "            token_type_ids=None, output_hidden_states=True)\n",
    "#         concat_bert = torch.cat((bert_outputs[-1],bert_outputs[-2],bert_outputs[-3]),dim=-1)\n",
    "\n",
    "        last_layer = bert_outputs.last_hidden_state\n",
    "        head_outputs = self.head(last_layer, offsets)\n",
    "#         return concat_bert\n",
    "        return head_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f489d7",
   "metadata": {
    "id": "f4f489d7"
   },
   "source": [
    "GradScaler: https://pytorch.org/docs/stable/notes/amp_examples.html#gradient-clipping\n",
    "\n",
    "https://pytorch.org/docs/stable/amp.html#gradient-scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a41065",
   "metadata": {
    "id": "21a41065"
   },
   "source": [
    "**Gradient Scaling**\n",
    "\n",
    "If the forward pass for a particular op has float16 inputs, the backward pass for that op will produce float16 gradients. Gradient values with small magnitudes may not be representable in float16. These values will flush to zero (“underflow”), so the update for the corresponding parameters will be lost.\n",
    "\n",
    "To prevent underflow, “gradient scaling” multiplies the network’s loss(es) by a scale factor and invokes a backward pass on the scaled loss(es). Gradients flowing backward through the network are then scaled by the same factor. In other words, gradient values have a larger magnitude, so they don’t flush to zero.\n",
    "\n",
    "The method `step(optimizer, *args, **kwargs)` internally invokes `unscale_(optimizer)`and if no inf/NaN gradients are found, invokes `optimizer.step()` using the unscaled gradients. Otherwise `optimizer.step()` is skipped to avoid corrupting the params.\n",
    "\n",
    "\\**Note for Gradient Clipping*\n",
    "\n",
    "If you wish to modify the gradients (like in gradient clipping), you should unscale them first. If you attempted to clip *without* unscaling, the gradients' norm magnitude would also be scaled, so your requested threshold would be invalid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47cdacb2",
   "metadata": {
    "id": "47cdacb2"
   },
   "outputs": [],
   "source": [
    "# class Trainer:\n",
    "    \n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         model: nn.Module,\n",
    "#         args: TrainingArguments,\n",
    "#         train_dataloader: DataLoader,\n",
    "#         valid_dataloader: DataLoader,\n",
    "#         criterion: torch.nn,\n",
    "#         optimizer: torch.optim.Optimizer,\n",
    "#         scheduler: torch.optim.lr_scheduler = None,\n",
    "        \n",
    "#     ):\n",
    "        \n",
    "#         self.model = model\n",
    "#         self.train_dataloader = train_dataloader\n",
    "#         self.valid_dataloader = valid_dataloader\n",
    "#         self.criterion = criterion\n",
    "#         self.optimizer = optimizer\n",
    "#         self.scheduler = scheduler\n",
    "        \n",
    "#         if args is None:\n",
    "#             output_dir = \"../../model/tmp_trainer\"\n",
    "#             print(f\"No 'TrainingArguments' passed, using 'output_dir={output_dir}'.\")\n",
    "#             args = TrainingArguments(output_dir=output_dir)\n",
    "        \n",
    "#         self.args = args\n",
    "        \n",
    "#     def train(self, grad_clipping, save_model):\n",
    "#         args = self.args\n",
    "#         train_dataloader = self.train_dataloader\n",
    "#         valid_dataloader = self.valid_dataloader\n",
    "        \n",
    "#         train_losses = []\n",
    "#         train_acc_list = []\n",
    "#         valid_losses = []\n",
    "#         valid_acc_list = []\n",
    "        \n",
    "#         epochs = args.num_train_epochs\n",
    "#         train_loss = 0.0\n",
    "#         train_acc, total_count = 0.0, 0.0\n",
    "#         training_start_time = time.time()\n",
    "        \n",
    "#         scaler = GradScaler()\n",
    "#         self.model.train()\n",
    "#         for epoch in range(epochs):\n",
    "#             epoch_loss = 0.0\n",
    "            \n",
    "#             for step, (features, offsets, labels) in enumerate(train_dataloader):\n",
    "#                 # Empty gradients\n",
    "#                 self.optimizer.zero_grad(set_to_none=True)\n",
    "                \n",
    "#                 # Forward\n",
    "# #                 predictions = self.model(features, offsets)\n",
    "# #                 loss = self.criterion(predictions, labels)\n",
    "#                 # Forward pass with mixed precision\n",
    "#                 with torch.cuda.amp.autocast(): # autocast as a context manager\n",
    "#                     predictions = self.model(features, offsets)\n",
    "#                     loss = self.criterion(predictions, labels)\n",
    "                \n",
    "#                 train_acc += (predictions.argmax(1) == labels).sum().item()\n",
    "#                 total_count += labels.shape[0]\n",
    "                \n",
    "# #                 # Backward  \n",
    "# #                 loss.backward()\n",
    "#                 # Backward pass without mixed precision\n",
    "#                 # It's not recommended to use mixed precision for backward pass\n",
    "#                 # Because we need more precise loss\n",
    "#                 scaler.scale(loss).backward()\n",
    "                \n",
    "#                 torch.nn.utils.clip_grad_norm_(self.model.parameters(), grad_clipping)\n",
    "                \n",
    "#                 # Update weights \n",
    "# #                 self.optimizer.step()\n",
    "#                 scaler.step(self.optimizer)\n",
    "#                 scaler.update()\n",
    "        \n",
    "                \n",
    "#                 epoch_loss += loss.tolist()\n",
    "\n",
    "#                 if step % args.logging_steps == args.logging_steps - 1:\n",
    "#                     mid_loss = epoch_loss / (step + 1)\n",
    "#                     mid_acc = train_acc / total_count\n",
    "# #                     print('\\t[E: {:2d} @ step {}] current avg loss = {:0.4f}'.format(epoch, step, mid_loss))\n",
    "#                     print(f'\\t| step {step+1:3d}/{len(train_dataloader):d} | train_loss: {mid_loss:.3f} | ' \\\n",
    "#                     f'train_acc: {mid_acc:.3f} |')\n",
    "            \n",
    "#             avg_epoch_loss = epoch_loss / len(train_dataloader)\n",
    "#             train_loss += avg_epoch_loss\n",
    "#             train_losses.append(train_loss)\n",
    "#             train_acc_list.append(train_acc / total_count)\n",
    "            \n",
    "# #             print('\\t[E: {:2d}] train loss = {:0.4f}'.format(epoch, avg_epoch_loss))  # print train loss at the end of the epoch\n",
    "            \n",
    "    \n",
    "#             valid_loss, valid_acc = self.evaluate(valid_dataloader)\n",
    "#             valid_losses.append(valid_loss)\n",
    "#             valid_acc_list.append(valid_acc)\n",
    "            \n",
    "# #             print('  [E: {:2d}] valid loss = {:0.4f}'.format(epoch, valid_loss))\n",
    "#             print('-' * 74)\n",
    "#             print(f'| epoch {epoch+1:3d}/{epochs:d} | train_loss: {avg_epoch_loss:.3f} | ' \\\n",
    "#                     f'valid_loss: {valid_loss:.3f} | valid_acc: {valid_acc:.3f} |')\n",
    "#             print('-' * 74)\n",
    "\n",
    "            \n",
    "#         training_time = time.time() - training_start_time\n",
    "#         print(f'Training time: {training_time:.2f}s')\n",
    "#         avg_epoch_loss = train_loss / epochs\n",
    "#         histories = {\n",
    "#             \"train_losses\": train_losses,\n",
    "#             \"train_acc\": train_acc_list,\n",
    "#             \"valid_losses\": valid_losses,\n",
    "#             \"valid_acc\": valid_acc_list,\n",
    "\n",
    "#         }\n",
    "#         print(histories)\n",
    "#         if save_model:\n",
    "#             self._save_model(epoch, valid_acc)\n",
    "    \n",
    "    \n",
    "#         return #avg_epoch_loss, histories\n",
    "            \n",
    "#     def evaluate(self, eval_dataloader):\n",
    "#         valid_loss = 0.0\n",
    "#         eval_acc, total_count = 0, 0\n",
    "        \n",
    "#         self.model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             for (features, offsets, labels) in eval_dataloader:\n",
    "                \n",
    "#                 predictions = self.model(features, offsets)\n",
    "#                 loss = self.criterion(predictions, labels)\n",
    "#                 valid_loss += loss.tolist()\n",
    "\n",
    "#                 eval_acc += (predictions.argmax(1) == labels).sum().item()\n",
    "#                 total_count += labels.shape[0]\n",
    "        \n",
    "#         return valid_loss / len(eval_dataloader), eval_acc / total_count\n",
    "    \n",
    "#     def _save_model(self, epoch, valid_acc):\n",
    "#         torch.save({\n",
    "#                 \"epoch\": epoch,\n",
    "#                 \"model_state_dict\": self.model.state_dict(),\n",
    "#                 \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "#             }, f\"{self.args.output_dir}my_model_{str(valid_acc)[2:5]}_{epoch+1}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "766de1e5",
   "metadata": {
    "executionInfo": {
     "elapsed": 576,
     "status": "ok",
     "timestamp": 1660494298114,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "766de1e5"
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        args: CustomTrainingArguments,\n",
    "        train_dataloader: DataLoader,\n",
    "        valid_dataloader: DataLoader,\n",
    "        criterion: torch.nn,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        scheduler: torch.optim.lr_scheduler = None,\n",
    "        \n",
    "    ):\n",
    "        \n",
    "        self.model = model\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        \n",
    "        if args is None:\n",
    "            output_dir = \"../../model/tmp_trainer\"\n",
    "            print(f\"No 'TrainingArguments' passed, using 'output_dir={output_dir}'.\")\n",
    "            args = CustomTrainingArguments(output_dir=output_dir)\n",
    "        \n",
    "        self.args = args\n",
    "        \n",
    "    def train(self):\n",
    "        args = self.args\n",
    "        valid_dataloader = self.valid_dataloader\n",
    "        epochs = args.num_train_epochs\n",
    "        \n",
    "        train_losses = []\n",
    "        train_acc_list = []\n",
    "        valid_losses = []\n",
    "        valid_acc_list = []\n",
    "        \n",
    "        if args.early_stopping:\n",
    "            patience_counter = 0 \n",
    "\n",
    "        scaler = GradScaler()\n",
    "\n",
    "        if args.resume_from_checkpoint is not None:\n",
    "            self._resume_model(args.resume_from_checkpoint, scaler)\n",
    "\n",
    "        training_start_time = time.time()\n",
    "        print(\"\\nTraining...\")\n",
    "        for epoch in range(epochs):\n",
    "            train_loss, train_acc = self._inner_training_loop(scaler)\n",
    "            train_losses.append(train_loss)\n",
    "            train_acc_list.append(train_acc)\n",
    "\n",
    "            valid_loss, valid_acc = self.evaluate(valid_dataloader)\n",
    "            valid_losses.append(valid_loss)\n",
    "            valid_acc_list.append(valid_acc)\n",
    "\n",
    "            if self.scheduler is not None:\n",
    "                print('-' * 14)\n",
    "                print(f\"  LR: {self.scheduler.get_last_lr()[0]:.2e}\")\n",
    "                self.scheduler.step()\n",
    "            \n",
    "            \n",
    "            self._print_epoch_log(epoch, epochs, train_loss, valid_loss, valid_acc)\n",
    "\n",
    "            if args.early_stopping and len(valid_acc_list) >= 2:\n",
    "                # stop = args.early_stopping_mode == 'min' and epoch > 0 and valid_acc_list[-1] > valid_acc_list[-2]\n",
    "                stop = args.early_stopping_mode == 'max' and epoch > 0 and valid_acc_list[-1] < valid_acc_list[-2]\n",
    "                if stop:\n",
    "                    if patience_counter >= args.early_stopping_patience:\n",
    "                        print('Early stop.')\n",
    "                        break\n",
    "                    else:\n",
    "                        print('-- Patience.\\n')\n",
    "                        patience_counter += 1\n",
    "        \n",
    "        training_time = time.time() - training_start_time\n",
    "        print(f'Training time: {training_time:.2f}s')\n",
    "\n",
    "        metrics_history = {\n",
    "            \"train_losses\": train_losses,\n",
    "            \"train_acc\": train_acc_list,\n",
    "            \"valid_losses\": valid_losses,\n",
    "            \"valid_acc\": valid_acc_list,\n",
    "        }\n",
    "#         print(metrics_history)\n",
    "        if args.save_model:\n",
    "            self._save_model(epoch, valid_acc, scaler)\n",
    "    \n",
    "        return metrics_history\n",
    "\n",
    "    def _inner_training_loop(self, scaler):\n",
    "        args = self.args\n",
    "        train_dataloader = self.train_dataloader\n",
    "        \n",
    "        train_loss = 0.0\n",
    "        train_acc, total_count = 0.0, 0.0\n",
    "\n",
    "        self.model.train()\n",
    "        for step, (features, offsets, labels) in enumerate(train_dataloader):\n",
    "            # Empty gradients\n",
    "            self.optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            # Forward\n",
    "            predictions = self.model(features, offsets)\n",
    "            loss = self.criterion(predictions, labels)\n",
    "            # with torch.cuda.amp.autocast(): # autocast as a context manager\n",
    "            #     predictions = self.model(features, offsets)\n",
    "            #     loss = self.criterion(predictions, labels)\n",
    "\n",
    "            train_acc += (predictions.argmax(1) == labels).sum().item()\n",
    "            total_count += labels.shape[0]\n",
    "            \n",
    "#                 # Backward  \n",
    "            # loss.backward()\n",
    "            # Backward pass without mixed precision\n",
    "            # It's not recommended to use mixed precision for backward pass\n",
    "            # Because we need more precise loss\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            scaler.unscale_(optimizer)\n",
    "            \n",
    "            if args.grad_clipping is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), args.grad_clipping)\n",
    "            \n",
    "            # Update weights \n",
    "            # self.optimizer.step()\n",
    "            scaler.step(self.optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            if step % args.logging_steps == args.logging_steps - 1:\n",
    "                running_loss = train_loss / (step + 1)\n",
    "                running_acc = train_acc / total_count\n",
    "                self._print_step_log(step, running_loss, running_acc)\n",
    "                \n",
    "        return train_loss / len(train_dataloader), train_acc / total_count\n",
    "\n",
    "\n",
    "    def evaluate(self, eval_dataloader):\n",
    "        valid_loss = 0.0\n",
    "        eval_acc, total_count = 0, 0\n",
    "        \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for (features, offsets, labels) in eval_dataloader:\n",
    "                \n",
    "                predictions = self.model(features, offsets)\n",
    "                loss = self.criterion(predictions, labels)\n",
    "                valid_loss += loss.item()\n",
    "\n",
    "                eval_acc += (predictions.argmax(1) == labels).sum().item()\n",
    "                total_count += labels.shape[0]\n",
    "        \n",
    "        return valid_loss / len(eval_dataloader), eval_acc / total_count\n",
    "\n",
    "\n",
    "    def _print_step_log(self, step, running_loss, running_acc):\n",
    "        print(f'\\t| step {step+1:3d}/{len(self.train_dataloader):d} | train_loss: {running_loss:.3f} | ' \\\n",
    "                f'train_acc: {running_acc:.3f} |')\n",
    "\n",
    "    def _print_epoch_log(self, epoch, epochs, train_loss, valid_loss, valid_acc):\n",
    "        print('-' * 74)\n",
    "        print(f'| epoch {epoch+1:3d}/{epochs:d} | train_loss: {train_loss:.3f} | ' \\\n",
    "                f'valid_loss: {valid_loss:.3f} | valid_acc: {valid_acc:.3f} |')\n",
    "        print('-' * 74)\n",
    "        \n",
    "    \n",
    "    def _save_model(self, epoch, valid_acc, scaler):\n",
    "        print(\"Saving model...\")\n",
    "        torch.save({\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": self.model.state_dict(),\n",
    "                \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                \"scaler_state_dict\": scaler.state_dict(),\n",
    "            }, f\"{self.args.output_dir}my_model_{str(valid_acc)[2:5]}_{epoch+1}.pth\")\n",
    "        print(\"Model saved.\")\n",
    "\n",
    "    def _resume_model(self, path, scaler):\n",
    "        checkpoint = torch.load(path, map_location=device)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scaler.load_state_dict(checkpoint['scaler_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31aa4455",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121,
     "referenced_widgets": [
      "33f4b3cc68744f15a9050ab13fa50369",
      "5aa9444352044afbab11e80a90ad11ce",
      "a357bf43127d4b818aca2fae5663097e",
      "77855a78ad6d4eab8803037a54d4f110",
      "bdd013c6bd6c4093adfe23ad74806294",
      "56846c464a09417a9cee013d0c6364fa",
      "4ae3e2d7cd1847fe91e3032c86d313bd",
      "04b1e4e278cd42f8b38dcc45a3e70a44",
      "3c6ee84b2e3b44dc949033915a2229f7",
      "7ec9dc5b2d10478982523e4fbadc626a",
      "3db13623113342b0adfacabe692109fd"
     ]
    },
    "executionInfo": {
     "elapsed": 22294,
     "status": "ok",
     "timestamp": 1660494395331,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "31aa4455",
    "outputId": "3665464a-054f-47b5-94e3-c9356b545dac",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = GAPModel(model_name_or_path).to(device, non_blocking=True)\n",
    "\n",
    "yaml_file = \"/content/drive/MyDrive/Colab Notebooks/Deep Learning/NLP/nlp2022-hw3/hw3/stud/train_notebook.yaml\"\n",
    "yaml_file = \"./train_notebook.yaml\"\n",
    "# Read configuration file with all the necessary parameters\n",
    "with open(yaml_file) as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    \n",
    "training_args = CustomTrainingArguments(**config['training_args'])\n",
    "\n",
    "# Make sure that the learning rate is read as a number and not as a string\n",
    "training_args.learning_rate = float(training_args.learning_rate)\n",
    "\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device=device, non_blocking=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=training_args.learning_rate)\n",
    "# scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, \n",
    "                              collate_fn=collate_batch, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_ds, batch_size=batch_size, \n",
    "                              collate_fn=collate_batch, shuffle=False)\n",
    "\n",
    "trainer = Trainer(model, training_args, \n",
    "                  train_dataloader, valid_dataloader, \n",
    "                  criterion, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7c8f03a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 783
    },
    "executionInfo": {
     "elapsed": 403281,
     "status": "error",
     "timestamp": 1660495715345,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "e7c8f03a",
    "outputId": "069ebd09-c4e9-4184-b659-75c93a7aacc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training...\n",
      "\t| step  10/25 | train_loss: 1.638 | train_acc: 0.450 |\n",
      "\t| step  20/25 | train_loss: 1.557 | train_acc: 0.475 |\n",
      "--------------\n",
      "  LR: 4.55e-03\n",
      "--------------------------------------------------------------------------\n",
      "| epoch   1/10 | train_loss: 1.585 | valid_loss: 0.781 | valid_acc: 0.560 |\n",
      "--------------------------------------------------------------------------\n",
      "\t| step  10/25 | train_loss: 1.721 | train_acc: 0.375 |\n",
      "\t| step  20/25 | train_loss: 1.655 | train_acc: 0.362 |\n",
      "--------------\n",
      "  LR: 4.55e-03\n",
      "--------------------------------------------------------------------------\n",
      "| epoch   2/10 | train_loss: 1.581 | valid_loss: 3.030 | valid_acc: 0.020 |\n",
      "--------------------------------------------------------------------------\n",
      "\t| step  10/25 | train_loss: 1.454 | train_acc: 0.425 |\n",
      "\t| step  20/25 | train_loss: 1.395 | train_acc: 0.388 |\n",
      "--------------\n",
      "  LR: 4.55e-03\n",
      "--------------------------------------------------------------------------\n",
      "| epoch   3/10 | train_loss: 1.473 | valid_loss: 0.986 | valid_acc: 0.420 |\n",
      "--------------------------------------------------------------------------\n",
      "\t| step  10/25 | train_loss: 1.273 | train_acc: 0.425 |\n",
      "\t| step  20/25 | train_loss: 1.212 | train_acc: 0.425 |\n",
      "--------------\n",
      "  LR: 4.55e-04\n",
      "--------------------------------------------------------------------------\n",
      "| epoch   4/10 | train_loss: 1.181 | valid_loss: 1.057 | valid_acc: 0.560 |\n",
      "--------------------------------------------------------------------------\n",
      "\t| step  10/25 | train_loss: 1.244 | train_acc: 0.475 |\n",
      "\t| step  20/25 | train_loss: 1.225 | train_acc: 0.412 |\n",
      "--------------\n",
      "  LR: 4.55e-04\n",
      "--------------------------------------------------------------------------\n",
      "| epoch   5/10 | train_loss: 1.188 | valid_loss: 1.075 | valid_acc: 0.560 |\n",
      "--------------------------------------------------------------------------\n",
      "\t| step  10/25 | train_loss: 1.316 | train_acc: 0.350 |\n",
      "\t| step  20/25 | train_loss: 1.280 | train_acc: 0.287 |\n",
      "--------------\n",
      "  LR: 4.55e-04\n",
      "--------------------------------------------------------------------------\n",
      "| epoch   6/10 | train_loss: 1.231 | valid_loss: 1.081 | valid_acc: 0.560 |\n",
      "--------------------------------------------------------------------------\n",
      "\t| step  10/25 | train_loss: 1.215 | train_acc: 0.325 |\n",
      "\t| step  20/25 | train_loss: 1.149 | train_acc: 0.425 |\n",
      "--------------\n",
      "  LR: 4.55e-05\n",
      "--------------------------------------------------------------------------\n",
      "| epoch   7/10 | train_loss: 1.176 | valid_loss: 1.083 | valid_acc: 0.560 |\n",
      "--------------------------------------------------------------------------\n",
      "\t| step  10/25 | train_loss: 1.070 | train_acc: 0.400 |\n",
      "\t| step  20/25 | train_loss: 1.006 | train_acc: 0.525 |\n",
      "--------------\n",
      "  LR: 4.55e-05\n",
      "--------------------------------------------------------------------------\n",
      "| epoch   8/10 | train_loss: 1.034 | valid_loss: 1.066 | valid_acc: 0.560 |\n",
      "--------------------------------------------------------------------------\n",
      "\t| step  10/25 | train_loss: 1.066 | train_acc: 0.425 |\n",
      "\t| step  20/25 | train_loss: 1.063 | train_acc: 0.438 |\n",
      "--------------\n",
      "  LR: 4.55e-05\n",
      "--------------------------------------------------------------------------\n",
      "| epoch   9/10 | train_loss: 1.089 | valid_loss: 1.075 | valid_acc: 0.560 |\n",
      "--------------------------------------------------------------------------\n",
      "\t| step  10/25 | train_loss: 1.294 | train_acc: 0.200 |\n",
      "\t| step  20/25 | train_loss: 1.240 | train_acc: 0.275 |\n",
      "--------------\n",
      "  LR: 4.55e-06\n",
      "--------------------------------------------------------------------------\n",
      "| epoch  10/10 | train_loss: 1.249 | valid_loss: 1.102 | valid_acc: 0.560 |\n",
      "--------------------------------------------------------------------------\n",
      "Training time: 56.82s\n"
     ]
    }
   ],
   "source": [
    "metrics_history = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3280693e",
   "metadata": {
    "id": "3280693e"
   },
   "outputs": [],
   "source": [
    "metrics_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8569d8f9",
   "metadata": {
    "id": "8569d8f9",
    "outputId": "57936374-9bc5-47ed-a694-4ad2953e0ea5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(metrics_history['train_acc'])\n",
    "plt.plot(metrics_history['valid_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e847996d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_linear_schedule_with_warmup() missing 3 required positional arguments: 'optimizer', 'num_warmup_steps', and 'num_training_steps'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21352\\2506784198.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mscheduler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_linear_schedule_with_warmup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: get_linear_schedule_with_warmup() missing 3 required positional arguments: 'optimizer', 'num_warmup_steps', and 'num_training_steps'"
     ]
    }
   ],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfcc7055",
   "metadata": {
    "id": "bfcc7055",
    "outputId": "91099e06-378b-4b8b-c1d2-5cd2fbd75b71"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_resumed = GAPModel(model_name_or_path).to(device, non_blocking=True)\n",
    "optimizer_resumed = torch.optim.Adam(model_resumed.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9a3799f",
   "metadata": {
    "id": "f9a3799f"
   },
   "outputs": [],
   "source": [
    "path = \"../../model/checkpoints/my_model_850_6.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "683896dc",
   "metadata": {
    "id": "683896dc"
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(path, map_location=device)\n",
    "model_resumed.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer_resumed.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0617e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a02d185d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 5e-06\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer_resumed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d78d01",
   "metadata": {
    "id": "01d78d01",
    "outputId": "d8d325cb-1780-40be-a878-d38f59c6a88e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41, 42, 44, 44, 61]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(train_ds[0][0])\n",
    "# tokens[train_ds[0][1][0] - 1]\n",
    "train_ds[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ad9afe",
   "metadata": {
    "id": "36ad9afe",
    "outputId": "6b9cc51f-8378-4a0a-f39f-a9f85115b9f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cheryl', 'cassidy']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[42:44]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095dabb5",
   "metadata": {
    "id": "095dabb5"
   },
   "source": [
    "A List with your predictions.\n",
    "\n",
    "Each prediction is a tuple, composed by two tuples:\n",
    "(ambigous_pronoun, ambiguous_pronoun_offset), (coreferent_entity, coreferent_entity_offset))\n",
    "\n",
    "for example:\n",
    "    [(('her', 274), ('Pauline', 418))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf34075",
   "metadata": {
    "id": "6bf34075"
   },
   "source": [
    "I need to know the original positions.\n",
    "\n",
    "The model return the label prediction (0 1 2)\n",
    "\n",
    "If pred == 0 => A\n",
    "\n",
    "elif pred == 1 => B\n",
    "\n",
    "else => --\n",
    "\n",
    "I have to know:\n",
    "1. The pronoun and its pos\n",
    "2. The predicted entity and its pos\n",
    "\n",
    "\n",
    "1. I can retrieve the pronoun through the last offset in offsets after encoding the ids.\n",
    "    I also need its original position.\n",
    "    \n",
    "2. \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "180d6256",
   "metadata": {
    "id": "180d6256"
   },
   "outputs": [],
   "source": [
    "def read_dataset(path: str) -> List[Dict]:\n",
    "    samples: List[Dict] = []\n",
    "    pron_counter = Counter()\n",
    "    with open(path) as f:\n",
    "        next(f)\n",
    "        for line in f:\n",
    "            (\n",
    "                id,\n",
    "                text,\n",
    "                pron,\n",
    "                p_offset,\n",
    "                entity_A,\n",
    "                offset_A,\n",
    "                is_coref_A,\n",
    "                entity_B,\n",
    "                offset_B,\n",
    "                is_coref_B,\n",
    "                url,\n",
    "            ) = line.strip().split(\"\\t\")\n",
    "            pron_counter[pron.lower()] += 1\n",
    "            samples.append(\n",
    "                {\n",
    "                    \"id\": id,\n",
    "                    \"text\": text,\n",
    "                    \"pron\": pron,\n",
    "                    \"p_offset\": int(p_offset),\n",
    "                    \"entity_A\": entity_A,\n",
    "                    \"offset_A\": int(offset_A),\n",
    "                    \"is_coref_A\": is_coref_A,\n",
    "                    \"entity_B\": entity_B,\n",
    "                    \"offset_B\": int(offset_B),\n",
    "                    \"is_coref_B\": is_coref_B,\n",
    "                    \"url\": url,\n",
    "                }\n",
    "            )\n",
    "    print(pron_counter)\n",
    "    return samples, pron_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8a8bee5",
   "metadata": {
    "id": "b8a8bee5"
   },
   "outputs": [],
   "source": [
    "train_path = \"../../model/data/train.tsv\"\n",
    "valid_path = \"../../model/data/dev.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ab5e64b",
   "metadata": {
    "id": "4ab5e64b",
    "outputId": "067c9bad-ec3a-4414-8989-e1fdaf39e8a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'his': 904, 'her': 773, 'he': 610, 'she': 555, 'him': 157})\n",
      "Counter({'her': 140, 'his': 108, 'he': 93, 'she': 87, 'him': 26})\n"
     ]
    }
   ],
   "source": [
    "train_dataset, train_pron_counter = read_dataset(train_path)\n",
    "valid_dataset, valid_pron_counter = read_dataset(valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbc6e74",
   "metadata": {
    "id": "7cbc6e74",
    "outputId": "611ea31b-3883-4644-c1df-057ce66f683e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'train-1',\n",
       " 'text': \"Zoe Telford -- played the police officer girlfriend of Simon, Maggie. Dumped by Simon in the final episode of series 1, after he slept with Jenny, and is not seen again. Phoebe Thomas played Cheryl Cassidy, Pauline's friend and also a year 11 pupil in Simon's class. Dumped her boyfriend following Simon's advice after he wouldn't have sex with her but later realised this was due to him catching crabs off her friend Pauline.\",\n",
       " 'pron': 'her',\n",
       " 'p_offset': 274,\n",
       " 'entity_A': 'Cheryl Cassidy',\n",
       " 'offset_A': 191,\n",
       " 'is_coref_A': 'TRUE',\n",
       " 'entity_B': 'Pauline',\n",
       " 'offset_B': 207,\n",
       " 'is_coref_B': 'FALSE',\n",
       " 'url': 'http://en.wikipedia.org/wiki/List_of_Teachers_(UK_TV_series)_characters'}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e635bc0e",
   "metadata": {
    "id": "e635bc0e"
   },
   "outputs": [],
   "source": [
    "def get_entity_and_offset_from_id(label_id, sentence):\n",
    "    if label_id == 0: # Entity A\n",
    "        return sentence['entity_A'], sentence['offset_A']\n",
    "    elif label_id == 1: # Entity B\n",
    "        return sentence['entity_B'], sentence['offset_B']\n",
    "    else: # Neither\n",
    "        return None, None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a00c15d",
   "metadata": {
    "id": "3a00c15d",
    "outputId": "2390d1d4-9f8b-4102-ee5b-1d15fa04e839"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_entity_and_offset_from_id(2, train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ca534a6",
   "metadata": {
    "id": "6ca534a6"
   },
   "outputs": [],
   "source": [
    "def predict(model, sentences: List[Dict]) -> List[Tuple[Tuple[str, int], Tuple[str, int]]]:\n",
    "    df = pd.DataFrame(sentences)\n",
    "    \n",
    "    # tokenizer will be self.tokenizer in the final implementation\n",
    "    dataset = GAPDataset(df, tokenizer)\n",
    "    collator = Collator(device)\n",
    "\n",
    "    predictions = []\n",
    "    \n",
    "    #self.model.eval()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        dataloader = DataLoader(dataset, batch_size=1, \n",
    "                                collate_fn=collator, shuffle=False)\n",
    "        \n",
    "        for (features, offsets, labels), sentence in zip(dataloader, sentences):\n",
    "            \n",
    "#             predictions = self.model(features, offsets).argmax(1).item()\n",
    "            predicted_label_id = model(features, offsets).argmax(1).item()\n",
    "            pred_entity, pred_entity_offset = get_entity_and_offset_from_id(predicted_label_id, sentence)\n",
    "            pron, pron_offset = sentence['pron'],  sentence['p_offset']\n",
    "            \n",
    "            predictions.append(((pron, pron_offset), (pred_entity, pred_entity_offset)))\n",
    "            \n",
    "    return predictions\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c427614f",
   "metadata": {
    "id": "c427614f"
   },
   "outputs": [],
   "source": [
    "pred = predict(model, valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9bba0ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_values = []\n",
    "for sentence in valid_dataset:\n",
    "    gold_both_wrong = sentence[\"is_coref_A\"] == \"FALSE\" and sentence[\"is_coref_B\"] == \"FALSE\"\n",
    "    if gold_both_wrong:\n",
    "        gold_entity_offset = None\n",
    "        gold_entity = None\n",
    "    else:\n",
    "        gold_entity_offset = (\n",
    "            sentence[\"offset_A\"] if sentence[\"is_coref_A\"] == \"TRUE\" else sentence[\"offset_B\"]\n",
    "        )\n",
    "        gold_entity = (\n",
    "            sentence[\"entity_A\"] if sentence[\"is_coref_A\"] == \"TRUE\" else sentence[\"entity_B\"]\n",
    "        )\n",
    "    \n",
    "    \n",
    "    gold_values.append(((sentence['pron'], sentence['p_offset']),(gold_entity, gold_entity_offset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "94057fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {}\n",
    "\n",
    "a.setdefault(\"age\", 0)\n",
    "a.setdefault(\"age\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "940ba563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 0, 'a': 0}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['a'] = 0\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b86c72b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong = []\n",
    "for p, g in zip(pred, gold_values):\n",
    "    if g[1][0] != p[1][0]:\n",
    "        wrong.append((g, p))\n",
    "#     print(p[1], g[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5d5f3f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = wrong[0][0][0][0]\n",
    "get_gender(\"she\")\n",
    "\n",
    "gender = {}\n",
    "\n",
    "for pair in wrong:\n",
    "    pr = pair[0][0][0]\n",
    "    gender.setdefault(get_gender(pr.lower()), 0)\n",
    "    gender[get_gender(pr.lower())] += 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "19ef2627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 35, 0: 34}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d475e6f",
   "metadata": {
    "id": "2d475e6f",
    "outputId": "b09b0735-78cd-41d6-f2ab-a67274d07c31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'validation-2',\n",
       " 'text': \"Kathleen Nott was born in Camberwell, London. Her father, Philip, was a lithographic printer, and her mother, Ellen, ran a boarding house in Brixton; Kathleen was their third daughter. She was educated at Mary Datchelor Girls' School (now closed), London, before attending King's College, London.\",\n",
       " 'pron': 'She',\n",
       " 'p_offset': 185,\n",
       " 'entity_A': 'Ellen',\n",
       " 'offset_A': 110,\n",
       " 'is_coref_A': 'FALSE',\n",
       " 'entity_B': 'Kathleen',\n",
       " 'offset_B': 150,\n",
       " 'is_coref_B': 'TRUE',\n",
       " 'url': 'http://en.wikipedia.org/wiki/Kathleen_Nott'}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f429bd56",
   "metadata": {
    "id": "f429bd56"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(predictions_s, samples):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for pred, label in zip(predictions_s, samples):\n",
    "        gold_pron_offset = label[\"p_offset\"]\n",
    "        pred_pron_offset = pred[0][1] if len(pred[0]) > 0 else None\n",
    "        gold_pron = label[\"pron\"]\n",
    "        pred_pron = pred[0][0] if len(pred[0]) > 0 else None\n",
    "        gold_both_wrong = label[\"is_coref_A\"] == \"FALSE\" and label[\"is_coref_B\"] == \"FALSE\"\n",
    "        pred_entity_offset = pred[1][1] if len(pred[1]) > 0 else None\n",
    "        pred_entity = pred[1][0] if len(pred[1]) > 0 else None\n",
    "              \n",
    "        if gold_both_wrong:\n",
    "            if pred_entity is None and gold_pron_offset == pred_pron_offset and gold_pron == pred_pron:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "        else:\n",
    "            gold_entity_offset = (\n",
    "                label[\"offset_A\"] if label[\"is_coref_A\"] == \"TRUE\" else label[\"offset_B\"]\n",
    "            )\n",
    "            gold_entity = (\n",
    "                label[\"entity_A\"] if label[\"is_coref_A\"] == \"TRUE\" else label[\"entity_B\"]\n",
    "            )\n",
    "            if (\n",
    "                gold_pron_offset == pred_pron_offset\n",
    "                and gold_pron == pred_pron\n",
    "                and gold_entity_offset == pred_entity_offset\n",
    "                and gold_entity == pred_entity\n",
    "            ):\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    \n",
    "    print(f\"# instances: {total}\")\n",
    "    acc = float(correct) / total\n",
    "    print(f\"# accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f970c3d9",
   "metadata": {
    "id": "f970c3d9",
    "outputId": "a73a7b89-4175-45f2-ce1b-1c88e4ee808e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# instances: 454\n",
      "# accuracy: 0.8480\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(pred, valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3908b386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arguments import CustomTrainingArguments\n",
    "a = CustomTrainingArguments(output_dir=\"c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaff3c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomTrainingArguments(output_dir='c', resume_from_checkpoint=None, save_model=False, num_train_epochs=3, logging_steps=250, learning_rate=0.0005, grad_clipping=None, early_stopping=False, early_stopping_mode='max', early_stopping_patience=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0b7ae21f",
   "metadata": {
    "id": "0b7ae21f",
    "outputId": "22c6c145-e93b-4a94-f7fb-47600fbbc5cc"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'resume_from_checkpoint'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9356\\1665919785.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msafe_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0marg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCustomTrainingArguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'training_args'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'resume_from_checkpoint'"
     ]
    }
   ],
   "source": [
    "from arguments import CustomTrainingArguments\n",
    "\n",
    "yaml_file = \"./train.yaml\"\n",
    "\n",
    "# Read configuration file with all the necessary parameters\n",
    "with open(yaml_file) as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    \n",
    "arg = CustomTrainingArguments(**config['training_args'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d9e9ff37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomTrainingArguments(output_dir='../../model/checkpoints/', num_train_epochs=6, logging_steps=250, save_model=False, learning_rate=5e-06, grad_clipping=None, early_stopping=False, early_stopping_mode='max', early_stopping_patience=0)\n"
     ]
    }
   ],
   "source": [
    "print(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a6450b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Training.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.7 (DL)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04b1e4e278cd42f8b38dcc45a3e70a44": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33f4b3cc68744f15a9050ab13fa50369": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5aa9444352044afbab11e80a90ad11ce",
       "IPY_MODEL_a357bf43127d4b818aca2fae5663097e",
       "IPY_MODEL_77855a78ad6d4eab8803037a54d4f110"
      ],
      "layout": "IPY_MODEL_bdd013c6bd6c4093adfe23ad74806294"
     }
    },
    "3c6ee84b2e3b44dc949033915a2229f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3db13623113342b0adfacabe692109fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4ae3e2d7cd1847fe91e3032c86d313bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "56846c464a09417a9cee013d0c6364fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5aa9444352044afbab11e80a90ad11ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56846c464a09417a9cee013d0c6364fa",
      "placeholder": "​",
      "style": "IPY_MODEL_4ae3e2d7cd1847fe91e3032c86d313bd",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "77855a78ad6d4eab8803037a54d4f110": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ec9dc5b2d10478982523e4fbadc626a",
      "placeholder": "​",
      "style": "IPY_MODEL_3db13623113342b0adfacabe692109fd",
      "value": " 420M/420M [00:13&lt;00:00, 55.4MB/s]"
     }
    },
    "7ec9dc5b2d10478982523e4fbadc626a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a357bf43127d4b818aca2fae5663097e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_04b1e4e278cd42f8b38dcc45a3e70a44",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3c6ee84b2e3b44dc949033915a2229f7",
      "value": 440473133
     }
    },
    "bdd013c6bd6c4093adfe23ad74806294": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
